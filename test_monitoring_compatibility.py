#!/usr/bin/env python3
"""
ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

ê¸°ì¡´ ë¡œê·¸ í¬ë§·ê³¼ Phase 1 ìƒˆë¡œìš´ ë¡œê·¸ í¬ë§·ì´ ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±ë˜ëŠ”ì§€ ê²€ì¦
"""

import re
import json
from datetime import datetime, timezone, timedelta

class MonitoringCompatibilityTest:
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.test_results = []
        
        # Phase 1 í™•ì¥ëœ ì •ê·œì‹ íŒ¨í„´ë“¤ (realtime_training_logger.pyì™€ ë™ì¼)
        self.patterns = {
            # ê¸°ì¡´ íŒ¨í„´ë“¤
            'batch': r'Epoch\s+(\d+)\s+\|\s+Batch\s+(\d+)/(\d+)\s+\|\s+Loss:\s+([\d.]+)',
            'accuracy': r'Cls Acc:\s+([\d.]+)\s+\|\s+Det mAP:\s+([\d.]+)\s+\|\s+Time:\s+([\d.]+)s',
            
            # Phase 1 ìƒˆë¡œìš´ íŒ¨í„´ë“¤
            'top5': r'Top-1:\s*([â€°\d.]+)\s*\|\s*Top-5:\s*([\d.]+)',
            'macro_f1': r'Macro-F1:\s*([\d.]+)',
            'domain': r'Single:\s*Top-1=([â€°\d.]+)\s*\|\s*Combination:\s*Top-1=([\d.]+)',
            'latency': r'Pipeline:\s*det=([â€°\d.]+)ms,\s*crop=([\d.]+)ms,\s*cls=([\d.]+)ms,\s*total=([\d.]+)ms',
            'confidence': r'Auto-selected confidence:\s*det=([â€°\d.]+),\s*cls=([\d.]+)',
            'oom': r'OOM Guard:\s*batch_size\s*reduced\s*(\d+)â†’(\d+),\s*grad_accum\s*(\d+)â†’(\d+)',
            'interleave': r'Interleaved:\s*det_steps=(\d+),\s*cls_steps=(\d+)\s*\(ratio=1:([\d.]+)\)'
        }
    
    def test_legacy_logs(self):
        """ê¸°ì¡´ ë¡œê·¸ í¬ë§· í…ŒìŠ¤íŠ¸"""
        print("ğŸ” ê¸°ì¡´ ë¡œê·¸ í¬ë§· í…ŒìŠ¤íŠ¸...")
        
        legacy_logs = [
            "2025-08-24 15:30:22 | INFO | Epoch 4 | Batch 2000/5093 | Loss: 3.5000",
            "2025-08-24 15:35:45 | INFO | Epoch 4 ì™„ë£Œ | Cls Acc: 0.441 | Det mAP: 0.250 | Time: 635.0s",
            "2025-08-24 15:36:00 | INFO | Stage 3 í•™ìŠµ ì§„í–‰ ì¤‘...",
        ]
        
        for log in legacy_logs:
            # Batch íŒ¨í„´ í…ŒìŠ¤íŠ¸
            batch_match = re.search(self.patterns['batch'], log)
            if batch_match:
                epoch, current_batch, total_batches, loss = batch_match.groups()
                result = {
                    'type': 'legacy_batch',
                    'epoch': int(epoch),
                    'batch': f"{current_batch}/{total_batches}",
                    'loss': loss,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… Batch íŒŒì‹±: Epoch {epoch}, Batch {current_batch}/{total_batches}, Loss {loss}")
            
            # ì •í™•ë„ íŒ¨í„´ í…ŒìŠ¤íŠ¸
            acc_match = re.search(self.patterns['accuracy'], log)
            if acc_match:
                cls_acc, det_map, epoch_time = acc_match.groups()
                result = {
                    'type': 'legacy_accuracy',
                    'cls_acc': cls_acc,
                    'det_map': det_map,
                    'epoch_time': f"{epoch_time}s",
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… ì •í™•ë„ íŒŒì‹±: Cls {cls_acc}, Det mAP {det_map}, Time {epoch_time}s")
    
    def test_phase1_logs(self):
        """Phase 1 ìƒˆë¡œìš´ ë¡œê·¸ í¬ë§· í…ŒìŠ¤íŠ¸"""
        print("\nğŸ†• Phase 1 ìƒˆë¡œìš´ ë¡œê·¸ í¬ë§· í…ŒìŠ¤íŠ¸...")
        
        phase1_logs = [
            "2025-08-24 15:40:12 | METRIC | Top-1: 0.441 | Top-5: 0.672",
            "2025-08-24 15:40:15 | METRIC | Macro-F1: 0.387",
            "2025-08-24 15:40:18 | DOMAIN | Single: Top-1=0.523 | Combination: Top-1=0.342",
            "2025-08-24 15:40:25 | LATENCY | Pipeline: det=45ms, crop=12ms, cls=28ms, total=85ms",
            "2025-08-24 15:40:30 | CONFIDENCE | Auto-selected confidence: det=0.25, cls=0.30",
            "2025-08-24 15:40:35 | OOM | OOM Guard: batch_size reduced 16â†’8, grad_accum 2â†’4",
            "2025-08-24 15:40:40 | INTERLEAVE | Interleaved: det_steps=1247, cls_steps=2491 (ratio=1:2.00)"
        ]
        
        for log in phase1_logs:
            # Top-5 ì •í™•ë„ í…ŒìŠ¤íŠ¸
            top5_match = re.search(self.patterns['top5'], log)
            if top5_match:
                top1_acc, top5_acc = top5_match.groups()
                result = {
                    'type': 'phase1_top5',
                    'top1_accuracy': top1_acc,
                    'top5_accuracy': top5_acc,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… Top-5 íŒŒì‹±: Top-1 {top1_acc}, Top-5 {top5_acc}")
            
            # Macro F1 í…ŒìŠ¤íŠ¸
            f1_match = re.search(self.patterns['macro_f1'], log)
            if f1_match:
                macro_f1 = f1_match.groups()[0]
                result = {
                    'type': 'phase1_f1',
                    'macro_f1': macro_f1,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… Macro-F1 íŒŒì‹±: {macro_f1}")
            
            # ë„ë©”ì¸ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            domain_match = re.search(self.patterns['domain'], log)
            if domain_match:
                single_acc, combo_acc = domain_match.groups()
                result = {
                    'type': 'phase1_domain',
                    'single_domain_acc': single_acc,
                    'combination_domain_acc': combo_acc,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… ë„ë©”ì¸ë³„ íŒŒì‹±: Single {single_acc}, Combination {combo_acc}")
            
            # ë ˆì´í„´ì‹œ ë¶„í•´ í…ŒìŠ¤íŠ¸
            latency_match = re.search(self.patterns['latency'], log)
            if latency_match:
                det_latency, crop_latency, cls_latency, total_latency = latency_match.groups()
                result = {
                    'type': 'phase1_latency',
                    'det_latency': det_latency,
                    'crop_latency': crop_latency,
                    'cls_latency': cls_latency,
                    'total_latency': total_latency,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… ë ˆì´í„´ì‹œ íŒŒì‹±: Det {det_latency}ms, Crop {crop_latency}ms, Cls {cls_latency}ms, Total {total_latency}ms")
            
            # Auto Confidence í…ŒìŠ¤íŠ¸
            conf_match = re.search(self.patterns['confidence'], log)
            if conf_match:
                det_conf, cls_conf = conf_match.groups()
                result = {
                    'type': 'phase1_confidence',
                    'det_confidence': det_conf,
                    'cls_confidence': cls_conf,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… Confidence íŒŒì‹±: Detection {det_conf}, Classification {cls_conf}")
            
            # OOM Guard í…ŒìŠ¤íŠ¸
            oom_match = re.search(self.patterns['oom'], log)
            if oom_match:
                old_batch, new_batch, old_accum, new_accum = oom_match.groups()
                result = {
                    'type': 'phase1_oom',
                    'oom_old_batch': old_batch,
                    'oom_new_batch': new_batch,
                    'oom_old_accum': old_accum,
                    'oom_new_accum': new_accum,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… OOM Guard íŒŒì‹±: Batch {old_batch}â†’{new_batch}, Accum {old_accum}â†’{new_accum}")
            
            # Interleaved Learning í…ŒìŠ¤íŠ¸
            interleave_match = re.search(self.patterns['interleave'], log)
            if interleave_match:
                det_steps, cls_steps, ratio = interleave_match.groups()
                result = {
                    'type': 'phase1_interleave',
                    'det_steps': det_steps,
                    'cls_steps': cls_steps,
                    'interleave_ratio': ratio,
                    'status': 'âœ… íŒŒì‹± ì„±ê³µ'
                }
                self.test_results.append(result)
                print(f"  âœ… Interleave íŒŒì‹±: Det {det_steps}, Cls {cls_steps}, Ratio 1:{ratio}")
    
    def test_websocket_payload(self):
        """WebSocket í˜ì´ë¡œë“œ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“¡ WebSocket í˜ì´ë¡œë“œ êµ¬ì¡° í…ŒìŠ¤íŠ¸...")
        
        # ìƒ˜í”Œ í˜ì´ë¡œë“œ ìƒì„± (realtime_training_logger.py broadcast_to_clientsì™€ ë™ì¼ êµ¬ì¡°)
        sample_payload = {
            "timestamp": datetime.now(timezone(timedelta(hours=9))).isoformat(),
            "message": "Test message",
            "type": "realtime",
            # ê¸°ì¡´ ë©”íŠ¸ë¦­
            "epoch": 4,
            "batch": "2000/5093",
            "loss": "3.5000",
            "cls_acc": "0.441",
            "det_map": "0.250",
            "epoch_time": "635.0s",
            # Phase 1 ìƒˆë¡œìš´ ë©”íŠ¸ë¦­
            "top1_accuracy": "0.441",
            "top5_accuracy": "0.672",
            "macro_f1": "0.387",
            "single_domain_acc": "0.523",
            "combination_domain_acc": "0.342",
            "det_latency": "45",
            "crop_latency": "12",
            "cls_latency": "28",
            "total_latency": "85",
            "det_confidence": "0.25",
            "cls_confidence": "0.30",
            "oom_old_batch": "16",
            "oom_new_batch": "8",
            "oom_old_accum": "2",
            "oom_new_accum": "4",
            "det_steps": "1247",
            "cls_steps": "2491",
            "interleave_ratio": "2.00"
        }
        
        try:
            # JSON ì§ë ¬í™”/ì—­ì§ë ¬í™” í…ŒìŠ¤íŠ¸
            json_payload = json.dumps(sample_payload, ensure_ascii=False)
            parsed_payload = json.loads(json_payload)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = [
                'timestamp', 'message', 'type', 'epoch', 'batch', 'loss'
            ]
            
            phase1_fields = [
                'top1_accuracy', 'top5_accuracy', 'macro_f1', 
                'single_domain_acc', 'combination_domain_acc',
                'det_latency', 'crop_latency', 'cls_latency', 'total_latency',
                'det_confidence', 'cls_confidence'
            ]
            
            # ê¸°ì¡´ í•„ë“œ ê²€ì¦
            missing_required = [field for field in required_fields if field not in parsed_payload]
            if not missing_required:
                print("  âœ… ê¸°ì¡´ í•„ìˆ˜ í•„ë“œ ëª¨ë‘ ì¡´ì¬")
            else:
                print(f"  âŒ ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œ: {missing_required}")
            
            # Phase 1 í•„ë“œ ê²€ì¦
            missing_phase1 = [field for field in phase1_fields if field not in parsed_payload]
            if not missing_phase1:
                print("  âœ… Phase 1 ìƒˆë¡œìš´ í•„ë“œ ëª¨ë‘ ì¡´ì¬")
            else:
                print(f"  âŒ ëˆ„ë½ëœ Phase 1 í•„ë“œ: {missing_phase1}")
            
            # í˜ì´ë¡œë“œ í¬ê¸° í™•ì¸
            payload_size = len(json_payload)
            print(f"  ğŸ“Š í˜ì´ë¡œë“œ í¬ê¸°: {payload_size} bytes")
            
            if payload_size < 2048:  # 2KB ë¯¸ë§Œ
                print("  âœ… í˜ì´ë¡œë“œ í¬ê¸° ì ì • (< 2KB)")
            else:
                print("  âš ï¸ í˜ì´ë¡œë“œ í¬ê¸°ê°€ í¼ (â‰¥ 2KB)")
            
            result = {
                'type': 'websocket_payload',
                'payload_size': payload_size,
                'required_fields': len(required_fields) - len(missing_required),
                'phase1_fields': len(phase1_fields) - len(missing_phase1),
                'status': 'âœ… í˜ì´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ'
            }
            self.test_results.append(result)
            
        except Exception as e:
            print(f"  âŒ í˜ì´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            result = {
                'type': 'websocket_payload',
                'error': str(e),
                'status': 'âŒ í˜ì´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨'
            }
            self.test_results.append(result)
    
    def generate_report(self):
        """í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ")
        print("="*60)
        
        total_tests = len(self.test_results)
        success_tests = sum(1 for result in self.test_results if 'âœ…' in result['status'])
        
        print(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"ì„±ê³µ: {success_tests}")
        print(f"ì‹¤íŒ¨: {total_tests - success_tests}")
        print(f"ì„±ê³µë¥ : {(success_tests / total_tests * 100):.1f}%")
        
        print("\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
        for result in self.test_results:
            print(f"  {result['status']} - {result['type']}")
        
        # JSON ë³´ê³ ì„œ ì €ì¥
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_tests': total_tests,
                'success_tests': success_tests,
                'success_rate': success_tests / total_tests * 100
            },
            'details': self.test_results
        }
        
        with open('/tmp/monitoring_compatibility_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: /tmp/monitoring_compatibility_report.json")
        
        if success_tests == total_tests:
            print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜¸í™˜ì„± ì™„ë²½!")
            return True
        else:
            print(f"\nâš ï¸ {total_tests - success_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ì ê²€ í•„ìš”.")
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*60)
        
        self.test_legacy_logs()
        self.test_phase1_logs()
        self.test_websocket_payload()
        
        return self.generate_report()


if __name__ == "__main__":
    tester = MonitoringCompatibilityTest()
    success = tester.run_all_tests()
    exit(0 if success else 1)