# Original PART_B Design - Two-Stage Conditional Pipeline
# RTX 5080 16GB + 128GB RAM Optimization + Progressive Validation Strategy

# 경로 설정 (SSD 최적화)
paths:
  exp_dir: "/home/max16/pillsnap_data/exp/exp01"
  data_root: "/home/max16/pillsnap_data"  # Native Linux 데이터 전용 경로
  ckpt_dir: null  # exp_dir/checkpoints 자동 생성
  tb_dir: null    # exp_dir/tb 자동 생성
  reports_dir: null  # exp_dir/reports 자동 생성

# 점진적 검증 전략 (PART_0 핵심 설계)
progressive_validation:
  enabled: true
  current_stage: 3    # Stage 3 최적화 학습 (4로의 진행은 보류)
  strategy: "stratified_balanced_sampling"  # 계층적 균형 샘플링
  
  stage_configs:
    stage_1:
      purpose: "pipeline_validation"        # 파이프라인 검증
      max_samples: 5000
      max_classes: 50
      target_ratio: {single: 0.7, combination: 0.3}
      time_limit_hours: 2
      target_metrics:
        classification_accuracy: 0.40      # 50클래스 기준
        detection_map_0_5: 0.30           # 기본 검출 가능성
        inference_time_ms: 50             # RTX 5080 실시간 처리
        memory_usage_gb: 14               # VRAM 안정성
        data_loading_s_per_batch: 2       # 128GB RAM 활용도
        
    stage_2:
      purpose: "performance_baseline"       # 성능 기준선 확립
      max_samples: 25000
      max_classes: 250
      target_ratio: {single: 0.7, combination: 0.3}
      time_limit_hours: 8
      target_metrics:
        classification_accuracy: 0.60      # 250클래스 대상
        detection_map_0_5: 0.50           # 기본 검출 성능
        detection_map_0_5_0_95: 0.35      # COCO 표준 지표
        macro_f1: 0.55                    # 클래스 불균형 환경
        throughput_img_per_s: 100         # API 서빙 처리량
        
    stage_3:
      purpose: "two_stage_pipeline_validation"  # Two-Stage Pipeline 기능 검증
      max_samples: 100000
      max_classes: 1000
      target_ratio: {single: 0.95, combination: 0.05}  # 설명용 목표치 (실제 배치 샘플링은 domain_mixing 3:1=25% combo)
      # 실제 샘플링은 interleave_ratio와 domain_mixing으로 제어됨
      time_limit_hours: 16                  # Detection 추가로 시간 유지
      # ⭐ IMPORTANT: Stage 3는 반드시 manifest 기반으로 진행 (실행 인자 우선)
      data_method: "manifest_based"         # 물리적 복사 없이 원본 직접 로딩
      manifest_path: "artifacts/stage3/manifest_train.csv"  # 기본값 (실행 시 --manifest-train 인자가 우선)
      # MANIFEST | train=artifacts/stage3/manifest_train.remove.csv | val=artifacts/stage3/manifest_val.remove.csv
      storage_savings_gb: 14.6              # 용량 절약 (복사 시 대비)
      focus: "two_stage_pipeline"           # Detection + Classification 통합
      skip_detection: false                 # Detection 학습 활성화
      target_metrics:
        classification_accuracy: 0.85      # 높은 Classification 목표 (유지)
        detection_map_0_5: 0.30           # Detection 기능 검증 목표 (5% 데이터)
        macro_f1: 0.80                    # 불균형 환경 높은 성능
        top5_accuracy: 0.95               # Top-5 정확도
        memory_stable_hours: 12           # 장시간 안정성
        pipeline_inference_ms: 80         # Two-Stage 파이프라인 추론 시간
        
    stage_4:
      purpose: "production_deployment"      # 최종 프로덕션 학습
      max_samples: 500000
      max_classes: 5000
      target_ratio: {single: 0.7, combination: 0.3}
      time_limit_hours: 120
      # 향후 대배치 학습도 manifest 기반 예정
      data_method: "manifest_based"         # 물리적 복사 없이 원본 직접 로딩
      manifest_path: "artifacts/stage4/manifest_train.csv"  # 향후 참조용
      storage_savings_gb: 73.0              # 용량 절약 (복사 시 대비)
      target_metrics:
        classification_accuracy: 0.92      # 최종 목표
        detection_map_0_5: 0.85           # 조합약품 최종 목표
        detection_map_0_5_0_95: 0.65      # 최고 수준
        macro_f1: 0.88                    # 최고 수준 F1
        inference_latency_ms: 30          # 전체 파이프라인

# 조건부 Two-Stage Pipeline (PART_A 핵심 설계)
pipeline:
  # 사용자 제어 기반 설계 (자동 판단 완전 제거)
  mode: "single"  # "single" (기본, 90% 케이스) | "combo" (명시적 선택)
  strategy: "user_controlled"  # 복잡한 자동 판단 대신 사용자 직접 선택
  auto_fallback: false         # 자동화 완전 제거
  
  # 단일 약품: 직접 분류 경로 (기본 권장)
  single_mode:
    model: "efficientnetv2_l"   # 384px 입력, Stage 3+ Large 모델
    accuracy_target: 0.92
    
  # 조합 약품: 검출 → 개별 분류 (명시적 선택시)
  combo_mode:
    detector: "yolov11l"        # 640px 입력, Stage 3+ Large 모델 (XL→L 통일)
    classifier: "efficientnetv2_l"  # 384px 입력, Stage 3+ Large 모델
    map_target: 0.85

# 데이터셋 구성 (PART_B ZIP 기반 구조)
data:
  root: "/home/max16/pillsnap_data"
  
  # ZIP 추출 구조 기반 (PART_0 설계)
  train:
    single_images: "data/train/images/single"        # TS_1_single~TS_81_single
    combination_images: "data/train/images/combination"  # TS_1_combo~TS_8_combo
    single_labels: "data/train/labels/single"        # TL_1_single~TL_81_single  
    combination_labels: "data/train/labels/combination"  # TL_1_combo~TL_8_combo
  val:
    single_images: "data/val/images/single"          # VS_1_single~VS_10_single
    combination_images: "data/val/images/combination"    # VS_1_combo
    single_labels: "data/val/labels/single"          # VL_1_single~VL_10_single
    combination_labels: "data/val/labels/combination"    # VL_1_combo
  test:
    single_images: "data/test/images/single"         # 테스트용 데이터
    combination_images: "data/test/images/combination"
    single_labels: "data/test/labels/single" 
    combination_labels: "data/test/labels/combination"
  
  # 이미지 크기 (PART_A 설계)
  img_size:
    detection: 640      # YOLOv11l 입력 (모델 크기 통일)
    classification: 384 # EfficientNetV2-L 입력 (크기 주석 통일)
  
  # 클래스 정보 (manifest 기반 실제 클래스 수)
  num_classes: 4020     # manifest 기반 실제 클래스 수 (val-only 2개 제거 후)
  # CLASS_SET | num_classes=4020 | source=manifest | head_reset=True
  class_names_path: "processed/class_names.json"
  edi_mapping_path: "processed/edi_mapping.json"

# 검출 모델 (Stage 3+ YOLOv11l Large)
detection:
  model: "yolov11l"     # Stage 3+ Large 모델 (XL→L 통일)
  pretrained: true
  num_classes: 1        # "pill" 위치 검출용
  class_names: ["pill"]
  # conf_threshold: 자동 튜닝 결과로 대체
  iou_threshold: 0.5
  max_detections: 100
  amp: true

# 분류 모델 (Stage 3+ EfficientNetV2-L)
classification:
  backbone: "efficientnetv2_l.in21k_ft_in1k"  # Stage 3+ Large 모델
  pretrained: true
  drop_rate: 0.3
  drop_path_rate: 0.2
  num_classes: 4020     # manifest 기반 실제 클래스 수 (체크포인트 로드시 헤드 리셋)
  # CLASS_SET | num_classes=4020 | source=manifest_train.remove.csv
  amp: true

# Interleaved Two-Stage 학습 (PART_A Annex)
train:
  strategy: "interleaved"  # 미니배치 단위 교차 학습
  interleave_ratio: [1, 2]  # det:cls = 1:2 (분류 학습 비중 증가, 제안에 따라)
  
  # 검출 모델 학습 - Production 최적화 설정 (YOLOv11l 사용)
  detection:
    epochs: 50
    # OOM 회피 우선 - 마이크로 배치 + Gradient Accumulation
    batch_size: 4          # 마이크로 배치 (보수적 시작)
    auto_batch_tune: true
    auto_batch_max: 8      # 루트 설정 (stage override에서 재정의됨)
    
    # Model: Large 모델로 통일
    model_size: "yolov11l"  # Large 모델로 통일 (v 추가, 표기 통일)
    
    # Gradient Accumulation으로 효과 배치 달성 (목표: effective 16)
    grad_accum_steps: 4    # 4×4=16 효과 배치
    grad_clip: 10.0        # Gradient clipping
    
    # Optimizer: AdamW with production settings
    optimizer: "adamw"
    optimizer_params:
      weight_decay: 5e-4   # 제안된 weight_decay
      betas: [0.9, 0.999]
    
    # LR Schedule: base 1e-3, warmup 1000 step → cosine decay, min_lr 1e-5
    # 효과 배치 16 기준 (4×4=16), OOM 시 자동 스케일링
    lr: 1e-3              # 제안된 base LR (효과 배치 16 기준)
    scheduler: "cosine"
    warmup_steps: 1000    # step 기반 warmup (제안에 따라) - Stage 3 유지
    warmup_epochs: null   # step 기반이므로 비활성화
    min_lr: 1e-5          # 제안된 min_lr
    effective_batch_base: 16  # LR 스케일링 기준 효과 배치
    
    # EMA 활성화 (decay≈0.9998)
    ema:
      enabled: true
      decay: 0.9998       # 제안된 decay 값
      use_for_eval: true  # 평가는 EMA 가중치 기준
      use_for_save: true  # 저장은 EMA 가중치 기준
    
    # 증강 설정
    augmentation:
      mosaic: 0.3          # 제안값 (≈0.3)
      hsv_h: 0.015         # HSV 증강 (≈0.7 strength)
      hsv_s: 0.7
      hsv_v: 0.4
      fliplr: 0.5          # flip (≈0.5)
      # copy_paste: 0.2    # 고정값 비활성화 (램프 정책 우선)
      mixup: 0.0           # YOLO에서는 0 유지 (콤보 오검 방지, 합성 파이프가 대체)
      
    # 평가 임계: Recall 우선 세팅
    evaluation:
      # conf_threshold: 자동 튜닝 결과로 대체 (Recall 우선)
      iou_threshold: 0.50   # IoU=0.50
      max_det: 100          # max_det≈100
    
    early_stopping:
      enabled: true
      monitor: "mAP@0.5"
      mode: "max"
      patience: 12        # Detection은 더 긴 patience
  
  # 분류 모델 학습 - Production 최적화 설정 (효과 배치 64 기준)
  classification:
    epochs: 30
    # OOM 회피 우선 - 마이크로 배치 + Gradient Accumulation
    batch_size: 8          # 마이크로 배치 (보수적 시작)
    auto_batch_tune: true  
    auto_batch_max: 16     # 루트 설정 (stage override에서 재정의됨)
    
    # Gradient Accumulation으로 효과 배치 32 달성 (추가 제안)
    grad_accum_steps: 4    # 8×4=32 효과 배치 (메모리 안정성)
    grad_clip: 1.0        # Gradient clipping
    
    # Optimizer: AdamW with production settings
    optimizer: "adamw"
    optimizer_params:
      betas: [0.9, 0.999]  # 제안된 betas
      weight_decay: 0.02   # 제안된 weight_decay
    
    # LR Schedule: base 5e-5, warmup 500 steps → cosine decay, min_lr 1e-6
    # 효과 배치 32 기준, 과적합 방지 우선
    lr: 5e-5              # 과적합 방지를 위해 낮춤 (2e-4 → 5e-5)
    scheduler: "cosine_with_restarts"  # Warm restarts 추가
    warmup_steps: 500     # 추가 제안: 스텝 기반 warmup
    warmup_epochs: null   # 스텝 기반이므로 비활성화
    min_lr: 1e-6          # 최소 LR
    T_0: 10               # Warm restart 주기
    T_mult: 2             # 주기 증가 배율
    effective_batch_base: 32  # LR 스케일링 기준 효과 배치
    
    # EMA 활성화 (decay≈0.9998)
    ema:
      enabled: true
      decay: 0.9998       # 제안된 decay 값
      use_for_eval: true  # 평가는 EMA 가중치 기준
      use_for_save: true  # 저장은 EMA 가중치 기준
    
    # 정규화/증강 설정
    regularization:
      label_smoothing: 0.1      # 제안값
      mixup: 0.1               # 제안값
      cutmix: 0.2              # 제안값
      random_erasing: 0.20     # 초반 수렴 저하 시 0.15~0.20으로 자동 조정 가능
      # REG_ADJ | random_erasing 0.25 -> 0.20 (slow start) 자동 조정 스위치
      
    # 불균형 보정: class-balanced reweighting (빈도^-0.5)
    class_balancing:
      enabled: true
      method: "reweight_frequency"  # 빈도 기반 재가중치
      exponent: -0.5               # 제안된 지수
    
    # 메트릭 로깅: top-1, top-5, macro-F1 포함
    metrics:
      - "top1_accuracy"
      - "top5_accuracy"
      - "macro_f1"
      - "precision_macro"
      - "recall_macro"
    
    # Early stopping은 통합 설정에서 제어 (중복 방지)
    # EARLY_STOP | source=unified | monitor=val_top1 | patience=10
  
  # 데이터 커리큘럼 및 샘플링 전략
  curriculum:
    # Detection Curriculum: Single 사전학습 → Combination 미세조정
    detection_curriculum:
      enabled: true
      pretrain_on_single: true        # Single 데이터로 사전학습
      finetune_on_combination: true   # Combination으로 미세조정
      pretrain_epochs: 15             # 사전학습 에포크
      finetune_epochs: 35             # 미세조정 에포크
      
      # Single 데이터용 약한 라벨 생성
      weak_labeling:
        enabled: true
        method: "center_fixed_ratio"   # 중앙 고정 비율 박스
        coverage_ratio: [0.70, 0.85]  # 긴변의 70~85% 커버
        loss_weight: 0.5               # 약한 라벨 loss weight 낮춤
        
    # Synthetic Combination from Single (Copy-Paste)
    synthetic_combination:
      enabled: true
      instance_count: [2, 5]          # 2~5개/이미지
      scale_jitter: [0.7, 1.3]       # scale jitter
      rotation_degrees: 15            # ±15° 회전
      occlusion_ratio: [0.10, 0.35]  # 10~35% 겹침 허용
      lighting_jitter: "medium"       # 중간 강도
      initial_ratio: 0.20             # 초기 20% 시작
      max_ratio: 0.30                 # 최대 30%까지
      
    # Domain-Mixed Sampling (배치 단위 혼합)
    domain_sampling:
      enabled: true
      single_combination_ratio: [3, 1]  # Single:Combination = 3:1
      maintain_batch_balance: true      # 배치 균형 유지
      
    # Classification Input Consistency (검출-크롭 규칙 동기화)  
    input_consistency:
      enabled: true
      crop_margin: [0.10, 0.15]        # 박스 여유 마진 10~15%
      resize_method: "minimal_distortion"  # 왜곡 최소화
      apply_to_all_domains: true       # Single/Combination/합성 모두 동일 적용
      
    # Hard Example Mining
    hard_example_mining:
      enabled: true
      classification:
        top_loss_percentile: 0.10      # 손실 상위 10%
        resampling_weight: 1.5         # 다음 epoch 1.5x 가중
      detection:
        fn_augmentation: true          # FN 사례 재배치
        
    # Guardrails (안정성 장치)
    guardrails:
      weak_label_rollback:
        metric: "mAP_single"
        threshold: -0.03               # 0.03p 이상 하락시
        action: "reduce_weight_to_0.3"
      synthetic_rollback:
        metrics: ["mAP_combo", "recall_combo"]
        threshold: -0.02               # 0.02p 이상 하락시
        action: "reduce_ratio_by_0.05"
        cooldown_epochs: 1

  seed: 42
  deterministic: false
  resume: null

# GPU/메모리 최적화 - Stage 3 Production 준비 최적화
optimization:
  # Mixed Precision - BF16 우선, FP16 강제 금지
  amp: true
  amp_dtype: "auto"      # BF16 > FP16 자동 선택 (FP16 강제 금지)
  
  # CUDA 최적화
  tf32: true             # TF32 허용 유지
  channels_last: true    # 메모리 효율성
  torch_compile: "max-autotune"     # 최적화 모드 유지
  compile_mode: "max-autotune"      # 재컴파일 방지용 고정 모드
  compile_fallback: "reduce-overhead"
  compile_warmup_steps: 100
  compile_dynamic_shapes: false     # 재컴파일 방지를 위한 고정 모양
  
  # CUDA Graphs (안정성을 위해 비활성화 유지)
  use_cuda_graphs: false
  
  # 메모리 관리 - 주기적 empty_cache 비활성화 (수동 호출만)
  empty_cache_steps: null           # 비활성화 (제안에 따라)
  empty_cache_manual_only: true     # 필요시 수동 호출만 허용
  
  # OOM 가드 시스템
  oom_guard:
    enabled: true                   # OOM 가드 활성화
    auto_reduce_batch: true         # OOM 시 자동 배치 감소
    batch_reduction_factor: 0.75    # 배치 크기 감소 비율 (75%)
    max_reduction_attempts: 3       # 최대 감소 시도 횟수
    maintain_effective_batch: true  # 효과 배치 유지 (grad_accum 증가)
    lr_scale_with_effective_batch: true  # 효과 배치에 따른 LR 선형 보정
  
  # 프로파일링
  warmup_steps: 100
  profile_interval: 500

# 128GB RAM 최적화 - Stage 3 Production 고성능 설정
dataloader:
  num_workers: 16           # 높은 값으로 설정 (제안: 16 내외)
  autotune_workers: true    # Native Linux 최적화
  pin_memory: true          # 활성화 (제안에 따라)
  pin_memory_device: "cuda"
  prefetch_factor: 8        # 높은 값으로 설정 (제안: 8 내외)
  persistent_workers: true  # 활성화 (제안에 따라)
  drop_last: true
  
  # 128GB RAM 활용 - Stage 3에 맞는 대용량 캐시
  ram_optimization:
    cache_policy: "hotset"
    hotset_size_images: 100000  # Stage 3 대응 10만장 캐시 (≈41 GiB)
    cache_labels: true
    use_lmdb: false
    decode_dtype: uint8
    to_tensor_dtype: float16    # 메모리 효율성
    preload_samples: 0

# Stage별 하드웨어 최적화 (현재 테스트 방법론 통합)
stage_overrides:
  1:    # Stage 1: 파이프라인 검증 (SSD 최적화)
    purpose: pipeline_validation
    test_mode: true           # 현재 스모크 테스트 방법론 통합
    dataloader:
      num_workers: 16         # SSD I/O 최적화: 2→16 복원
      prefetch_factor: 6      # SSD 성능 활용: 2→6 복원
    train:
      detection: 
        auto_batch_max: 200
        epochs: 1             # 스모크 테스트 수준
      classification:
        auto_batch_max: 320   # 디스크 병목 대응: 280→320
        epochs: 1             # 스모크 테스트 수준
    ram_optimization:
      hotset_size_images: 30000
  
  2:    # Stage 2: 성능 기준선
    test_mode: false          # 실제 학습 모드
    dataloader:
      num_workers: 12
      prefetch_factor: 6
    train:
      detection: {auto_batch_max: 120}
      classification: {auto_batch_max: 160}
    ram_optimization:
      hotset_size_images: 50000
  
  3:    # Stage 3: 확장성 테스트 (Two-Stage: YOLOv11l + EfficientNetV2-L)
    dataloader:
      num_workers: 12  # Large 모델용 조정
      prefetch_factor: 6
    train:
      detection: 
        auto_batch_max: 6   # Stage 3 최종 적용값 (루트 8 → override 6)
        epochs: 50
      classification:
        auto_batch_max: 12  # Stage 3 최종 적용값 (루트 16 → override 12)
        epochs: 50
    ram_optimization:
      hotset_size_images: 70000
      
  # Stage 4는 비활성화됨 (orphan keys 제거)
  # 4:
  #   dataloader:
  #     num_workers: 16
  #     prefetch_factor: 8
  #   ram_optimization:
  #     hotset_size_images: 80000

# OptimizationAdvisor (PART_0 반자동화 평가 시스템)
optimization_advisor:
  enabled: true
  run_after_training: true
  generate_report: true
  update_tensorboard: true
  recommend_next_stage: true    # 사용자 선택권 제공
  
  # 사용자 선택지 제공 (PART_0 철학)
  user_choice_options:
    - "RECOMMEND_PROCEED: 권장사항 적용 후 다음 Stage"
    - "SUGGEST_OPTIMIZE: 현재 성능으로 다음 Stage 진행" 
    - "WARN_STOP: 수동 디버깅 모드"

# 로깅 설정은 하단 통합 블록으로 이동 (중복 제거)

# 추론 설정은 하단 통합 블록으로 이동 (중복 제거)

# ONNX 내보내기 (PART_A 설계)
export:
  opset: 17
  dynamic_axes:
    detection: {"images": {0: "batch"}}
    classification: {"input": {0: "batch"}}
  compare:
    enabled: true
    tolerance:
      detection_map: 0.01
      classification_acc: 0.005

# API 서빙 (PART_A 설계)
api:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  timeout: 60
  cors_allow_origins: 
    - "http://localhost:3000"
    - "https://pillsnap.co.kr"
    - "https://api.pillsnap.co.kr"
  require_api_key: true
  max_request_size: 20971520

# 현재 테스트 방법론 통합
testing:
  # 현재 GPU 스모크 테스트 패턴 적용
  smoke_tests:
    enabled: true
    gpu_synthetic: "tests/gpu_smoke/gpu_smoke_A.py"
    gpu_real_data: "tests/gpu_smoke/gpu_smoke_B.py"  
    gpu_stage2_integration: "tests/gpu_smoke/gpu_smoke_stage2.py"
    
  # Progressive Validation과 연동
  stage_integration:
    stage_1: 
      smoke_test_mode: true     # 현재 방식 적용
      max_epochs: 1
      validation_only: true
    stage_2:
      smoke_test_mode: false    # 실제 학습 모드
      max_epochs: 30
    stage_3:
      smoke_test_mode: false
    stage_4:
      smoke_test_mode: false

# Stage 3 Production 로깅/평가 시스템 (통합 단일 블록)
logging:
  # 기본 로깅 설정 (첫 번째 블록에서 병합)
  tensorboard: true
  wandb: false
  step_log_interval: 50
  epoch_log_interval: 1
  save_metrics_json: true
  # 무거운 옵션 비활성화 (요구사항)
  save_confusion_matrix: false      # 무거운 옵션 비활성화
  save_roc_curves: false           # 무거운 옵션 비활성화
  
  # 체크포인트 설정
  save_best: true
  save_last: true
  save_top_k: 3
  
  # 도메인별 메트릭 분리 (미니멀 핵심만)
  domain_separation:
    enabled: true
    domains: ["single", "combination"]
    # 미니멀 핵심 메트릭만
    metrics:
      - "top1_accuracy"     # 분류: top-1
      - "top5_accuracy"     # 분류: top-5  
      - "macro_f1"          # 분류: macro-F1
      - "map_0_5"           # 검출: mAP@0.5
      - "recall"            # 검출: Recall
      - "precision"         # 검출: Precision
    
  # 지연시간 세분화 모니터링
  latency_breakdown:
    enabled: true
    components:
      - "det_ms"        # Detection 추론 시간
      - "crop_ms"       # Crop 처리 시간  
      - "cls_ms"        # Classification 추론 시간
      - "total_ms"      # 전체 파이프라인 시간
    percentiles: [50, 95, 99]
    
  # 검증 주기 최적화 (경량 + 정식)
  validation_schedule:
    # 정식 검증: 3 epoch마다 (지표·레이턴시 분해 포함)
    comprehensive_interval: 3    # 3 epoch마다 정식 검증 (요구사항)
    # 경량 sanity 검증: 매 epoch (100 batch만 평가)
    lightweight_interval: 1     # 매 epoch 경량 검증
    lightweight_samples: 100    # 100 batch만 평가 (요구사항)
    # 도메인 분리 지표 항상 기록
    domain_separation_always: true
    
  # 클래스별 F1 요약 (간소화)
  per_class_metrics:
    enabled: true
    summary_only: true          # 요약만 저장 (대형 표 제외)
    top_worst_classes: 10       # 성능 낮은 상위 10개만
    f1_threshold: 0.5           # F1 임계값 미만 클래스 보고
    # 대형 혼동행렬·썸네일·전클래스 F1 전체 표 저장 안함
    save_full_confusion_matrix: false
    save_class_thumbnails: false
    save_full_f1_table: false
    
  # 그래디언트 노름 모니터링 (일관된 지점 기록)
  gradient_monitoring:
    enabled: true
    # 기본: 클리핑 후 기록, 3 epoch마다 클리핑 전도 기록
    default_timing: "after_clipping"    # 기본은 클리핑 후
    log_interval: 100                   # 100 스텝마다 기록
    # 3 epoch마다 클리핑 전도 함께 로그
    pre_clipping_interval_epochs: 3     # 3 epoch마다 클리핑 전 기록
    track_layers: ["classifier.head", "detector.head"]  # 주요 레이어만
    norm_threshold: 10.0                # 임계값 초과시 경고
    
  # 신뢰도 임계값 자동 튜닝 (도메인별 최적화)
  confidence_tuning:
    enabled: true
    # 스위프 범위 및 설정
    confidence_range: [0.20, 0.30]  # 스위프 범위 [0.20, 0.30]
    confidence_step: 0.02           # 스텝 크기 0.02
    # 우선순위: Recall 우선, 동률 시 F1
    priority_metric: "recall"       # 우선순위 메트릭
    fallback_metric: "f1_score"     # 동률 시 결정 메트릭
    # 도메인별 개별 최적화
    domain_specific: true           # single/combination 도메인별 최적화
    domains: ["single", "combination"]
    # 평가 주기
    tune_interval_epochs: 3         # 3 epoch마다 튜닝 실행
    
  # 로깅 최적화 (용량·시간 절감)
  optimization:
    async_logging: true         # 비동기 로깅
    buffer_size: 1000          # 로그 버퍼 크기
    flush_interval: 30         # 30초마다 플러시
    compress_old_logs: true    # 오래된 로그 압축
    max_log_files: 5          # 최대 로그 파일 수 (10→5 절감)
    
    # 한 페이지 요약 리포트 (용량 절감)
    summary_report:
      enabled: true
      format: "single_page"    # 한 페이지 요약만
      include_plots: false     # 플롯 제외 (용량 절약)
      auto_compress: true      # 자동 압축
      retention_days: 7        # 7일 후 자동 삭제

# Stage 3 Production 추론/NMS 튜닝 설정 (통합 단일 블록)
inference:
  # 기본 추론 설정 (첫 번째 블록에서 병합)
  # confidence_threshold: 자동 튜닝 결과 대체
  lazy_load_detector: true
  batch_size: 1
  target_latency_ms: 100
  
  # Detection NMS 튜닝 (confidence는 자동 튜닝으로 결정)
  detection_nms:
    # confidence_threshold: 자동 튜닝 결과로 대체
    iou_threshold: 0.7           # NMS IoU 임계값 (높게 설정 - 보수적)
    max_detections: 300          # 최대 검출 수 (조합약 다중객체 대응)
    
  # Classification 임계값 (자동 튜닝으로 결정)
  classification:
    # confidence_threshold: 자동 튜닝 결과로 대체
    top_k_candidates: 5         # Top-K 후보 고려
    
  # 파이프라인 최적화
  pipeline_optimization:
    batch_detection: true       # Detection 배치 처리
    batch_classification: true  # Classification 배치 처리
    max_batch_size: 32         # 추론 최대 배치 크기
    
  # TensorRT 최적화 (Production 준비)
  tensorrt:
    enabled: false             # 개발단계에서는 비활성화
    fp16_mode: true           # FP16 정밀도
    max_workspace_size: "2GB" # TensorRT 워크스페이스
    
  # ONNX 최적화
  onnx:
    enabled: true             # ONNX 변환 활성화
    optimization_level: "all" # 모든 최적화 적용
    providers: ["CUDAExecutionProvider", "CPUExecutionProvider"]
    
  # 후처리 최적화
  post_processing:
    crop_padding: 0.1         # Crop 패딩 (10%)
    resize_interpolation: "bilinear"  # 리사이즈 보간법
    normalize_confidence: true # 신뢰도 정규화

# Stage 3 Production 데이터 전략 (Single → Combination 활용)
data_strategy:
  # Detection 커리큘럼 학습 (Single → Combination)
  detection_curriculum:
    enabled: true
    # Single 사전학습 단계
    single_pretrain_epochs: 10      # Single로 사전 학습
    # Combination 미세조정 단계
    combination_finetune_epochs: 40 # Combination으로 미세조정
    freeze_backbone_during_pretrain: false  # Backbone 동결 안함
    
    # Single 약라벨 생성 (Detection용)
    weak_label_generation:
      enabled: true
      strategy: "center_fixed_ratio"  # 중앙 고정 비율 박스
      center_ratio: 0.3              # 중앙 30% 영역
      loss_weight: 0.1               # 약라벨 loss 가중치 (낮게 설정)
    
  # 도메인 혼합 샘플링 (배치 수준 Single:Combination=3:1)
  domain_mixing:
    enabled: true
    # 배치 수준 혼합 비율 (요구사항: 3:1)
    batch_level_mixing: true     # 배치 수준 샘플링
    single_ratio: 0.75           # Single 데이터 75% (3:1 비율)
    combination_ratio: 0.25      # Combination 데이터 25%
    enforce_batch_ratio: true    # 배치마다 비율 강제
    
  # 합성 조합약 생성 (Copy-Paste 증강) - 램프 정책
  synthetic_combinations:
    enabled: true
    # 램프 전략: 시작 0.20 → warmup 5 epoch → 최대 0.30
    generation_probability_start: 0.2   # 시작 확률
    generation_probability_max: 0.3     # 최대 확률
    warmup_epochs: 5                    # warmup 기간
    adaptive_reduction: 0.05            # 성능 악화시 감소량
    max_pills_per_image: 5              # 이미지당 최대 5개 알약
    background_mixing: true             # 배경 혼합
    lighting_augmentation: true         # 조명 증강
    scale_variation: [0.8, 1.2]         # 크기 변화 범위
    
  # Hard Example Mining
  hard_example_mining:
    enabled: true
    difficulty_threshold: 0.3     # 어려운 샘플 임계값 (낮을수록 어려움)
    mining_frequency: 5          # 5 epoch마다 마이닝
    hard_sample_ratio: 0.2       # 전체의 20%를 어려운 샘플로
    
  # 클래스 균형 재가중
  class_balancing:
    enabled: true
    reweighting_strategy: "inverse_freq"  # 역빈도 가중
    smoothing_factor: 0.5        # frequency^-0.5 (제안값)
    min_weight: 0.1             # 최소 가중치
    max_weight: 10.0            # 최대 가중치
    
  # 약물 유사성 기반 샘플링
  similarity_sampling:
    enabled: true
    similarity_metric: "embedding"  # 임베딩 기반 유사성
    neighbor_sample_ratio: 0.1   # 유사한 클래스 10% 포함
    update_embeddings_frequency: 10  # 10 epoch마다 임베딩 업데이트
    
  # 분류 입력 일치화 (검출 크롭 규칙과 통일)
  classification_input_alignment:
    enabled: true
    # 검출 크롭 규칙과 동일하게 설정
    crop_margin: 0.125              # 마진 12.5% (10-15% 범위)
    resize_strategy: "minimal_distortion"  # 왜곡 최소 리사이즈
    maintain_aspect_ratio: true     # 종횡비 유지
    padding_if_needed: true         # 필요시 패딩 추가

# Stage 3 Production Validation 및 로깅 최적화
validation_optimization:
  # 경량 검증 모드 최적화
  lightweight_validation:
    enabled: true
    # 대표 구간 샘플링 (100 batch 기준)
    sampling_strategy: "representative"  # 대표 구간 샘플링
    class_stratified: true              # 클래스별 균등 샘플링
    cache_embeddings: true              # 임베딩 캐싱으로 속도 향상
    
  # 조기 종료 최적화 (통합 단일 설정 - 중복 방지)
  early_stopping:
    enabled: true
    patience: 10                # 10 epoch 대기 (과적합 방지)
    min_delta: 0.001           # 최소 성능 향상 (0.1%)
    monitor: "val_top1"        # 주 메트릭: Val Top-1 accuracy
    secondary_monitor: "val_f1_macro"  # 보조 메트릭: F1 macro
    mode: "max"                # 최대값 추적
    restore_best_weights: true  # 최적 가중치 복원
    # EARLY_STOP | source=unified | monitor=val_top1 | patience=10
    
  # 체크포인트 최적화
  checkpoint_optimization:
    save_frequency: "every_epoch"  # 매 에포크마다 저장
    keep_top_k: 3              # 상위 3개 체크포인트만 유지 (추가 제안)
    save_optimizer_state_last: true  # last에는 optimizer state 저장 (재개 보장)
    save_optimizer_state_best: false # best에는 저장 안함 (용량 절약)
    compress_checkpoints: false  # 압축하지 않음 (빠른 로딩)
    # CKPT_POLICY | last:save_optimizer_state=True | best:save_optimizer_state=False
    
  # 실시간 로깅 최적화
  realtime_logging:
    websocket_enabled: true     # WebSocket 실시간 로깅
    update_frequency: 10        # 10 step마다 업데이트
    metrics_buffer_size: 100    # 메트릭 버퍼 크기
    log_gpu_memory: true       # GPU 메모리 사용량 로깅
    log_cpu_usage: true        # CPU 사용량 로깅
    
  # 성능 프로파일링 (용량·시간 절감)
  performance_profiling:
    enabled: true
    # 정식 검증 시점에서만 기록 (3 epoch마다)
    profile_training: false           # 학습 프로파일링 비활성화
    profile_validation: "comprehensive_only"  # 정식 검증시에만
    trace_memory: true               # 메모리 추적
    export_chrome_trace: false       # Chrome tracing 비활성화 (용량 문제)
    # 시간 추적만 정식 검증시 기록
    time_tracking_comprehensive_only: true

# GPU 최적화 설정 (RTX 5080 16GB)
gpu_optimization:
  # Mixed Precision 설정
  mixed_precision:
    enabled: true
    policy: "mixed_float16"     # TF32 + FP16 혼합
    loss_scale: "dynamic"       # 동적 손실 스케일링
    
  # Memory 최적화
  memory_optimization:
    gradient_checkpointing: true  # 메모리 절약
    channels_last: true          # NHWC 포맷 (성능 향상)
    cuda_empty_cache_freq: 100  # 100 스텝마다 캐시 정리
    
  # Torch Compile 설정
  torch_compile:
    enabled: true
    mode: "reduce-overhead"     # 컴파일 시간 단축 (max-autotune → reduce-overhead)
    backend: "inductor"         # 기본 백엔드
    # TORCH_COMPILE | mode=reduce-overhead
    
  # CUDNN 최적화
  cudnn:
    benchmark: true             # 최적 알고리즘 자동 선택
    deterministic: false        # 성능 우선
    
  # TensorBoard 통합
  tensorboard:
    enabled: true
    log_dir: "artifacts/tensorboard"  # 통합 로그 디렉토리
    # TB_LOGDIR | artifacts/tensorboard

# 통합 Early Stopping (최종 단일 정의)
unified_early_stopping:
  enabled: true
  monitor: "val_top1"          # 주 모니터 메트릭
  patience: 10                 # 인내심
  min_delta: 0.001            # 최소 개선량
  mode: "max"                 # 최대화
  restore_best: true          # 최적 가중치 복원
  # 이 설정이 모든 early stopping을 오버라이드함

# 자가점검 시스템 설정
self_check:
  enabled: true
  run_at_start: true          # 시작 시 자동 실행
  
  # 점검 항목
  checks:
    - name: "CLASS_SET"
      check: "manifest_classes_match"  # manifest 클래스 수 일치 확인
      expected: 4020
      
    - name: "MANIFEST"
      check: "paths_exist"            # 경로 존재 확인
      paths:
        - "artifacts/stage3/manifest_train.remove.csv"
        - "artifacts/stage3/manifest_val.remove.csv"
        
    - name: "CKPT_POLICY"
      check: "checkpoint_settings"    # 체크포인트 설정 확인
      last_saves_optimizer: true
      best_saves_optimizer: false
      
    - name: "TORCH_COMPILE"
      check: "compile_mode"          # 컴파일 모드 확인
      expected: "reduce-overhead"
      
    - name: "EARLY_STOP"
      check: "early_stop_config"     # Early stopping 설정 확인
      source: "unified"
      monitor: "val_top1"
      
    - name: "TB_LOGDIR"
      check: "tensorboard_dir"       # TensorBoard 디렉토리 확인
      path: "artifacts/tensorboard"
      
    - name: "DATA_ISSUES"
      check: "data_quality"          # 데이터 품질 확인
      max_corrupt: 0
      max_val_only: 0
      combo_ratio_range: [0.04, 0.06]  # 현재 5% 수준
      
  # 실패 시 동작
  on_failure: "warn_and_continue"    # 경고 후 계속 (abort 대신)
  
  # 로그 출력
  log_format: "SELF_CHECK | {status} | {details}"