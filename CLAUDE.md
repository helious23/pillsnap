# CLAUDE.md

PillSnap ML í”„ë¡œì íŠ¸ì˜ Claude Code ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ê°œìš”, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, ì„¸ì…˜ ì´ˆê¸°í™” ì§€ì¹¨ì„ í†µí•©í•˜ì—¬ ì¼ê´€ë˜ê³  ìµœì í™”ëœ ìƒí˜¸ì‘ìš©ì„ ë³´ì¥í•©ë‹ˆë‹¤.

---

## ì„¸ì…˜ ì´ˆê¸°í™”

**ëª¨ë“  ì„¸ì…˜ ì‹œì‘ ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Claude Code í™˜ê²½ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”:**

```
/.claude/commands/initial-prompt.md
```

ì´ ëª…ë ¹ì–´ëŠ” ì •í™•í•˜ê³  íš¨ìœ¨ì ì¸ ì§€ì›ì„ ìœ„í•´ ì»¨í…ìŠ¤íŠ¸, í™˜ê²½ë³€ìˆ˜, í”„ë¡œì íŠ¸ë³„ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

**ëª©ì :**  
- PillSnap ML í”„ë¡œì íŠ¸ì˜ ê¸°ë³¸ ì§€ì‹ êµ¬ì¶•
- SSD ê¸°ë°˜ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© ê°•ì œ
- ëª¨ë“  ì‘ë‹µì˜ ê¸°ë³¸ ì–¸ì–´ë¥¼ í•œêµ­ì–´ë¡œ ì„¤ì •
- Two-Stage Conditional Pipeline ë¡œì§ ë“± í•µì‹¬ ì œì•½ì‚¬í•­ ë¡œë“œ
- **Stage 1-2 ê²€ì¦ ì™„ë£Œ** ìƒíƒœ ë° í˜„ì¬ ì§„í–‰ ìƒí™© ë°˜ì˜

ì´ˆê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šìœ¼ë©´ ì¼ê´€ì„± ì—†ëŠ” ì¶œë ¥ì´ë‚˜ í”„ë¡œì íŠ¸ ê·œì¹™ ìœ„ë°˜ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## í•µì‹¬ ê·œì¹™

- **ì–¸ì–´:** ë³„ë„ ì§€ì‹œê°€ ì—†ëŠ” í•œ ëª¨ë“  ì‘ë‹µì€ **í•œêµ­ì–´**ë¡œ ì‘ì„±
- **ê²½ë¡œ ì‚¬ìš©:** **Native Linux ì ˆëŒ€ ê²½ë¡œë§Œ ì‚¬ìš©** (`/home/max16/pillsnap_data/`). Windows ìŠ¤íƒ€ì¼ ê²½ë¡œ(ì˜ˆ: `C:\`) ê¸ˆì§€  
- **ë°ì´í„° ìœ„ì¹˜:** ëª¨ë“  ë°ì´í„°ì…‹ì€ í”„ë¡œì íŠ¸ì™€ ë¶„ë¦¬ëœ ì „ìš© ê²½ë¡œ ì‚¬ìš© (`/home/max16/pillsnap_data`)
- **Two-Stage Pipeline ê°•ì œ:** ì¡°ê±´ë¶€ íŒŒì´í”„ë¼ì¸ ë¡œì§ ì¤€ìˆ˜:
  - Single pills â†’ EfficientNetV2-S ì§ì ‘ ë¶„ë¥˜ (384px)
  - Combination pills â†’ YOLOv11m ê²€ì¶œ â†’ crop â†’ ë¶„ë¥˜ (640pxâ†’384px)  
- **API Security:** Always assume API key authentication and rate limiting are in place (100 requests/minute).  
- **Performance Targets:**  
  - Single pill accuracy: 92%  
  - Combination pill mAP@0.5: 0.85  
- **Hardware Optimization:**  
  - Use mixed precision (TF32) and channels_last memory format on RTX 5080 (16GB) GPUs.  
  - Enable `torch.compile(model, mode='max-autotune')` for training speedups.  
  - **Native Linux í™˜ê²½**: num_workers=8-12 (16 CPU ì½”ì–´ í™œìš©)
  - **2025-08-22 ì—…ë°ì´íŠ¸**: Native Ubuntu ì´ì „ ì™„ë£Œ, CPU ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™” í™œì„±í™”
  - Monitor VRAM usage to stay under 14GB.  

---

## Recommended Workflow

1. **Initialize session:** Run `/ .claude/commands/initial-prompts.md` first.  
2. **Environment setup:**  
   ```bash
   source /home/max16/pillsnap/.venv/bin/activate
   # Python 3.11.13, PyTorch 2.8.0+cu128, CUDA 12.8
   ```  
3. **Training (Manifest ê¸°ë°˜ - Stage 3-4 í‘œì¤€):**  
   ```bash
   # â­ IMPORTANT: Stage 3-4ëŠ” ë°˜ë“œì‹œ manifest ê¸°ë°˜ìœ¼ë¡œë§Œ ì§„í–‰
   # ë¬¼ë¦¬ì  ë°ì´í„° ë³µì‚¬ ì—†ì´ ì›ë³¸ì—ì„œ ì§ì ‘ ë¡œë”© (ìš©ëŸ‰ ì ˆì•½)
   
   # Stage 3 (100K ìƒ˜í”Œ, 1000 í´ë˜ìŠ¤)
   python -m src.training.train_classification_stage --manifest artifacts/stage3/manifest_train.csv --epochs 50 --batch-size 16
   
   # Stage 4 (500K ìƒ˜í”Œ, 4523 í´ë˜ìŠ¤) 
   python -m src.training.train_classification_stage --manifest artifacts/stage4/manifest_train.csv --epochs 100 --batch-size 8
   
   # Stage 1-2 (ê¸°ì¡´ ë°©ì‹)
   python -m src.train --cfg config.yaml
   python -m src.train --cfg config.yaml train.resume=last
   ```  
4. **Monitoring & Status Check:**  
   ```bash
   # ë¹ ë¥¸ ìƒíƒœ í™•ì¸ (ë³„ì¹­ ì‚¬ìš© - ì¶”ì²œ)
   status       # GPU, Stage ì™„ë£Œ í˜„í™©, ë””ìŠ¤í¬ ê³µê°„
   
   # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ë³„ì¹­ ì‚¬ìš© - ì¶”ì²œ) 
   monitor      # ìë™ Stage ê°ì§€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   mon2         # Stage 2 ì „ìš© ëª¨ë‹ˆí„°ë§
   monfast      # 1ì´ˆë§ˆë‹¤ ë¹ ë¥¸ ìƒˆë¡œê³ ì¹¨
   gpu          # nvidia-smi
   
   # ì „ì²´ ê²½ë¡œ (ë³„ì¹­ ë¯¸ì„¤ì •ì‹œ)
   ./scripts/monitoring/quick_status.sh
   ./scripts/monitoring/universal_training_monitor.sh --stage 2
   ```
5. **Testing & Evaluation:**  
   ```bash
   pytest tests/
   bash tests/evaluate_stage.sh 1  # Replace with appropriate stage number (1-4)
   python -m tests.stage_1_evaluator  # Replace with stage 1-4 as needed
   python -m tests.stage_progress_tracker
   ```  
6. **Inference:**  
   ```bash
   python -m src.infer --engine torch --model /mnt/data/exp/exp01/checkpoints/best.pt --inputs "/path/to/images/*.jpg" --batch 16
   python -m src.infer --engine onnx --model /mnt/data/exp/exp01/export/model.onnx --inputs "/path/to/images/*.jpg" --batch 16
   ```  
7. **API & Deployment:**  
   ```bash
   bash scripts/deployment/run_api.sh
   bash scripts/deployment/export_onnx.sh
   bash scripts/deployment/maintenance.sh
   ```  

---

## Project Overview

**PillSnap ML** is an AI-powered pharmaceutical pill identification system using a **Two-Stage Conditional Pipeline** designed to extract `edi_code` from pill images efficiently and accurately.

### Architecture

```
Input Image â†’ Auto Mode Detection
    â”œâ”€ Single Pills â†’ Direct Classification (EfficientNetV2-L)
    â””â”€ Combination Pills â†’ YOLOv11x Detection â†’ Crop â†’ Classification
```

### Model Components

- **Detection:** YOLOv11x (640px input) for combination pill detection  
- **Classification:** EfficientNetV2-L (384px input) for 5000-class `edi_code` identification  
- **Target Performance:**  
  - Single pill accuracy: 92%  
  - Combination pill mAP@0.5: 0.85  

### Critical Paths

| Purpose            | Native Linux (2025-08-22)                  |
|--------------------|--------------------------------------------|
| Codebase           | `/home/max16/pillsnap`                     |
| Dataset            | `/home/max16/pillsnap_data` (ë¶„ë¦¬ëœ ê²½ë¡œ)    |
| Virtual Environment | `/home/max16/pillsnap/.venv`               |
| Experiment Outputs | `/home/max16/pillsnap/exp`                 |

---

## Hardware Optimization Settings

### ğŸ–¥ï¸ **Current Environment (Native Linux)**
- **GPU:** RTX 5080 (16GB)  
  - Use mixed precision (TF32)  
  - Apply `channels_last` memory format  
  - Utilize `torch.compile(model, mode='max-autotune')` for training  
- **System RAM:** 128GB  
  - **Native Linux**: num_workers=8-12 (CPU ë©€í‹°í”„ë¡œì„¸ì‹± í™œì„±í™”)
  - WSL ì œì•½ ì™„ì „ í•´ê²°: ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ë°ì´í„° ë¡œë”©
- **Current Performance:**  
  - Stage 1: âœ… ì™„ë£Œ (74.9% ì •í™•ë„, 1ë¶„, Native Linux)
  - ë°ì´í„° êµ¬ì¡°: `/home/max16/pillsnap_data` ë¶„ë¦¬ ì™„ë£Œ
  - ì‹¬ë³¼ë¦­ ë§í¬: Windows SSD + Linux SSD í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì„±
  - Albumentations 2.0.8 ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ

### ğŸš€ **Planned Environment (Native Ubuntu on M.2 SSD)**
- **Storage:** Samsung 990 PRO 4TB M.2 SSD (7,450MB/s)
- **OS:** Native Ubuntu (WSL ì œì•½ ì™„ì „ í•´ê²°)
- **DataLoader:** num_workers=8-12 (16 CPU ì½”ì–´ í™œìš©)
- **Expected Performance:**  
  - ë°ì´í„° ë¡œë”© ì†ë„: 8-12ë°° í–¥ìƒ
  - Stage 3-4 ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìµœì í™”
  - Cloud tunnel API ì„œë¹„ìŠ¤ ì¤€ë¹„  

---

## Progressive Validation Stages (Manifest ê¸°ë°˜)

| Stage | Images  | Classes | Purpose              | Accuracy | Status | Method |
|-------|---------|---------|----------------------|----------|--------|---------|
| 1     | 5,000   | 50      | Pipeline verification | 74.9%    | âœ… **ì™„ë£Œ** (Native) | Config ê¸°ë°˜ |
| 2     | 25,000  | 250     | Performance baseline  | ì§„í–‰ì˜ˆì •  | ğŸ”„ ì¤€ë¹„ë¨ | Config ê¸°ë°˜ |
| 3     | 100,000 | 1,000   | Scalability test      | ëª©í‘œ85%  | ğŸ¯ **Manifest ê¸°ë°˜** | **ì›ë³¸ ì§ì ‘ë¡œë”©** |
| 4     | 500,000 | 4,523   | Production deployment | ëª©í‘œ92%  | ğŸ¯ **Manifest ê¸°ë°˜** | **ì›ë³¸ ì§ì ‘ë¡œë”©** |

### **â­ Stage 3-4 í•µì‹¬ ë³€ê²½ì‚¬í•­:**
- **ë¬¼ë¦¬ì  ë³µì‚¬ ì—†ìŒ**: 14.6GB â†’ 50MB (manifest CSV íŒŒì¼ë§Œ)
- **í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€**: Linux SSD + Windows SSD ì‹¬ë³¼ë¦­ ë§í¬ í™œìš©
- **Native Linux ìµœì í™”**: 128GB RAM + ë¹ ë¥¸ SSD I/Oë¡œ ì‹¤ì‹œê°„ ë¡œë”©
- **ìš©ëŸ‰ ì ˆì•½**: Stage 4ê¹Œì§€ ì´ ~73GB â†’ ~200MB ì ˆì•½

---

## ğŸ”„ Native Ubuntu Migration Plan

### **Migration Roadmap**
1. **Hardware Setup**
   - âœ… Install 4TB M.2 SSD in available slot
   - âœ… Install Native Ubuntu on M.2 SSD

2. **Data & Code Migration**
   - âœ… Windows SSD access (NTFS mount)
   - âœ… External HDD access (USB/SATA mount)
   - âœ… Copy datasets to Ubuntu M.2 SSD
   - âœ… Copy codebase to Ubuntu M.2 SSD

3. **Environment Setup**
   - âœ… Install Cursor & development tools
   - âœ… Setup Python virtual environment
   - âœ… Install PyTorch with CUDA support
   - âœ… Configure cloud tunnel for API service

4. **Performance Benefits**
   - ğŸ¯ **CPU Utilization**: 16 cores â†’ num_workers=8-12
   - ğŸ¯ **Storage Speed**: 7,450MB/s (vs current 3,500MB/s)
   - ğŸ¯ **WSL Constraints**: Completely eliminated
   - ğŸ¯ **Production Ready**: Cloud API deployment

### **Migration Priority**
- **Stage 1-2**: âœ… Current WSL sufficient (ì™„ë£Œë¨)
  - Stage 1: 83.2% (ëª©í‘œ 78% ì´ˆê³¼ë‹¬ì„±)
  - Stage 2: 83.1% (ëª©í‘œ 82% ì´ˆê³¼ë‹¬ì„±)
- **Stage 3-4**: Native Ubuntu essential (25ë§Œ-50ë§Œ ì´ë¯¸ì§€)
  - í˜„ì¬ SSD ìš©ëŸ‰: 459GB ì‚¬ìš© (Stage 3 ëŒ€ë¹„ ë¶€ì¡±)
  - M.2 SSD 4TB í™•ì¥ í•„ìˆ˜
- **Production API**: Cloud tunnel deployment required

---

## Project Structure

```
src/
â”œâ”€â”€ data.py               # Conditional two-stage data loaders
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector.py       # YOLOv11x wrapper
â”‚   â”œâ”€â”€ classifier.py     # EfficientNetV2-L implementation
â”‚   â””â”€â”€ pipeline.py       # Two-stage conditional pipeline
â”œâ”€â”€ train.py              # GPU-optimized training loops
â”œâ”€â”€ evaluate.py           # Performance metrics
â”œâ”€â”€ infer.py              # Inference pipeline
â””â”€â”€ api/                  # FastAPI serving
```

---

By following this guide and running the session initialization command every time, Claude Code will maintain accuracy, consistency, and compliance with the PillSnap ML project standards.
- === Quick Check: ë°ì´í„° ë£¨íŠ¸ëŠ” /mnt/data/pillsnap_dataset ì´ì–´ì•¼ í•¨ ===
# 0) í™˜ê²½ë³€ìˆ˜ë¡œ ê³ ì • (ì½”ë“œ ë³€ê²½ ì—†ì´ ìµœìš°ì„  ì ìš©)
export PILLSNAP_DATA_ROOT=/mnt/data/pillsnap_dataset

# 1) ì¡´ì¬/ê¶Œí•œ/ìƒ˜í”Œ ë‚˜ì—´
ls -al /mnt/data/pillsnap_dataset | head -n 20 || echo "ê²½ë¡œ ì—†ìŒ"

# 2) config ë¡œë”ê°€ í•´ë‹¹ ê²½ë¡œë¥¼ ì½ëŠ”ì§€ í™•ì¸
source $HOME/pillsnap/.venv/bin/activate && python - <<'PY'
import sys; sys.path.insert(0,'.')
import config
c = config.load_config()
print("data.root =", c.data.root)
assert c.data.root == "/mnt/data/pillsnap_dataset", "data.root mismatch"
print("âœ… ok")
PY