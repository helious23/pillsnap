# CLAUDE.md

PillSnap ML í”„ë¡œì íŠ¸ì˜ Claude Code ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ê°œìš”, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­, ì„¸ì…˜ ì´ˆê¸°í™” ì§€ì¹¨ì„ í†µí•©í•˜ì—¬ ì¼ê´€ë˜ê³  ìµœì í™”ëœ ìƒí˜¸ì‘ìš©ì„ ë³´ì¥í•©ë‹ˆë‹¤.

---

## ì„¸ì…˜ ì´ˆê¸°í™”

**ëª¨ë“  ì„¸ì…˜ ì‹œì‘ ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Claude Code í™˜ê²½ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”:**

```
/.claude/commands/initial-prompt.md
```

ì´ ëª…ë ¹ì–´ëŠ” ì •í™•í•˜ê³  íš¨ìœ¨ì ì¸ ì§€ì›ì„ ìœ„í•´ ì»¨í…ìŠ¤íŠ¸, í™˜ê²½ë³€ìˆ˜, í”„ë¡œì íŠ¸ë³„ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

**ëª©ì :**  
- PillSnap ML í”„ë¡œì íŠ¸ì˜ ê¸°ë³¸ ì§€ì‹ êµ¬ì¶•
- SSD ê¸°ë°˜ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© ê°•ì œ
- ëª¨ë“  ì‘ë‹µì˜ ê¸°ë³¸ ì–¸ì–´ë¥¼ í•œêµ­ì–´ë¡œ ì„¤ì •
- Two-Stage Conditional Pipeline ë¡œì§ ë“± í•µì‹¬ ì œì•½ì‚¬í•­ ë¡œë“œ
- **Stage 3 Two-Stage í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ** ìƒíƒœ ë° ì˜¬ë°”ë¥¸ Manifest ë°˜ì˜

ì´ˆê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šìœ¼ë©´ ì¼ê´€ì„± ì—†ëŠ” ì¶œë ¥ì´ë‚˜ í”„ë¡œì íŠ¸ ê·œì¹™ ìœ„ë°˜ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## í•µì‹¬ ê·œì¹™

- **ì–¸ì–´:** ë³„ë„ ì§€ì‹œê°€ ì—†ëŠ” í•œ ëª¨ë“  ì‘ë‹µì€ **í•œêµ­ì–´**ë¡œ ì‘ì„±
- **ê²½ë¡œ ì‚¬ìš©:** **Native Linux ì ˆëŒ€ ê²½ë¡œë§Œ ì‚¬ìš©** (`/home/max16/pillsnap_data/`). Windows ìŠ¤íƒ€ì¼ ê²½ë¡œ(ì˜ˆ: `C:\`) ê¸ˆì§€  
- **ë°ì´í„° ìœ„ì¹˜:** ëª¨ë“  ë°ì´í„°ì…‹ì€ í”„ë¡œì íŠ¸ì™€ ë¶„ë¦¬ëœ ì „ìš© ê²½ë¡œ ì‚¬ìš© (`/home/max16/pillsnap_data`)
- **Two-Stage Pipeline ê°•ì œ:** ì¡°ê±´ë¶€ íŒŒì´í”„ë¼ì¸ ë¡œì§ ì¤€ìˆ˜:
  - Single pills â†’ EfficientNetV2-S ì§ì ‘ ë¶„ë¥˜ (384px)
  - Combination pills â†’ YOLOv11m ê²€ì¶œ â†’ crop â†’ ë¶„ë¥˜ (640pxâ†’384px)  
- **API Security:** Always assume API key authentication and rate limiting are in place (100 requests/minute).  
- **Performance Targets:**  
  - Single pill accuracy: 92%  
  - Combination pill mAP@0.5: 0.85  
- **Hardware Optimization:**  
  - Use mixed precision (TF32) and channels_last memory format on RTX 5080 (16GB) GPUs.  
  - Enable `torch.compile(model, mode='max-autotune')` for training speedups.  
  - **Native Linux í™˜ê²½**: num_workers=8-12 (16 CPU ì½”ì–´ í™œìš©)
  - **2025-08-22 ì—…ë°ì´íŠ¸**: Native Ubuntu ì´ì „ ì™„ë£Œ, CPU ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™” í™œì„±í™”
  - Monitor VRAM usage to stay under 14GB.  

---

## Recommended Workflow

1. **Initialize session:** Run `/ .claude/commands/initial-prompts.md` first.  
2. **Environment setup:**  
   ```bash
   source /home/max16/pillsnap/.venv/bin/activate
   # Python 3.11.13, PyTorch 2.8.0+cu128, CUDA 12.8
   ```  
3. **Training (Manifest ê¸°ë°˜ - Stage 3-4 í‘œì¤€):**  
   ```bash
   # â­ IMPORTANT: Stage 3-4ëŠ” ë°˜ë“œì‹œ manifest ê¸°ë°˜ìœ¼ë¡œë§Œ ì§„í–‰
   # ë¬¼ë¦¬ì  ë°ì´í„° ë³µì‚¬ ì—†ì´ ì›ë³¸ì—ì„œ ì§ì ‘ ë¡œë”© (ìš©ëŸ‰ ì ˆì•½)
   
   # Stage 3 ì™„ë£Œë¨ (44.1% Classification + 25.0% Detection) - Resume ê¸°ëŠ¥ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥
   python -m src.training.train_stage3_two_stage \
     --resume /home/max16/pillsnap_data/exp/exp01/checkpoints/stage3_classification_best.pt \
     --epochs 50 --lr-classifier 1e-4 --lr-detector 5e-3 --batch-size 12
   
   # Stage 4 ì¤€ë¹„ ì¤‘ (500K ìƒ˜í”Œ, 4523 í´ë˜ìŠ¤) 
   python -m src.training.train_classification_stage --manifest artifacts/stage4/manifest_train.csv --epochs 100 --batch-size 8
   
   # Stage 1-2 (ì™„ë£Œë¨)
   python -m src.train --cfg config.yaml
   python -m src.train --cfg config.yaml train.resume=last
   ```  
4. **Monitoring & Status Check:**  
   ```bash
   # ë¹ ë¥¸ ìƒíƒœ í™•ì¸ (ë³„ì¹­ ì‚¬ìš© - ì¶”ì²œ)
   status       # GPU, Stage ì™„ë£Œ í˜„í™©, ë””ìŠ¤í¬ ê³µê°„
   
   # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (ë³„ì¹­ ì‚¬ìš© - ì¶”ì²œ) 
   monitor      # ìë™ Stage ê°ì§€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   mon2         # Stage 2 ì „ìš© ëª¨ë‹ˆí„°ë§
   monfast      # 1ì´ˆë§ˆë‹¤ ë¹ ë¥¸ ìƒˆë¡œê³ ì¹¨
   gpu          # nvidia-smi
   
   # ì „ì²´ ê²½ë¡œ (ë³„ì¹­ ë¯¸ì„¤ì •ì‹œ)
   ./scripts/monitoring/quick_status.sh
   ./scripts/monitoring/universal_training_monitor.sh --stage 2
   ```
5. **Testing & Evaluation:**  
   ```bash
   pytest tests/
   bash tests/evaluate_stage.sh 1  # Replace with appropriate stage number (1-4)
   python -m tests.stage_1_evaluator  # Replace with stage 1-4 as needed
   python -m tests.stage_progress_tracker
   ```  
6. **Inference:**  
   ```bash
   python -m src.infer --engine torch --model /mnt/data/exp/exp01/checkpoints/best.pt --inputs "/path/to/images/*.jpg" --batch 16
   python -m src.infer --engine onnx --model /mnt/data/exp/exp01/export/model.onnx --inputs "/path/to/images/*.jpg" --batch 16
   ```  
7. **API & Deployment:**  
   ```bash
   bash scripts/deployment/run_api.sh
   bash scripts/deployment/export_onnx.sh
   bash scripts/deployment/maintenance.sh
   ```  

---

## Project Overview

**PillSnap ML** is an AI-powered pharmaceutical pill identification system using a **Two-Stage Conditional Pipeline** designed to extract `edi_code` from pill images efficiently and accurately.

### Architecture

```
Input Image â†’ Auto Mode Detection
    â”œâ”€ Single Pills â†’ Direct Classification (EfficientNetV2-L)
    â””â”€ Combination Pills â†’ YOLOv11x Detection â†’ Crop â†’ Classification
```

### Model Components

- **Detection:** YOLOv11x (640px input) for combination pill detection  
- **Classification:** EfficientNetV2-L (384px input) for 5000-class `edi_code` identification  
- **Target Performance:**  
  - Single pill accuracy: 92%  
  - Combination pill mAP@0.5: 0.85  

### Critical Paths

| Purpose            | Native Linux (2025-08-22)                  |
|--------------------|--------------------------------------------|
| Codebase           | `/home/max16/pillsnap`                     |
| Dataset            | `/home/max16/pillsnap_data` (ë¶„ë¦¬ëœ ê²½ë¡œ)    |
| Virtual Environment | `/home/max16/pillsnap/.venv`               |
| Experiment Outputs | `/home/max16/pillsnap/exp`                 |

---

## Hardware Optimization Settings

### ğŸ–¥ï¸ **Current Environment (Native Linux)**
- **GPU:** RTX 5080 (16GB)  
  - Use mixed precision (TF32)  
  - Apply `channels_last` memory format  
  - Utilize `torch.compile(model, mode='max-autotune')` for training  
- **System RAM:** 128GB  
  - **Native Linux**: num_workers=8-12 (CPU ë©€í‹°í”„ë¡œì„¸ì‹± í™œì„±í™”)
  - WSL ì œì•½ ì™„ì „ í•´ê²°: ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ë°ì´í„° ë¡œë”©
- **Current Performance:**  
  - Stage 1: âœ… ì™„ë£Œ (74.9% ì •í™•ë„, 1ë¶„, Native Linux)
  - Stage 2: âœ… ì™„ë£Œ (83.1% ì •í™•ë„, Native Linux)
  - Stage 3: âœ… **í•™ìŠµ ì™„ë£Œ** (44.1% Classification + 25.0% Detection, 2025-08-23)
    - **Two-Stage Pipeline**: EfficientNetV2-L + YOLOv11m í†µí•© í•™ìŠµ ì™„ë£Œ
    - **Progressive Resize**: 128pxâ†’384px ì ì§„ì  í•´ìƒë„ ì¦ê°€ ì‹œìŠ¤í…œ
    - **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: WebSocket ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ (http://localhost:8888)
    - **OOM ë°©ì§€**: ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì • ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    - **Resume ê¸°ëŠ¥**: í•˜ì´í¼íŒŒë¼ë¯¸í„° override + Top-5 accuracy ì¶”ì 
    - **118ê°œ í…ŒìŠ¤íŠ¸**: ëª¨ë“  í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ
    - **Multi-object Detection**: JSONâ†’YOLO ë³€í™˜ 99.644% ì„±ê³µë¥ 
  - Stage 4: ğŸ¯ **ëŒ€ê¸° ì¤‘** (ìµœì¢… í”„ë¡œë•ì…˜ í•™ìŠµ)
  - ë°ì´í„° êµ¬ì¡°: Manifest ê¸°ë°˜ ë¡œë”©ìœ¼ë¡œ 99.7% ì €ì¥ê³µê°„ ì ˆì•½
  - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: WebSocket ê¸°ë°˜ í•™ìŠµ ìƒíƒœ ì¶”ì  ì‹œìŠ¤í…œ (KST í‘œì¤€ì‹œ ì ìš©)
  - torch.compile ìµœì í™” ì™„ë£Œ (EfficientNetV2-L + YOLOv11x)
  - **Native Linux ìµœì í™”**: 128GB RAM + RTX 5080 16GB ì™„ì „ í™œìš©

### ğŸš€ **Planned Environment (Native Ubuntu on M.2 SSD)**
- **Storage:** Samsung 990 PRO 4TB M.2 SSD (7,450MB/s)
- **OS:** Native Ubuntu (WSL ì œì•½ ì™„ì „ í•´ê²°)
- **DataLoader:** num_workers=8-12 (16 CPU ì½”ì–´ í™œìš©)
- **Expected Performance:**  
  - ë°ì´í„° ë¡œë”© ì†ë„: 8-12ë°° í–¥ìƒ
  - Stage 3-4 ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìµœì í™”
  - Cloud tunnel API ì„œë¹„ìŠ¤ ì¤€ë¹„  

---

## Progressive Validation Stages (Manifest ê¸°ë°˜)

| Stage | Images  | Classes | Purpose              | Result | Status | Method |
|-------|---------|---------|----------------------|----------|--------|---------|
| 1     | 5,000   | 50      | Pipeline verification | 74.9%    | âœ… **ì™„ë£Œ** (Native) | Config ê¸°ë°˜ |
| 2     | 25,000  | 250     | Performance baseline  | 83.1%    | âœ… **ì™„ë£Œ** (Native) | Config ê¸°ë°˜ |
| 3     | 100,000 | 1,000   | Scalability test      | 44.1% + 25.0% mAP | âœ… **ì™„ë£Œ** | **Two-Stage Pipeline** |
| 4     | 500,000 | 4,523   | Production deployment | ëª©í‘œ92%  | ğŸ¯ **ëŒ€ê¸° ì¤‘** | **Two-Stage Pipeline** |

### **â­ Stage 3-4 í•µì‹¬ ë³€ê²½ì‚¬í•­:**
- **ë¬¼ë¦¬ì  ë³µì‚¬ ì—†ìŒ**: 14.6GB â†’ 50MB (manifest CSV íŒŒì¼ë§Œ)
- **í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€**: Linux SSD + Windows SSD ì‹¬ë³¼ë¦­ ë§í¬ í™œìš©
- **Native Linux ìµœì í™”**: 128GB RAM + ë¹ ë¥¸ SSD I/Oë¡œ ì‹¤ì‹œê°„ ë¡œë”©
- **ìš©ëŸ‰ ì ˆì•½**: Stage 4ê¹Œì§€ ì´ ~73GB â†’ ~200MB ì ˆì•½
- **Progressive Resize**: ë™ì  í•´ìƒë„ ì¡°ì •ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ìµœì í™”
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: WebSocket + ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°

---

## ğŸ”„ Native Ubuntu Migration Plan

### **Migration Roadmap**
1. **Hardware Setup**
   - âœ… Install 4TB M.2 SSD in available slot
   - âœ… Install Native Ubuntu on M.2 SSD

2. **Data & Code Migration**
   - âœ… Windows SSD access (NTFS mount)
   - âœ… External HDD access (USB/SATA mount)
   - âœ… Copy datasets to Ubuntu M.2 SSD
   - âœ… Copy codebase to Ubuntu M.2 SSD

3. **Environment Setup**
   - âœ… Install Cursor & development tools
   - âœ… Setup Python virtual environment
   - âœ… Install PyTorch with CUDA support
   - âœ… Configure cloud tunnel for API service

4. **Performance Benefits**
   - ğŸ¯ **CPU Utilization**: 16 cores â†’ num_workers=8-12
   - ğŸ¯ **Storage Speed**: 7,450MB/s (vs current 3,500MB/s)
   - ğŸ¯ **WSL Constraints**: Completely eliminated
   - ğŸ¯ **Production Ready**: Cloud API deployment

### **Migration Priority**
- **Stage 1-2**: âœ… Current WSL sufficient (ì™„ë£Œë¨)
  - Stage 1: 83.2% (ëª©í‘œ 78% ì´ˆê³¼ë‹¬ì„±)
  - Stage 2: 83.1% (ëª©í‘œ 82% ì´ˆê³¼ë‹¬ì„±)
- **Stage 3-4**: Native Ubuntu essential (25ë§Œ-50ë§Œ ì´ë¯¸ì§€)
  - í˜„ì¬ SSD ìš©ëŸ‰: 459GB ì‚¬ìš© (Stage 3 ëŒ€ë¹„ ë¶€ì¡±)
  - M.2 SSD 4TB í™•ì¥ í•„ìˆ˜
- **Production API**: Cloud tunnel deployment required

---

## Project Structure

```
src/
â”œâ”€â”€ data.py               # Conditional two-stage data loaders
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector.py       # YOLOv11x wrapper
â”‚   â”œâ”€â”€ classifier.py     # EfficientNetV2-L implementation
â”‚   â””â”€â”€ pipeline.py       # Two-stage conditional pipeline
â”œâ”€â”€ train.py              # GPU-optimized training loops
â”œâ”€â”€ evaluate.py           # Performance metrics
â”œâ”€â”€ infer.py              # Inference pipeline
â””â”€â”€ api/                  # FastAPI serving
```

---

---

## ğŸ“ **ìµœê·¼ ì—…ë°ì´íŠ¸ (2025-08-23)**

### âœ… **Stage 3 Two-Stage í•™ìŠµ ì™„ë£Œ**
- **Classification ì •í™•ë„**: 44.1% (1,000ê°œ í´ë˜ìŠ¤ ê¸°ì¤€)
- **Detection mAP@0.5**: 25.0% (Multi-object detection)
- **Progressive Resize**: 128pxâ†’384px ì ì§„ì  í•´ìƒë„ ì¦ê°€
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: WebSocket ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ (http://localhost:8888)
- **OOM ë°©ì§€**: ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì • ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
- **Resume ê¸°ëŠ¥**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ ì§€ì›
- **118ê°œ í…ŒìŠ¤íŠ¸**: ëª¨ë“  í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ

### âœ… **Multi-object Detection ì™„ì„±**
- **JSONâ†’YOLO ë³€í™˜**: 12,025ê°œ ì´ë¯¸ì§€ 99.644% ì„±ê³µë¥ 
- **ì‹¤ì œ bounding box**: í‰ê·  3.6ê°œ ê°ì²´/ì´ë¯¸ì§€ ì •í™•í•œ annotation
- **YOLO txt ë¼ë²¨**: 11,875ê°œ íŒŒì¼ ìƒì„± ì™„ë£Œ
- **Detection DataLoader**: Manifest ê¸°ë°˜ 640px ë¡œë”© ìµœì í™”
- **YOLOv11m ëª¨ë¸**: torch.compile ìµœì í™” ì ìš©

### ğŸš€ **Stage 4 ì¤€ë¹„ ì™„ë£Œ**
ëª¨ë“  ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì–´ 500K ìƒ˜í”Œ ëŒ€ê·œëª¨ í•™ìŠµì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤:
```bash
python -m src.training.train_stage3_two_stage \
  --manifest artifacts/stage4/manifest_train.csv \
  --epochs 100 --batch-size 8
```

### ğŸ¯ **Stage 4 ëª©í‘œ (500K ìƒ˜í”Œ)**
- Classification Accuracy: â‰¥ 92% (Production ëª©í‘œ)
- Detection mAP@0.5: â‰¥ 85% (ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ê³¼)
- Pipeline ì¶”ë¡ ì‹œê°„: â‰¤ 50ms (ONNX ìµœì í™”)
- ì™„ì „ ìë™í™”: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ + OOM ë°©ì§€

---

## ğŸ“ **ì™„ì„±ëœ ì‹œìŠ¤í…œ ëª©ë¡ (2025-08-23)**

### âœ… **Progressive Resize ì‹œìŠ¤í…œ**
- **ë™ì  í•´ìƒë„**: 128pxâ†’384px ì ì§„ì  ì¦ê°€
- **GPU ë©”ëª¨ë¦¬ ìµœì í™”**: ì´ˆê¸° ë‚®ì€ í•´ìƒë„ë¡œ OOM ë°©ì§€
- **ì„±ëŠ¥ í–¥ìƒ**: ì ì§„ì  fine-tuningìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± ì¦ëŒ€
- **ìë™í™”**: epochë³„ í•´ìƒë„ ìë™ ì¡°ì •

### âœ… **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
- **WebSocket ëŒ€ì‹œë³´ë“œ**: http://localhost:8888 ì‹¤ì‹œê°„ ë¡œê·¸
- **KST í‘œì¤€ì‹œ**: í•œêµ­ ì‹œê°„ëŒ€ í‘œì‹œ
- **ìë™ ê°ì§€**: Stage 1-4 í•™ìŠµ ìƒíƒœ ìë™ ì¶”ì 
- **ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ í„°ë¯¸ë„ ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë°

### âœ… **OOM ë°©ì§€ & ìµœì í™” ì‹œìŠ¤í…œ**
- **ë™ì  ë°°ì¹˜ í¬ê¸°**: VRAM ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ìë™ ì¡°ì •
- **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ì‹œìŠ¤í…œ
- **torch.compile**: EfficientNetV2-L + YOLOv11m ìµœì í™”
- **Mixed Precision**: TF32 í™œìš© ì„±ëŠ¥ í–¥ìƒ

---

By following this guide and running the session initialization command every time, Claude Code will maintain accuracy, consistency, and compliance with the PillSnap ML project standards.