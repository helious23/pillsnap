# PillSnap ML Environment Configuration
# Copy this file to .env and update values for your environment

# =============================================================================
# API Configuration
# =============================================================================

# API Key for authentication (generate with: openssl rand -hex 32)
API_KEY=CHANGE_ME_STRONG_RANDOM_API_KEY_HERE

# Logging level
LOG_LEVEL=info

# =============================================================================
# Model Paths (Optional - will use config.yaml defaults if not specified)
# =============================================================================

# Detection model path (YOLO)
DETECTION_MODEL_PATH=/mnt/data/exp/exp01/export/latest_detection.onnx

# Classification model path (EfficientNet)  
CLASSIFICATION_MODEL_PATH=/mnt/data/exp/exp01/export/latest_classification.onnx

# Drug metadata mapping file
DRUG_METADATA_PATH=/mnt/data/pillsnap_dataset/processed/edi_mapping.json

# =============================================================================
# API Server Configuration
# =============================================================================

# CORS allowed origins (comma-separated)
CORS_ALLOW_ORIGINS=http://localhost:3000,https://pillsnap.co.kr,https://api.pillsnap.co.kr

# Maximum upload size in MB
MAX_UPLOAD_MB=20

# Allowed file extensions (comma-separated)
ALLOWED_EXTS=.jpg,.jpeg,.png,.bmp,.webp

# Rate limiting (requests per minute per API key)
RATE_LIMIT_PER_MIN=60

# =============================================================================
# PyTorch & ONNX Configuration  
# =============================================================================

# CUDA device ID (0 for first GPU)
CUDA_DEVICE_ID=0

# Enable torch.compile (true/false)
TORCH_COMPILE_ENABLED=true

# torch.compile mode for inference (default/reduce-overhead/max-autotune)
TORCH_COMPILE_MODE=max-autotune

# ONNX Runtime providers (comma-separated priority order)
ONNX_PROVIDERS=TensorrtExecutionProvider,CUDAExecutionProvider,CPUExecutionProvider

# TensorRT engine cache directory
TENSORRT_CACHE_DIR=/mnt/data/exp/exp01/trt_cache

# =============================================================================
# Cloudflare Tunnel (Optional)
# =============================================================================

# Cloudflare Tunnel ID (if using permanent tunnel)
TUNNEL_ID=44d30bbb-1cee-4150-b957-a4cdeab985e5

# =============================================================================
# Data Processing Configuration
# =============================================================================

# ZIP integrity level for dataset loading (skip/quick/full)
ZIP_INTEGRITY_LEVEL=quick

# Enable streaming data loading (true/false)
STREAM_LOADING=true

# Maximum memory for ZIP processing (GB)
MAX_ZIP_MEMORY_GB=64