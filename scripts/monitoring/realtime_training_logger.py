#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ í•™ìŠµ ë¡œê·¸ ìº¡ì²˜ ì‹œìŠ¤í…œ

- tee ëª…ë ¹ì–´ë¡œ stdoutì„ íŒŒì¼ê³¼ í™”ë©´ì— ë™ì‹œ ì¶œë ¥
- WebSocketìœ¼ë¡œ ë¸Œë¼ìš°ì €ì— ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
- ë¡œê·¸ íŒŒì¼ì— ì˜êµ¬ ì €ì¥
- ì²˜ìŒë¶€í„° ëê¹Œì§€ ëª¨ë“  ì¶œë ¥ ìº¡ì²˜
"""

import os
import sys
import time
import asyncio
import subprocess
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Optional, List
import json

# FastAPI ë° WebSocket
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
import uvicorn
import asyncio
from pathlib import Path

class RealtimeTrainingLogger:
    """ì‹¤ì‹œê°„ í•™ìŠµ ë¡œê·¸ ìº¡ì²˜ ë° ìŠ¤íŠ¸ë¦¬ë°"""
    
    def __init__(self, log_file: Optional[str] = None):
        # ì‹¤ì œ Python í•™ìŠµ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ìë™ ê°ì§€
        if log_file is None:
            log_file = self._detect_latest_log_file()
        
        self.log_file = log_file
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {self.log_file}")
        
        # bash_23 ì¶œë ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì¼ì— ê¸°ë¡í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        self._start_bash23_capture()
        self.connected_clients: List[WebSocket] = []
        self.training_process: Optional[subprocess.Popen] = None
        self.last_position = 0  # íŒŒì¼ ì½ê¸° ìœ„ì¹˜ ì¶”ì 
    
    def _detect_latest_log_file(self) -> str:
        """ì‹¤ì œ Python í•™ìŠµ ë¡œê·¸ íŒŒì¼ ìë™ ê°ì§€"""
        import glob
        import os
        from datetime import datetime
        
        # ê°€ëŠ¥í•œ ë¡œê·¸ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ë³„)
        log_patterns = [
            # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ íŒ¨í„´ë“¤ (ì‹¤ì œ core.pyì—ì„œ ìƒì„±ë˜ëŠ” ê²½ë¡œ)
            "/home/max16/pillsnap_data/exp/exp01/logs/__main___*.log",
            "/home/max16/pillsnap_data/exp/exp01/logs/src.training.train_stage3_two_stage_*.log", 
            "/home/max16/pillsnap_data/exp/exp01/logs/*train*_*.log",
            "/home/max16/pillsnap_data/exp/*/logs/__main___*.log",
            "/home/max16/pillsnap_data/exp/*/logs/*train*_*.log",
            # ë°±ì—… ê²½ë¡œ
            "/tmp/pillsnap_training_*.log",
            "/tmp/stage3_training.log"
        ]
        
        latest_file = None
        latest_time = 0
        
        for pattern in log_patterns:
            files = glob.glob(pattern)
            for file in files:
                try:
                    mtime = os.path.getmtime(file)
                    if mtime > latest_time and os.path.getsize(file) > 0:  # ë¹ˆ íŒŒì¼ ì œì™¸
                        latest_time = mtime
                        latest_file = file
                except (OSError, IOError):
                    continue
        
        if latest_file:
            print(f"âœ… ìµœì‹  ë¡œê·¸ íŒŒì¼ ë°œê²¬: {latest_file}")
            return latest_file
        else:
            # ê¸°ë³¸ ë¡œê·¸ íŒŒì¼ ìƒì„±
            default_log = f"/tmp/pillsnap_training_{datetime.now().strftime('%Y%m%d')}.log"
            print(f"âš ï¸ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {default_log}")
            return default_log
        
    def normalize_value(self, value, value_type="percent"):
        """ê°’ì„ ì •ê·œí™”í•˜ê³  í¬ë§·íŒ…
        
        Args:
            value: ì›ë³¸ ê°’ (string ë˜ëŠ” float)
            value_type: "percent" (0-1 -> 0-100%), "ms" (ë°€ë¦¬ì´ˆ), "raw" (ê·¸ëŒ€ë¡œ)
        
        Returns:
            í¬ë§·íŒ…ëœ ë¬¸ìì—´
        """
        if value is None or value == "N/A":
            return "N/A"
        
        try:
            num_val = float(value)
            
            if value_type == "percent":
                # 0-1 ë²”ìœ„ë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                if 0 <= num_val <= 1:
                    return f"{num_val * 100:.1f}%"
                else:
                    # ì´ë¯¸ í¼ì„¼íŠ¸ì¸ ê²½ìš°
                    return f"{num_val:.1f}%"
            elif value_type == "ms":
                return f"{num_val:.1f}ms"
            elif value_type == "seconds":
                return f"{num_val:.1f}s"
            elif value_type == "mb":
                return f"{int(num_val)}MB"
            elif value_type == "ratio":
                return f"1:{num_val:.2f}"
            else:  # raw
                if num_val.is_integer():
                    return str(int(num_val))
                else:
                    return f"{num_val:.4f}"
        except (ValueError, TypeError):
            return str(value)
    
    def _start_bash23_capture(self):
        """bash_23ì˜ ì‹¤ì œ stdoutì„ ìº¡ì²˜í•´ì„œ ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        import threading
        import asyncio
        
        # í˜„ì¬ ìƒíƒœ ì¶”ì  ë³€ìˆ˜ë“¤ (ê¸°ì¡´)
        self.current_epoch = 3
        self.current_batch = "ì§„í–‰ì¤‘"  
        self.current_loss = "ê°ì†Œì¤‘"
        self.classification_acc = "N/A"
        self.detection_map = "N/A" 
        self.epoch_time = "N/A"
        
        # Phase 1 ìƒˆë¡œìš´ ì§€í‘œ ì¶”ì  ë³€ìˆ˜ë“¤
        # Overall ì§€í‘œ
        self.top1_overall = "N/A"
        self.top5_overall = "N/A"
        self.macro_f1_overall = "N/A"
        
        # ë„ë©”ì¸ë³„ ë¶„ë¦¬ ì§€í‘œ
        self.top1_single = "N/A"
        self.top5_single = "N/A"
        self.macro_f1_single = "N/A"
        self.top1_combo = "N/A"
        self.top5_combo = "N/A"
        self.macro_f1_combo = "N/A"
        
        # Detection mAP ë„ë©”ì¸ë³„
        self.det_map_single = "N/A"
        self.det_map_combo = "N/A"
        
        # ë ˆì´í„´ì‹œ ë¶„í•´ (ms)
        self.latency_ms = {
            "det": "N/A",
            "crop": "N/A",
            "cls": "N/A",
            "total": "N/A"
        }
        
        # ì„ íƒëœ Confidence
        self.selected_confidence = {
            "single": "N/A",
            "combo": "N/A"
        }
        
        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³€ìˆ˜ ìœ ì§€
        self.top1_accuracy = "N/A"  # overallê³¼ ë™ì¼
        self.top5_accuracy = "N/A"  # overallê³¼ ë™ì¼
        self.macro_f1 = "N/A"  # overallê³¼ ë™ì¼
        self.single_domain_acc = "N/A"
        self.combination_domain_acc = "N/A"
        self.det_latency = "N/A"
        self.crop_latency = "N/A"
        self.cls_latency = "N/A"
        self.total_latency = "N/A"
        self.det_confidence = "N/A"
        self.cls_confidence = "N/A"
        self.oom_old_batch = "N/A"
        self.oom_new_batch = "N/A"
        self.oom_old_accum = "N/A"
        self.oom_new_accum = "N/A"
        self.det_steps = "N/A"
        self.cls_steps = "N/A"
        self.interleave_ratio = "N/A"
        
        # ìƒˆë¡œìš´ í™•ì¥ ë³€ìˆ˜ë“¤ ì´ˆê¸°í™”
        self.single_top1 = "N/A"
        self.single_top5 = "N/A"
        self.single_macro_f1 = "N/A"
        self.combo_top1 = "N/A"
        self.combo_top5 = "N/A"
        self.combo_macro_f1 = "N/A"
        self.det_recall = "N/A"
        self.det_precision = "N/A"
        self.selected_conf_single = "N/A"
        self.selected_conf_combo = "N/A"
        self.latency_p50_det = "N/A"
        self.latency_p95_det = "N/A"
        self.latency_p99_det = "N/A"
        self.latency_p50_crop = "N/A"
        self.latency_p95_crop = "N/A"
        self.latency_p99_crop = "N/A"
        self.latency_p50_cls = "N/A"
        self.latency_p95_cls = "N/A"
        self.latency_p99_cls = "N/A"
        self.latency_p50_total = "N/A"
        self.latency_p95_total = "N/A"
        self.latency_p99_total = "N/A"
        self.vram_peak_mb = "N/A"
        self.grad_norm_after = "N/A"
        
        # ë””ë°”ìš´ìŠ¤ë¥¼ ìœ„í•œ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
        self.last_broadcast_time = 0
        self.pending_broadcast = False
        
        # í•™ìŠµ ì„¤ì • ì •ë³´
        self.total_epochs = 50  # ê¸°ë³¸ê°’
        self.total_batches = 5093  # ê¸°ë³¸ê°’
        
        # ë ˆì´í„´ì‹œ í¼ì„¼íƒ€ì¼ (p50/p95/p99)
        self.latency_p50_det = "N/A"
        self.latency_p95_det = "N/A"
        self.latency_p99_det = "N/A"
        self.latency_p50_crop = "N/A"
        self.latency_p95_crop = "N/A"
        self.latency_p99_crop = "N/A"
        self.latency_p50_cls = "N/A"
        self.latency_p95_cls = "N/A"
        self.latency_p99_cls = "N/A"
        self.latency_p50_total = "N/A"
        self.latency_p95_total = "N/A"
        self.latency_p99_total = "N/A"
        
        # VRAM Peak / Grad-Norm
        self.vram_peak_mb = "N/A"
        self.grad_norm_after = "N/A"
        
        # ë™ì  í•™ìŠµ ì„¤ì • ì¶”ì 
        self.total_epochs = 50  # ê¸°ë³¸ê°’ (Stage 3)
        self.total_batches = 5093  # ê¸°ë³¸ê°’
        
        def capture_bash23():
            """bash_23ì˜ ì‹¤ì œ stdoutì„ ìº¡ì²˜í•˜ê³  ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
            import time
            import subprocess
            import re
            
            # í•™ìŠµ ì‹œì‘ ì „ ì´ˆê¸°ê°’
            self.current_epoch = 1
            self.current_batch = "0/0"
            self.current_loss = "N/A"
            self.classification_acc = "N/A"
            self.detection_map = "N/A"
            self.epoch_time = "N/A"
            
            while True:
                try:
                    # BashOutput APIë¥¼ í†µí•´ bash_23 ì‹¤ì œ ì¶œë ¥ ê°€ì ¸ì˜¤ê¸°
                    result = subprocess.run([
                        "python3", "-c", 
                        """
import subprocess
import sys
try:
    result = subprocess.run(['tail', '-f', '-n', '20'], 
                          stdin=subprocess.PIPE, 
                          stdout=subprocess.PIPE, 
                          stderr=subprocess.PIPE,
                          text=True, timeout=2,
                          input='')
    print(result.stdout)
except Exception as e:
    # bash_23 í”„ë¡œì„¸ìŠ¤ ì§ì ‘ í™•ì¸
    try:
        import os
        bash23_pid = subprocess.check_output(['pgrep', '-f', 'train_stage3_two_stage'], text=True).strip()
        if bash23_pid:
            print(f'bash_23 PID: {bash23_pid}')
    except:
        pass
"""
                    ], capture_output=True, text=True, timeout=3)
                    
                    # bash_23 ì‹¤ì œ ì¶œë ¥ì„ BashOutput APIë¡œ ê°€ì ¸ì˜¤ê¸°  
                    try:
                        import subprocess
                        import re
                        
                        # ì‹¤ì œ í•™ìŠµ ë¡œê·¸ íŒŒì¼ì—ì„œ ìµœì‹  ë°ì´í„° ì½ê¸° (ìë™ ê°ì§€ëœ ê²½ë¡œ ì‚¬ìš©)
                        bash23_result = subprocess.run([
                            'tail', '-n', '20', self.log_file
                        ], capture_output=True, text=True, timeout=3)
                        
                        # KST ì‹œê°„ëŒ€ë¡œ ë¡œê·¸ ì‹œê°„ í‘œì‹œ (ìˆ˜ì •ë¨)
                        kst = timezone(timedelta(hours=9))
                        current_time = datetime.now(kst).strftime('%H:%M:%S')
                        log_line = None
                        
                        if bash23_result.returncode == 0 and bash23_result.stdout:
                            lines = bash23_result.stdout.strip().split('\n')
                            for line in lines:
                                if not line.strip():
                                    continue
                                    
                                # === í™•ì¥ëœ íŒŒì„œ: Phase 1 ë¡œê¹… í¬ë§· ëŒ€ì‘ ===
                                
                                # 1) ê¸°ì¡´ Epoch X | Batch Y/5093 | Loss: Z íŒ¨í„´ íŒŒì‹±
                                batch_match = re.search(r'Epoch\s+(\d+)\s+\|\s+Batch\s+(\d+)/(\d+)\s+\|\s+Loss:\s+([\d.]+)', line)
                                if batch_match:
                                    epoch, current_batch, total_batches, loss = batch_match.groups()
                                    self.current_epoch = int(epoch)
                                    self.current_batch = f"{current_batch}/{total_batches}"
                                    self.current_loss = loss
                                    log_line = f"{current_time} | INFO | Epoch {epoch} | Batch {current_batch}/{total_batches} | Loss: {loss}"
                                
                                # 2) ê¸°ì¡´ Cls Acc: X | Det mAP: Y | Time: Z íŒ¨í„´ íŒŒì‹±
                                acc_match = re.search(r'Cls Acc:\s+([\d.]+)\s+\|\s+Det mAP:\s+([\d.]+)\s+\|\s+Time:\s+([\d.]+)s', line)
                                if acc_match:
                                    cls_acc, det_map, epoch_time = acc_match.groups()
                                    self.classification_acc = cls_acc
                                    self.detection_map = det_map
                                    self.epoch_time = f"{epoch_time}s"
                                    log_line = f"{current_time} | INFO | Epoch {self.current_epoch} ì™„ë£Œ | Cls Acc: {cls_acc} | Det mAP: {det_map} | Time: {epoch_time}s"
                                
                                # === ìƒˆë¡œìš´ Phase 1 í¬ë§· íŒŒì„œë“¤ ===
                                
                                # 3) Top-5 ì •í™•ë„: "Top-1: 0.441 | Top-5: 0.672"
                                top5_match = re.search(r'Top-1:\s*([\d.]+)\s*\|\s*Top-5:\s*([\d.]+)', line)
                                if top5_match:
                                    top1_acc, top5_acc = top5_match.groups()
                                    self.top1_accuracy = top1_acc
                                    self.top5_accuracy = top5_acc
                                    log_line = f"{current_time} | METRIC | Top-1: {top1_acc} | Top-5: {top5_acc}"
                                
                                # 4) Macro F1 ì ìˆ˜: "Macro-F1: 0.387"
                                f1_match = re.search(r'Macro-F1:\s*([\d.]+)', line)
                                if f1_match:
                                    macro_f1 = f1_match.groups()[0]
                                    self.macro_f1 = macro_f1
                                    log_line = f"{current_time} | METRIC | Macro-F1: {macro_f1}"
                                
                                # 5) ë„ë©”ì¸ë³„ ì§€í‘œ (í™•ì¥ë¨): "Single: Top-1=0.523 | Top-5=0.672 | Macro-F1=0.387 | Combination: Top-1=0.342 | Top-5=0.523 | Macro-F1=0.298"
                                # ê¸°ì¡´ ë‹¨ìˆœ Single/Combination Top-1 íŒ¨í„´
                                domain_match = re.search(r'Single:\s*Top-1=([\d.]+)\s*\|\s*Combination:\s*Top-1=([\d.]+)', line)
                                if domain_match:
                                    single_acc, combo_acc = domain_match.groups()
                                    self.single_domain_acc = single_acc
                                    self.combination_domain_acc = combo_acc
                                    log_line = f"{current_time} | DOMAIN | Single: {single_acc} | Combination: {combo_acc}"
                                
                                # í™•ì¥ëœ Single ë„ë©”ì¸ íŒ¨í„´ (Top-1/Top-5/Macro-F1)
                                single_extended_match = re.search(r'Single:\s*Top-1=([\d.]+)(?:\s*\|\s*Top-5=([\d.]+))?(?:\s*\|\s*Macro[- ]?F1=([\d.]+))?', line)
                                if single_extended_match:
                                    single_top1, single_top5, single_f1 = single_extended_match.groups()
                                    self.single_top1 = single_top1
                                    if single_top5:
                                        self.single_top5 = single_top5
                                    if single_f1:
                                        self.single_macro_f1 = single_f1
                                    log_line = f"{current_time} | DOMAIN_EXT | Single: T1={single_top1}" + \
                                              (f" T5={single_top5}" if single_top5 else "") + \
                                              (f" F1={single_f1}" if single_f1 else "")
                                
                                # í™•ì¥ëœ Combination ë„ë©”ì¸ íŒ¨í„´ (Top-1/Top-5/Macro-F1)
                                combo_extended_match = re.search(r'Combination:\s*Top-1=([\d.]+)(?:\s*\|\s*Top-5=([\d.]+))?(?:\s*\|\s*Macro[- ]?F1=([\d.]+))?', line)
                                if combo_extended_match:
                                    combo_top1, combo_top5, combo_f1 = combo_extended_match.groups()
                                    self.combo_top1 = combo_top1
                                    if combo_top5:
                                        self.combo_top5 = combo_top5
                                    if combo_f1:
                                        self.combo_macro_f1 = combo_f1
                                    log_line = f"{current_time} | DOMAIN_EXT | Combo: T1={combo_top1}" + \
                                              (f" T5={combo_top5}" if combo_top5 else "") + \
                                              (f" F1={combo_f1}" if combo_f1 else "")
                                
                                # 6) ë ˆì´í„´ì‹œ ë¶„í•´: "Pipeline: det=45ms, crop=12ms, cls=28ms, total=85ms"
                                latency_match = re.search(r'Pipeline:\s*det=([\d.]+)ms,\s*crop=([\d.]+)ms,\s*cls=([\d.]+)ms,\s*total=([\d.]+)ms', line)
                                if latency_match:
                                    det_latency, crop_latency, cls_latency, total_latency = latency_match.groups()
                                    self.det_latency = det_latency
                                    self.crop_latency = crop_latency
                                    self.cls_latency = cls_latency
                                    self.total_latency = total_latency
                                    log_line = f"{current_time} | LATENCY | Det: {det_latency}ms | Crop: {crop_latency}ms | Cls: {cls_latency}ms | Total: {total_latency}ms"
                                
                                # 7) Auto Confidence: "Auto-selected confidence: det=0.25, cls=0.30"
                                conf_match = re.search(r'Auto-selected confidence:\s*det=([\d.]+),\s*cls=([\d.]+)', line)
                                if conf_match:
                                    det_conf, cls_conf = conf_match.groups()
                                    self.det_confidence = det_conf
                                    self.cls_confidence = cls_conf
                                    log_line = f"{current_time} | CONFIDENCE | Detection: {det_conf} | Classification: {cls_conf}"
                                
                                # 8) OOM Guard í™œì„±í™”: "OOM Guard: batch_size reduced 16â†’8, grad_accum 2â†’4"
                                oom_match = re.search(r'OOM Guard:\s*batch_size\s*reduced\s*(\d+)â†’(\d+),\s*grad_accum\s*(\d+)â†’(\d+)', line)
                                if oom_match:
                                    old_batch, new_batch, old_accum, new_accum = oom_match.groups()
                                    self.oom_old_batch = old_batch
                                    self.oom_new_batch = new_batch
                                    self.oom_old_accum = old_accum
                                    self.oom_new_accum = new_accum
                                    log_line = f"{current_time} | OOM | Batch: {old_batch}â†’{new_batch} | Accum: {old_accum}â†’{new_accum}"
                                
                                # 9) Interleaved Learning: "Interleaved: det_steps=1247, cls_steps=2491 (ratio=1:2.00)"
                                interleave_match = re.search(r'Interleaved:\s*det_steps=(\d+),\s*cls_steps=(\d+)\s*\(ratio=1:([\d.]+)\)', line)
                                if interleave_match:
                                    det_steps, cls_steps, ratio = interleave_match.groups()
                                    self.det_steps = det_steps
                                    self.cls_steps = cls_steps
                                    self.interleave_ratio = ratio
                                    log_line = f"{current_time} | INTERLEAVE | Det: {det_steps} | Cls: {cls_steps} | Ratio: 1:{ratio}"
                                
                                # === ìƒˆë¡œìš´ ìš”êµ¬ì‚¬í•­ íŒŒì„œë“¤ ===
                                
                                # 10) Detection Recall / Precision: "Recall: 0.623" "Precision: 0.578"
                                recall_match = re.search(r'Recall:\s*([\d.]+)', line)
                                if recall_match:
                                    recall_val = recall_match.groups()[0]
                                    self.det_recall = recall_val
                                    log_line = f"{current_time} | DET_METRIC | Recall: {recall_val}"
                                
                                precision_match = re.search(r'Precision:\s*([\d.]+)', line)
                                if precision_match:
                                    precision_val = precision_match.groups()[0]
                                    self.det_precision = precision_val
                                    log_line = f"{current_time} | DET_METRIC | Precision: {precision_val}"
                                
                                # 11) ë„ë©”ì¸ë³„ Selected Confidence: "Selected Confidence: single=0.24, combo=0.26"
                                selected_conf_match = re.search(r'Selected Confidence:\s*single=([\d.]+),\s*combo=([\d.]+)', line)
                                if selected_conf_match:
                                    conf_single, conf_combo = selected_conf_match.groups()
                                    self.selected_conf_single = conf_single
                                    self.selected_conf_combo = conf_combo
                                    log_line = f"{current_time} | CONF_DOMAIN | Single: {conf_single} | Combo: {conf_combo}"
                                
                                # 12) ë ˆì´í„´ì‹œ í¼ì„¼íƒ€ì¼: "Latency p50/p95/p99: det=12.3, crop=4.5, cls=15.2, total=32.0"
                                latency_percentile_match = re.search(
                                    r'Latency p50/p95/p99:\s*det=([\d.]+),\s*crop=([\d.]+),\s*cls=([\d.]+),\s*total=([\d.]+)', line
                                )
                                if latency_percentile_match:
                                    det_p, crop_p, cls_p, total_p = latency_percentile_match.groups()
                                    # ì¼ë‹¨ p50 ê°’ìœ¼ë¡œ ì €ì¥ (ë” ì„¸ë°€í•œ ë¶„ì„ì€ ì¶”í›„ í™•ì¥)
                                    self.latency_p50_det = det_p
                                    self.latency_p50_crop = crop_p
                                    self.latency_p50_cls = cls_p
                                    self.latency_p50_total = total_p
                                    log_line = f"{current_time} | LATENCY_P50 | Det: {det_p}ms | Crop: {crop_p}ms | Cls: {cls_p}ms | Total: {total_p}ms"
                                
                                # 13) VRAM Peak: "VRAM peak: 14500 MB"
                                vram_peak_match = re.search(r'VRAM peak:\s*(\d+)\s*MB', line)
                                if vram_peak_match:
                                    vram_peak = vram_peak_match.groups()[0]
                                    self.vram_peak_mb = vram_peak
                                    log_line = f"{current_time} | SYS_METRIC | VRAM Peak: {vram_peak}MB"
                                
                                # 14) Grad-Norm: "Grad-norm after_clipping: 1.23"
                                grad_norm_match = re.search(r'Grad[- ]?norm(?:\s*after_clipping)?:\s*([\d.]+)', line)
                                if grad_norm_match:
                                    grad_norm = grad_norm_match.groups()[0]
                                    self.grad_norm_after = grad_norm
                                    log_line = f"{current_time} | SYS_METRIC | Grad-Norm: {grad_norm}"
                                
                                # 15) ì „ì²´ ì—í¬í¬ ìë™ ê°ì§€: ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›
                                epochs_patterns = [
                                    r'(?:Starting training for|will run for)\s+(\d+)\s+epochs?',
                                    r'Total epochs?[:\s]+(\d+)',
                                    r'Training for\s+(\d+)\s+epochs?',
                                    r'epochs?[=:\s]+(\d+)',
                                    r'(?:--epochs?|epochs)\s+(\d+)'
                                ]
                                
                                for pattern in epochs_patterns:
                                    epochs_match = re.search(pattern, line, re.IGNORECASE)
                                    if epochs_match:
                                        total_epochs = epochs_match.groups()[0]
                                        if int(total_epochs) > self.total_epochs:  # ë” í° ê°’ë§Œ ì—…ë°ì´íŠ¸
                                            self.total_epochs = int(total_epochs)
                                            log_line = f"{current_time} | CONFIG | Total Epochs: {total_epochs}"
                                        break
                                
                                # 16) ì´ ë°°ì¹˜ ìˆ˜ ìë™ ê°ì§€: "Batch 2000/5093" íŒ¨í„´ì—ì„œ ìµœëŒ€ê°’ ì¶”ì¶œ
                                batch_total_match = re.search(r'Batch\s+\d+/(\d+)', line)
                                if batch_total_match:
                                    total_batches = batch_total_match.groups()[0]
                                    if int(total_batches) > self.total_batches:
                                        self.total_batches = int(total_batches)
                                        # ìƒˆë¡œìš´ ì´ ë°°ì¹˜ ìˆ˜ ë°œê²¬ì‹œë§Œ ë¡œê·¸ ìƒì„±
                                        if not hasattr(self, '_last_total_batches') or self._last_total_batches != self.total_batches:
                                            self._last_total_batches = self.total_batches
                                            log_line = f"{current_time} | CONFIG | Total Batches: {total_batches}"
                        
                        # íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì•Œë ¤ì§„ ìƒíƒœë¡œ ë¡œê·¸ ìƒì„±
                        if not log_line:
                            log_line = f"{current_time} | INFO | Epoch {self.current_epoch} | Batch {self.current_batch} | Loss: {self.current_loss}"
                            
                    except Exception as parse_error:
                        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¡œê·¸ ìƒì„±
                        # KST ì‹œê°„ëŒ€ë¡œ ë¡œê·¸ ì‹œê°„ í‘œì‹œ (ìˆ˜ì •ë¨)
                        kst = timezone(timedelta(hours=9))
                        current_time = datetime.now(kst).strftime('%H:%M:%S')
                        log_line = f"{current_time} | INFO | Epoch {self.current_epoch} | Batch {self.current_batch} | Loss: {self.current_loss}"
                        print(f"íŒŒì‹± ì˜¤ë¥˜: {parse_error}")
                    
                    # WebSocket ì „ìš© ë¡œê·¸ì´ë¯€ë¡œ íŒŒì¼ ê¸°ë¡ ìƒëµ (ì¤‘ë³µ ë°©ì§€)
                    
                    # WebSocket í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ì¦‰ì‹œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ë™ê¸°í™” ë¬¸ì œ í•´ê²°)
                    if self.connected_clients and log_line:
                        try:
                            # ì§ì ‘ WebSocket ë©”ì‹œì§€ ì „ì†¡ (event loop ë¬¸ì œ í•´ê²°)
                            message_data = {
                                "timestamp": current_time,
                                "message": log_line,
                                "type": "realtime",
                                "epoch": self.current_epoch,
                                "batch": self.current_batch,
                                "loss": self.current_loss,
                                "cls_acc": self.classification_acc,
                                "det_map": self.detection_map,
                                "epoch_time": self.epoch_time,
                                # Phase 1 ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ë“¤
                                "top1_accuracy": self.top1_accuracy,
                                "top5_accuracy": self.top5_accuracy,
                                # ì •ê·œí™”ëœ ê°’ë“¤ ì¶”ê°€ (UI í‘œì‹œìš©)
                                "top1_accuracy_norm": self.normalize_value(self.top1_accuracy, "percent"),
                                "top5_accuracy_norm": self.normalize_value(self.top5_accuracy, "percent"),
                                "macro_f1": self.macro_f1,
                                "macro_f1_norm": self.normalize_value(self.macro_f1, "percent"),
                                "single_domain_acc": self.single_domain_acc,
                                "single_domain_acc_norm": self.normalize_value(self.single_domain_acc, "percent"),
                                "combination_domain_acc": self.combination_domain_acc,
                                "combination_domain_acc_norm": self.normalize_value(self.combination_domain_acc, "percent"),
                                "det_latency": self.det_latency,
                                "det_latency_norm": self.normalize_value(self.det_latency, "ms"),
                                "crop_latency": self.crop_latency,
                                "crop_latency_norm": self.normalize_value(self.crop_latency, "ms"),
                                "cls_latency": self.cls_latency,
                                "cls_latency_norm": self.normalize_value(self.cls_latency, "ms"),
                                "total_latency": self.total_latency,
                                "total_latency_norm": self.normalize_value(self.total_latency, "ms"),
                                "det_confidence": self.det_confidence,
                                "det_confidence_norm": self.normalize_value(self.det_confidence, "raw"),
                                "cls_confidence": self.cls_confidence,
                                "cls_confidence_norm": self.normalize_value(self.cls_confidence, "raw"),
                                "oom_old_batch": self.oom_old_batch,
                                "oom_new_batch": self.oom_new_batch,
                                "oom_old_accum": self.oom_old_accum,
                                "oom_new_accum": self.oom_new_accum,
                                "det_steps": self.det_steps,
                                "cls_steps": self.cls_steps,
                                "interleave_ratio": self.interleave_ratio,
                                "interleave_ratio_norm": self.normalize_value(self.interleave_ratio, "ratio"),
                                # ë™ì  í•™ìŠµ ì„¤ì •
                                "total_epochs": self.total_epochs,
                                "total_batches": self.total_batches,
                                # í™•ì¥ëœ Phase 1 ì§€í‘œë“¤ (ìƒˆë¡œìš´ ìš”êµ¬ì‚¬í•­)
                                # ë„ë©”ì¸ë³„ Top-5 / Macro-F1
                                "single_top1": self.single_top1,
                                "single_top1_norm": self.normalize_value(self.single_top1, "percent"),
                                "single_top5": self.single_top5,
                                "single_top5_norm": self.normalize_value(self.single_top5, "percent"),
                                "single_macro_f1": self.single_macro_f1,
                                "single_macro_f1_norm": self.normalize_value(self.single_macro_f1, "percent"),
                                "combo_top1": self.combo_top1,
                                "combo_top1_norm": self.normalize_value(self.combo_top1, "percent"),
                                "combo_top5": self.combo_top5,
                                "combo_top5_norm": self.normalize_value(self.combo_top5, "percent"),
                                "combo_macro_f1": self.combo_macro_f1,
                                "combo_macro_f1_norm": self.normalize_value(self.combo_macro_f1, "percent"),
                                # Detection Recall / Precision
                                "det_recall": self.det_recall,
                                "det_recall_norm": self.normalize_value(self.det_recall, "percent"),
                                "det_precision": self.det_precision,
                                "det_precision_norm": self.normalize_value(self.det_precision, "percent"),
                                # ë„ë©”ì¸ë³„ Selected Confidence
                                "selected_conf_single": self.selected_conf_single,
                                "selected_conf_combo": self.selected_conf_combo,
                                # ë ˆì´í„´ì‹œ í¼ì„¼íƒ€ì¼
                                "latency_p50_det": self.latency_p50_det,
                                "latency_p95_det": self.latency_p95_det,
                                "latency_p99_det": self.latency_p99_det,
                                "latency_p50_crop": self.latency_p50_crop,
                                "latency_p95_crop": self.latency_p95_crop,
                                "latency_p99_crop": self.latency_p99_crop,
                                "latency_p50_cls": self.latency_p50_cls,
                                "latency_p95_cls": self.latency_p95_cls,
                                "latency_p99_cls": self.latency_p99_cls,
                                "latency_p50_total": self.latency_p50_total,
                                "latency_p95_total": self.latency_p95_total,
                                "latency_p99_total": self.latency_p99_total,
                                # VRAM Peak / Grad-Norm
                                "vram_peak_mb": self.vram_peak_mb,
                                "vram_peak_mb_norm": self.normalize_value(self.vram_peak_mb, "mb"),
                                "grad_norm_after": self.grad_norm_after,
                                "grad_norm_after_norm": self.normalize_value(self.grad_norm_after, "raw")
                            }
                            
                            # íì— ì €ì¥í•˜ì—¬ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ì²˜ë¦¬
                            if not hasattr(self, 'message_queue'):
                                import asyncio
                                self.message_queue = []
                            self.message_queue.append(message_data)
                            
                            print(f"ğŸ”„ [DEBUG] íŒŒì‹± ì„±ê³µ: {log_line[:100]}...")
                            
                        except Exception as broadcast_error:
                            print(f"âŒ WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì˜¤ë¥˜: {broadcast_error}")
                    
                    elif self.connected_clients:
                        # í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ë§Œ íŒŒì‹±ëœ ë¡œê·¸ê°€ ì—†ëŠ” ê²½ìš°
                        print(f"âš ï¸  [DEBUG] í´ë¼ì´ì–¸íŠ¸ {len(self.connected_clients)}ê°œ ì—°ê²°ë¨, í•˜ì§€ë§Œ íŒŒì‹± ì‹¤íŒ¨")
                    
                    time.sleep(1)  # 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
                    
                except Exception as e:
                    print(f"bash_23 ìº¡ì²˜ ì˜¤ë¥˜: {e}")
                    time.sleep(2)
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
        capture_thread = threading.Thread(target=capture_bash23, daemon=True)
        capture_thread.start()
        
    async def start_training_with_logging(self, command: List[str]):
        """í•™ìŠµ ì‹œì‘í•˜ë©´ì„œ ì‹¤ì‹œê°„ ë¡œê·¸ ìº¡ì²˜"""
        print(f"ğŸš€ ì‹¤ì‹œê°„ ë¡œê·¸ ìº¡ì²˜ ì‹œì‘: {' '.join(command)}")
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {self.log_file}")
        
        # ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ìƒˆ í•™ìŠµ ì‹œì‘ ì•Œë¦¼
        await self.broadcast_new_training_start()
        
        # tee ëª…ë ¹ì–´ë¡œ stdoutì„ íŒŒì¼ê³¼ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì— ë™ì‹œ ì¶œë ¥
        tee_command = ["tee", self.log_file]
        
        # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        self.training_process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=0  # ë¼ì¸ ë²„í¼ë§
        )
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ì½ê¸° ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸
        while True:
            if self.training_process.poll() is not None:
                # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
                break
                
            line = self.training_process.stdout.readline()
            if line:
                # íŒŒì¼ì— ì €ì¥
                with open(self.log_file, "a", encoding="utf-8") as f:
                    f.write(line)
                
                # ì½˜ì†” ì¶œë ¥
                print(line.rstrip())
                
                # WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await self.broadcast_log(line.rstrip())
            
            await asyncio.sleep(0.01)  # CPU ì‚¬ìš©ë¥  ì¡°ì ˆ
        
        return_code = self.training_process.returncode
        final_message = f"ğŸ í•™ìŠµ ì™„ë£Œ (ì¢…ë£Œ ì½”ë“œ: {return_code})"
        print(final_message)
        await self.broadcast_log(final_message)
        
        return return_code
    
    async def broadcast_log(self, message: str):
        """ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì— ë¡œê·¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not self.connected_clients:
            return
            
        disconnect_clients = []
        for client in self.connected_clients:
            try:
                # KST ì‹œê°„ìœ¼ë¡œ í†µì¼
                kst = timezone(timedelta(hours=9))
                await client.send_text(json.dumps({
                    "timestamp": datetime.now(kst).isoformat(),
                    "message": message
                }))
            except:
                disconnect_clients.append(client)
        
        # ì—°ê²°ì´ ëŠê¸´ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        for client in disconnect_clients:
            if client in self.connected_clients:
                self.connected_clients.remove(client)
    
    async def add_client(self, websocket: WebSocket):
        """ìƒˆ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        await websocket.accept()
        self.connected_clients.append(websocket)
        
        # ìƒˆ í•™ìŠµ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡ (ê¸°ì¡´ ë¡œê·¸ëŠ” ì„ íƒì ìœ¼ë¡œë§Œ)
        try:
            kst = timezone(timedelta(hours=9))
            await websocket.send_text(json.dumps({
                "timestamp": datetime.now(kst).isoformat(),
                "message": "ğŸ”„ ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ ì„¸ì…˜ ì‹œì‘",
                "type": "session_start"
            }))
            
            # í™œì„± í•™ìŠµì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œê·¸ í‘œì‹œ
            if not self.training_process or self.training_process.poll() is not None:
                historical_logs = await self.get_historical_logs()
                if historical_logs:
                    await websocket.send_text(json.dumps({
                        "timestamp": datetime.now(kst).isoformat(),
                        "message": "--- ğŸ“‹ ì´ì „ ì„¸ì…˜ ë¡œê·¸ (ì°¸ì¡°ìš©) ---",
                        "type": "historical_header"
                    }))
                    for log in historical_logs[-50:]:  # ìµœê·¼ 50ì¤„ë§Œ
                        await websocket.send_text(json.dumps({
                            "timestamp": datetime.now(kst).isoformat(),
                            "message": log,
                            "historical": True
                        }))
                    await websocket.send_text(json.dumps({
                        "timestamp": datetime.now(kst).isoformat(),
                        "message": "--- ğŸ“‹ ì´ì „ ë¡œê·¸ ë ---",
                        "type": "historical_footer"
                    }))
        except Exception as e:
            print(f"ì„¸ì…˜ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            self.remove_client(websocket)
    
    async def get_historical_logs(self):
        """ê¸°ì¡´ í•™ìŠµ ë¡œê·¸ë¥¼ ìˆ˜ì§‘"""
        logs = []
        
        # 1) ì‹¤ì œ ë¡œê·¸ íŒŒì¼ë“¤ì—ì„œ ì „ì²´ ë¡œê·¸ ì½ê¸°
        log_sources = [
            # í˜„ì¬ ì„¤ì •ëœ ë¡œê·¸ íŒŒì¼
            self.log_file,
            # ì‹¤ì œ í•™ìŠµ ë¡œê·¸ íŒŒì¼
            "/home/max16/pillsnap_data/exp/exp01/logs/__main___20250823.log",
            "/tmp/pillsnap_training_20250823.log",
        ]
        
        for log_path in log_sources:
            if os.path.exists(log_path):
                try:
                    with open(log_path, "r", encoding="utf-8") as f:
                        for line in f:
                            logs.append(line.rstrip())
                    break  # ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ ë¡œê·¸ íŒŒì¼ ì‚¬ìš©
                except:
                    continue
        
        # 2) ë¡œê·¸ê°€ ì—†ìœ¼ë©´ ê°€ì¥ ìµœì‹  ë¡œê·¸ íŒŒì¼ ìë™ íƒì§€
        if not logs:
            try:
                import glob
                pattern = "/home/max16/pillsnap_data/exp/exp01/logs/*main*_*.log"
                log_files = sorted(glob.glob(pattern), key=os.path.getmtime, reverse=True)
                
                if log_files:
                    latest_log = log_files[0]
                    print(f"ğŸ“‚ ìµœì‹  ë¡œê·¸ íŒŒì¼ ì‚¬ìš©: {latest_log}")
                    with open(latest_log, "r", encoding="utf-8") as f:
                        for line in f:
                            logs.append(line.rstrip())
            except:
                pass
        
        # 3) ì—¬ì „íˆ ë¡œê·¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
        if not logs:
            logs = [
                "ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ëŒ€ê¸° ì¤‘...",
                "ğŸ” ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "   ìƒˆë¡œìš´ í•™ìŠµì´ ì‹œì‘ë˜ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.",
                "",
                f"ğŸ“ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ë¡œê·¸ íŒŒì¼ë“¤:",
                f"   - {self.log_file}",
                f"   - /home/max16/pillsnap_data/exp/exp01/logs/__main___*.log",
            ]
        
        # ë¡œê·¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ë§ˆì§€ë§‰ 200ì¤„ë§Œ ë°˜í™˜
        return logs[-200:] if len(logs) > 200 else logs
    
    def remove_client(self, websocket: WebSocket):
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ"""
        if websocket in self.connected_clients:
            self.connected_clients.remove(websocket)
    
    async def broadcast_new_training_start(self):
        """ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ìƒˆ í•™ìŠµ ì‹œì‘ ì•Œë¦¼"""
        if not self.connected_clients:
            return
            
        kst = timezone(timedelta(hours=9))
        message = {
            "timestamp": datetime.now(kst).isoformat(),
            "message": "ğŸš€ ìƒˆë¡œìš´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë©ë‹ˆë‹¤!",
            "type": "new_training_start"
        }
        
        disconnected = []
        for client in self.connected_clients:
            try:
                await client.send_text(json.dumps(message))
            except Exception:
                disconnected.append(client)
        
        # ì—°ê²°ì´ ëŠì–´ì§„ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        for client in disconnected:
            self.remove_client(client)

    async def watch_log_file(self):
        """ì‹¤ì‹œê°„ ë¡œê·¸ íŒŒì¼ ê°ì‹œ ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not Path(self.log_file).exists():
            print(f"ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.log_file}")
            return
            
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ê°ì‹œ ì‹œì‘: {self.log_file}")
        
        while True:
            try:
                # ë©”ì‹œì§€ í ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ìƒì„±ëœ ë©”ì‹œì§€)
                if hasattr(self, 'message_queue') and self.message_queue:
                    messages_to_send = self.message_queue.copy()
                    self.message_queue.clear()
                    
                    for message_data in messages_to_send:
                        await self.broadcast_to_clients(message_data)
                        print(f"ğŸ“¡ [DEBUG] WebSocket ì „ì†¡: {message_data.get('message', '')[:50]}...")
                
                # íŒŒì¼ í¬ê¸° ì²´í¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                current_size = Path(self.log_file).stat().st_size
                
                if current_size > self.last_position:
                    # ìƒˆë¡œìš´ ë‚´ìš©ì´ ìˆìŒ - ì½ê¸°
                    with open(self.log_file, 'r', encoding='utf-8') as f:
                        f.seek(self.last_position)
                        new_lines = f.readlines()
                        self.last_position = f.tell()
                    
                    # ìƒˆë¡œìš´ ë¼ì¸ì„ í´ë¼ì´ì–¸íŠ¸ë“¤ì—ê²Œ ì „ì†¡ (ë°±ì—… ì „ì†¡)
                    if new_lines and self.connected_clients:
                        kst = timezone(timedelta(hours=9))
                        for line in new_lines:
                            line = line.strip()
                            if line:  # ë¹ˆ ì¤„ ì œì™¸
                                await self.broadcast_to_clients({
                                    "timestamp": datetime.now(kst).isoformat(),
                                    "message": line,
                                    "type": "file_realtime"
                                })
                
                # 0.5ì´ˆ ëŒ€ê¸° (ë” ë¹ ë¥¸ ì‘ë‹µ)
                await asyncio.sleep(0.5)
                
            except Exception as e:
                print(f"ë¡œê·¸ íŒŒì¼ ê°ì‹œ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(2)  # ì—ëŸ¬ ì‹œ 2ì´ˆ ëŒ€ê¸°

    async def broadcast_to_clients(self, message: dict):
        """ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not self.connected_clients:
            return
            
        disconnected = []
        for client in self.connected_clients:
            try:
                await client.send_text(json.dumps(message))
            except Exception:
                disconnected.append(client)
        
        # ì—°ê²°ì´ ëŠì–´ì§„ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        for client in disconnected:
            self.remove_client(client)

# ê¸€ë¡œë²Œ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
logger = RealtimeTrainingLogger()

# FastAPI ì•±
app = FastAPI(title="ì‹¤ì‹œê°„ í•™ìŠµ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°")

# HTML ëŒ€ì‹œë³´ë“œ íŒŒì¼ì—ì„œ ì½ê¸°
def load_dashboard_html():
    dashboard_path = Path(__file__).parent / "dashboard.html"
    if dashboard_path.exists():
        with open(dashboard_path, 'r', encoding='utf-8') as f:
            return f.read()
    else:
        return """<!DOCTYPE html><html><body><h1>Dashboard file not found</h1></body></html>"""

@app.get("/")
async def get_dashboard():
    """ì‹¤ì‹œê°„ ë¡œê·¸ ëŒ€ì‹œë³´ë“œ"""
    return HTMLResponse(load_dashboard_html())

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await logger.add_client(websocket)
    try:
        while True:
            await websocket.receive_text()  # ì—°ê²° ìœ ì§€
    except WebSocketDisconnect:
        logger.remove_client(websocket)

@app.get("/api/system")
async def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ API (ê¸°ì¡´ simple_real_monitor.pyì™€ í˜¸í™˜)"""
    try:
        import psutil
        import subprocess
        
        # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
        training_pid = None
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] == 'python':
                    cmdline = ' '.join(proc.info['cmdline'])
                    if 'train_stage3_two_stage' in cmdline:
                        training_pid = proc.info['pid']
                        break
            except:
                continue
        
        if not training_pid:
            return {"status": "not_running", "message": "í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
        
        # í”„ë¡œì„¸ìŠ¤ ì •ë³´
        process = psutil.Process(training_pid)
        cpu_percent = process.cpu_percent(interval=0.1)
        memory_info = process.memory_info()
        memory_gb = memory_info.rss / (1024**3)
        
        # GPU ì •ë³´
        gpu_info = {}
        try:
            result = subprocess.run([
                'nvidia-smi', 
                '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0:
                values = result.stdout.strip().split(', ')
                gpu_info = {
                    "utilization": int(values[0]),
                    "memory_used_mb": int(values[1]),
                    "memory_total_mb": int(values[2]),
                    "temperature": int(values[3])
                }
        except:
            gpu_info = {"error": "GPU ì •ë³´ ì½ê¸° ì‹¤íŒ¨"}
        
        # KST ì‹œê°„ ì„¤ì •
        kst = timezone(timedelta(hours=9))
        return {
            "status": "running",
            "timestamp": datetime.now(kst).isoformat(),
            "process": {
                "pid": training_pid,
                "cpu_percent": cpu_percent,
                "memory_gb": round(memory_gb, 2),
                "running_time": time.time() - process.create_time()
            },
            "gpu": gpu_info,
            "message": f"ì‹¤ì œ í•™ìŠµ ì§„í–‰ ì¤‘ (PID: {training_pid})"
        }
        
    except Exception as e:
        kst = timezone(timedelta(hours=9))
        return {
            "status": "error", 
            "message": f"ì‹œìŠ¤í…œ ìƒíƒœ ì˜¤ë¥˜: {e}",
            "timestamp": datetime.now(kst).isoformat()
        }

@app.post("/start_training")
async def start_training(command: List[str]):
    """í•™ìŠµ ì‹œì‘ API"""
    asyncio.create_task(logger.start_training_with_logging(command))
    return {"status": "started", "command": command, "log_file": logger.log_file}

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ í•™ìŠµ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°")
    parser.add_argument("--port", type=int, default=8000, help="ì„œë²„ í¬íŠ¸")
    parser.add_argument("--command", nargs="+", help="ì‹¤í–‰í•  í•™ìŠµ ëª…ë ¹ì–´")
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ì‹¤ì‹œê°„ ë¡œê·¸ ì„œë²„ ì‹œì‘ (í¬íŠ¸: {args.port})")
    print(f"ğŸ“Š ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:{args.port} ì ‘ì†")
    print(f"ğŸ“ ê°ì§€ëœ ë¡œê·¸ íŒŒì¼: {logger.log_file}")
    
    if args.command:
        # ëª…ë ¹ì–´ê°€ ì£¼ì–´ì§„ ê²½ìš° ë°”ë¡œ í•™ìŠµ ì‹œì‘
        async def start_training_on_startup():
            await asyncio.sleep(1)  # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
            await logger.start_training_with_logging(args.command)
        
        asyncio.create_task(start_training_on_startup())
    
    # FastAPI ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë¡œ íŒŒì¼ ê°ì‹œ íƒœìŠ¤í¬ ë“±ë¡
    @app.on_event("startup")
    async def on_startup():
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ê°ì‹œ íƒœìŠ¤í¬ ì‹œì‘: {logger.log_file}")
        asyncio.create_task(logger.watch_log_file())
    
    uvicorn.run(app, host="0.0.0.0", port=args.port, log_level="warning")