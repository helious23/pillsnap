#!/usr/bin/env python3
"""
PillSnap Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ïä§Ï∫î Ïä§ÌÅ¨Î¶ΩÌä∏
- Ïã§Ï†ú ÏïïÏ∂ï Ìï¥Ï†úÎêú Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Î∂ÑÏÑù
- Ïù¥ÎØ∏ÏßÄ/ÎùºÎ≤® Îß§Ïπ≠ Í≤ÄÏ¶ù
- K-ÏΩîÎìú Îß§Ìïë ÌÖåÏù¥Î∏î ÏÉùÏÑ±
- Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏÇ¨
"""

import os
import json
import sys
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Tuple, Optional

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Ï∂îÍ∞Ä (ÏÉÅÏúÑ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥Îèô)
sys.path.insert(0, '/home/max16/pillsnap')

# src.utils Î™®ÎìàÏóêÏÑú import (Ï†ïÎ¶¨Îêú Íµ¨Ï°∞)
from src.utils import build_logger, load_config, ensure_dir


class PillSnapDataScanner:
    """
    PillSnap Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞ Ïä§Ï∫êÎÑà
    - ZIP Ìï¥Ï†úÎêú Îç∞Ïù¥ÌÑ∞ Ïã§Ï†ú Íµ¨Ï°∞ Î∂ÑÏÑù
    - Ïù¥ÎØ∏ÏßÄ-ÎùºÎ≤® Îß§Ïπ≠ Í≤ÄÏ¶ù
    - EDI ÏΩîÎìú Îß§Ìïë ÌÖåÏù¥Î∏î Íµ¨Ï∂ï
    """
    
    def __init__(self, data_root: str):
        """
        Args:
            data_root: Îç∞Ïù¥ÌÑ∞ÏÖã Î£®Ìä∏ Í≤ΩÎ°ú (/mnt/data/pillsnap_dataset)
        """
        self.data_root = Path(data_root)
        self.logger = build_logger("data_scanner", level="info")
        
        # Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï
        self.train_images = self.data_root / "data" / "train" / "images"
        self.train_labels = self.data_root / "data" / "train" / "labels"
        self.val_images = self.data_root / "data" / "val" / "images"
        self.val_labels = self.data_root / "data" / "val" / "labels"
        
        # Î∂ÑÏÑù Í≤∞Í≥º Ï†ÄÏû•Ïö©
        self.structure_info = {}
        self.k_code_mapping = {}
        self.edi_code_mapping = {}
        self.integrity_issues = []
        
    def scan_full_structure(self) -> Dict:
        """Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ïä§Ï∫î Î∞è Î∂ÑÏÑù"""
        
        self.logger.step("Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ï†ÑÏ≤¥ Ïä§Ï∫î", "Ïã§Ï†ú ÏïïÏ∂ï Ìï¥Ï†úÎêú Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÏãúÏûë")
        
        try:
            # 1) Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ Ï°¥Ïû¨ ÌôïÏù∏
            self._verify_basic_structure()
            
            # 2) Single ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù
            single_info = self._scan_single_data()
            
            # 3) Combination ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù
            combo_info = self._scan_combination_data()
            
            # 4) Validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù
            val_info = self._scan_validation_data()
            
            # 5) K-ÏΩîÎìú Î∞è EDI ÏΩîÎìú Îß§Ìïë Íµ¨Ï∂ï
            self._build_code_mappings()
            
            # 6) Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏÇ¨
            self._verify_data_integrity()
            
            # 7) Ï†ÑÏ≤¥ Í≤∞Í≥º Ï∑®Ìï©
            self.structure_info = {
                "data_root": str(self.data_root),
                "scan_timestamp": self.logger.timer_start("scan_complete"),
                "train_data": {
                    "single": single_info,
                    "combination": combo_info
                },
                "validation_data": val_info,
                "k_code_mapping": self.k_code_mapping,
                "edi_code_mapping": self.edi_code_mapping,
                "integrity_issues": self.integrity_issues,
                "summary": self._generate_summary()
            }
            
            self.logger.success("Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ïä§Ï∫î ÏôÑÎ£å")
            return self.structure_info
            
        except Exception as e:
            self.logger.failure(f"Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Ïä§Ï∫î Ïã§Ìå®: {e}")
            raise
    
    def _verify_basic_structure(self) -> None:
        """Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞ Í≤ÄÏ¶ù"""
        
        required_dirs = [
            self.train_images / "single",
            self.train_images / "combination", 
            self.train_labels / "single",
            self.train_labels / "combination"
        ]
        
        for dir_path in required_dirs:
            if not dir_path.exists():
                raise FileNotFoundError(f"ÌïÑÏàò ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏùå: {dir_path}")
                
        self.logger.info("‚úÖ Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞ Í≤ÄÏ¶ù ÏôÑÎ£å")
    
    def _scan_single_data(self) -> Dict:
        """Single ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"""
        
        self.logger.info("üìÇ Single ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...")
        
        single_info = {
            "ts_directories": [],  # TS_*_single ÎîîÎ†âÌÜ†Î¶¨Îì§
            "tl_directories": [],  # TL_*_single ÎîîÎ†âÌÜ†Î¶¨Îì§
            "k_codes": set(),      # Î™®Îì† K-ÏΩîÎìúÎì§
            "total_images": 0,     # Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò
            "total_labels": 0,     # Ï¥ù ÎùºÎ≤® Ïàò
            "sample_analysis": {}  # ÏÉòÌîå Î∂ÑÏÑù Í≤∞Í≥º
        }
        
        # TS_*_single ÎîîÎ†âÌÜ†Î¶¨ Ïä§Ï∫î
        single_img_dirs = list(self.train_images.glob("single/TS_*_single"))
        single_info["ts_directories"] = [d.name for d in sorted(single_img_dirs)]
        
        # TL_*_single ÎîîÎ†âÌÜ†Î¶¨ Ïä§Ï∫î  
        single_lbl_dirs = list(self.train_labels.glob("single/TL_*_single"))
        single_info["tl_directories"] = [d.name for d in sorted(single_lbl_dirs)]
        
        # Ï≤´ Î≤àÏß∏ TS ÎîîÎ†âÌÜ†Î¶¨ ÏÉÅÏÑ∏ Î∂ÑÏÑù
        if single_img_dirs:
            sample_ts = single_img_dirs[0]
            k_code_dirs = list(sample_ts.glob("K-*"))
            
            for k_dir in k_code_dirs[:3]:  # Ï≤òÏùå 3Í∞úÎßå ÏÉòÌîå Î∂ÑÏÑù
                k_code = k_dir.name
                single_info["k_codes"].add(k_code)
                
                # Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ïàò Ïπ¥Ïö¥Ìä∏
                image_files = list(k_dir.glob("*.png")) + list(k_dir.glob("*.jpg"))
                single_info["total_images"] += len(image_files)
                
                # ÏÉòÌîå Î∂ÑÏÑù Ï†ÄÏû•
                if k_code not in single_info["sample_analysis"]:
                    single_info["sample_analysis"][k_code] = {
                        "image_count": len(image_files),
                        "sample_files": [f.name for f in image_files[:3]]
                    }
        
        # ÎåÄÏùëÎêòÎäî ÎùºÎ≤® ÌôïÏù∏
        if single_lbl_dirs:
            sample_tl = single_lbl_dirs[0]
            k_json_dirs = list(sample_tl.glob("K-*_json"))
            
            for k_json_dir in k_json_dirs[:3]:
                k_code = k_json_dir.name.replace("_json", "")
                
                # JSON ÌååÏùº Ïàò Ïπ¥Ïö¥Ìä∏
                json_files = list(k_json_dir.glob("*.json"))
                single_info["total_labels"] += len(json_files)
                
                # ÏÉòÌîå JSON Î∂ÑÏÑù
                if json_files and k_code in single_info["sample_analysis"]:
                    single_info["sample_analysis"][k_code]["label_count"] = len(json_files)
                    single_info["sample_analysis"][k_code]["sample_labels"] = [f.name for f in json_files[:3]]
        
        single_info["k_codes"] = list(single_info["k_codes"])  # setÏùÑ listÎ°ú Î≥ÄÌôò
        
        self.logger.info(f"‚úÖ Single Îç∞Ïù¥ÌÑ∞: TS ÎîîÎ†âÌÜ†Î¶¨ {len(single_info['ts_directories'])}Í∞ú, K-ÏΩîÎìú {len(single_info['k_codes'])}Í∞ú")
        return single_info
    
    def _scan_combination_data(self) -> Dict:
        """Combination ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"""
        
        self.logger.info("üîó Combination ÏïΩÌíà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...")
        
        combo_info = {
            "ts_directories": [],  # TS_*_combo ÎîîÎ†âÌÜ†Î¶¨Îì§
            "tl_directories": [],  # TL_*_combo ÎîîÎ†âÌÜ†Î¶¨Îì§
            "combo_k_codes": set(), # Ï°∞Ìï© K-ÏΩîÎìúÎì§ (K-xxx-yyy-zzz-www ÌòïÌÉú)
            "total_images": 0,
            "total_labels": 0,
            "sample_analysis": {}
        }
        
        # TS_*_combo ÎîîÎ†âÌÜ†Î¶¨ Ïä§Ï∫î
        combo_img_dirs = list(self.train_images.glob("combination/TS_*_combo"))
        combo_info["ts_directories"] = [d.name for d in sorted(combo_img_dirs)]
        
        # TL_*_combo ÎîîÎ†âÌÜ†Î¶¨ Ïä§Ï∫î
        combo_lbl_dirs = list(self.train_labels.glob("combination/TL_*_combo"))
        combo_info["tl_directories"] = [d.name for d in sorted(combo_lbl_dirs)]
        
        # Ï≤´ Î≤àÏß∏ TS_combo ÎîîÎ†âÌÜ†Î¶¨ ÏÉÅÏÑ∏ Î∂ÑÏÑù
        if combo_img_dirs:
            sample_ts = combo_img_dirs[0]
            combo_k_dirs = list(sample_ts.glob("K-*"))
            
            for combo_k_dir in combo_k_dirs[:3]:  # Ï≤òÏùå 3Í∞úÎßå ÏÉòÌîå Î∂ÑÏÑù
                combo_k_code = combo_k_dir.name
                combo_info["combo_k_codes"].add(combo_k_code)
                
                # Ï°∞Ìï© Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ïàò Ïπ¥Ïö¥Ìä∏
                image_files = list(combo_k_dir.glob("*.png")) + list(combo_k_dir.glob("*.jpg"))
                combo_info["total_images"] += len(image_files)
                
                # ÏÉòÌîå Î∂ÑÏÑù Ï†ÄÏû•
                combo_info["sample_analysis"][combo_k_code] = {
                    "image_count": len(image_files),
                    "sample_files": [f.name for f in image_files[:3]],
                    "individual_k_codes": combo_k_code.split('-')[1:]  # K- Ï†úÍ±∞ ÌõÑ Î∂ÑÎ¶¨
                }
        
        combo_info["combo_k_codes"] = list(combo_info["combo_k_codes"])
        
        self.logger.info(f"‚úÖ Combination Îç∞Ïù¥ÌÑ∞: TS ÎîîÎ†âÌÜ†Î¶¨ {len(combo_info['ts_directories'])}Í∞ú, Ï°∞Ìï© K-ÏΩîÎìú {len(combo_info['combo_k_codes'])}Í∞ú")
        return combo_info
    
    def _scan_validation_data(self) -> Dict:
        """Validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù"""
        
        self.logger.info("üîç Validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...")
        
        val_info = {
            "exists": False,
            "single": {"vs_directories": [], "vl_directories": []},
            "combination": {"vs_directories": [], "vl_directories": []},
            "total_images": 0,
            "total_labels": 0
        }
        
        if self.val_images.exists():
            val_info["exists"] = True
            
            # Validation Single Îç∞Ïù¥ÌÑ∞
            val_single_dirs = list(self.val_images.glob("single/VS_*_single"))
            val_info["single"]["vs_directories"] = [d.name for d in sorted(val_single_dirs)]
            
            val_single_lbl_dirs = list(self.val_labels.glob("single/VL_*_single"))
            val_info["single"]["vl_directories"] = [d.name for d in sorted(val_single_lbl_dirs)]
            
            # Validation Combination Îç∞Ïù¥ÌÑ∞
            val_combo_dirs = list(self.val_images.glob("combination/VS_*_combo"))
            val_info["combination"]["vs_directories"] = [d.name for d in sorted(val_combo_dirs)]
            
            val_combo_lbl_dirs = list(self.val_labels.glob("combination/VL_*_combo"))
            val_info["combination"]["vl_directories"] = [d.name for d in sorted(val_combo_lbl_dirs)]
        
        self.logger.info(f"‚úÖ Validation Îç∞Ïù¥ÌÑ∞: Ï°¥Ïû¨ Ïó¨Î∂Ä {val_info['exists']}")
        return val_info
    
    def _build_code_mappings(self) -> None:
        """K-ÏΩîÎìú Î∞è EDI ÏΩîÎìú Îß§Ìïë Íµ¨Ï∂ï"""
        
        self.logger.info("üóÇÔ∏è K-ÏΩîÎìú Î∞è EDI ÏΩîÎìú Îß§Ìïë Íµ¨Ï∂ï Ï§ë...")
        
        # ÏÉòÌîå JSON ÌååÏùºÏóêÏÑú EDI ÏΩîÎìú Ï∂îÏ∂ú
        sample_json_path = self.train_labels / "single" / "TL_1_single" / "K-000059_json" / "K-000059_0_0_0_0_60_000_200.json"
        
        if sample_json_path.exists():
            with open(sample_json_path, 'r', encoding='utf-8') as f:
                sample_data = json.load(f)
                
            if "images" in sample_data and sample_data["images"]:
                image_info = sample_data["images"][0]
                
                # K-ÏΩîÎìú Îß§Ìïë Ï†ïÎ≥¥ Ï∂îÏ∂ú
                k_code = image_info.get("dl_mapping_code", "")
                edi_code = image_info.get("di_edi_code", "")
                drug_name = image_info.get("dl_name", "")
                
                self.k_code_mapping[k_code] = {
                    "edi_code": edi_code,
                    "drug_name": drug_name,
                    "drug_shape": image_info.get("drug_shape", ""),
                    "color_class1": image_info.get("color_class1", ""),
                    "color_class2": image_info.get("color_class2", ""),
                    "print_front": image_info.get("print_front", ""),
                    "print_back": image_info.get("print_back", ""),
                    "company": image_info.get("dl_company", "")
                }
                
                # EDI ÏΩîÎìú Ïó≠Î∞©Ìñ• Îß§Ìïë
                if edi_code:
                    self.edi_code_mapping[edi_code] = k_code
        
        self.logger.info(f"‚úÖ ÏΩîÎìú Îß§Ìïë: K-ÏΩîÎìú {len(self.k_code_mapping)}Í∞ú, EDI ÏΩîÎìú {len(self.edi_code_mapping)}Í∞ú")
    
    def _verify_data_integrity(self) -> None:
        """Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏÇ¨"""
        
        self.logger.info("üîí Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏÇ¨ Ï§ë...")
        
        # ÏÉòÌîå Ïù¥ÎØ∏ÏßÄ-ÎùºÎ≤® Îß§Ïπ≠ Í≤ÄÏÇ¨
        sample_img_dir = self.train_images / "single" / "TS_1_single" / "K-000059"
        sample_lbl_dir = self.train_labels / "single" / "TL_1_single" / "K-000059_json"
        
        if sample_img_dir.exists() and sample_lbl_dir.exists():
            img_files = {f.stem for f in sample_img_dir.glob("*.png")}
            json_files = {f.stem for f in sample_lbl_dir.glob("*.json")}
            
            # Îß§Ïπ≠ÎêòÏßÄ ÏïäÎäî ÌååÏùºÎì§ Ï∞æÍ∏∞
            unmatched_images = img_files - json_files
            unmatched_labels = json_files - img_files
            
            if unmatched_images:
                self.integrity_issues.append(f"Îß§Ïπ≠ÎêòÏßÄ ÏïäÎäî Ïù¥ÎØ∏ÏßÄ: {len(unmatched_images)}Í∞ú")
            
            if unmatched_labels:
                self.integrity_issues.append(f"Îß§Ïπ≠ÎêòÏßÄ ÏïäÎäî ÎùºÎ≤®: {len(unmatched_labels)}Í∞ú")
        
        if not self.integrity_issues:
            self.logger.success("Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Í≤ÄÏÇ¨ ÌÜµÍ≥º")
        else:
            self.logger.warning(f"Î¨¥Í≤∞ÏÑ± Ïù¥Ïäà {len(self.integrity_issues)}Í∞ú Î∞úÍ≤¨")
    
    def _generate_summary(self) -> Dict:
        """Ï†ÑÏ≤¥ Î∂ÑÏÑù Í≤∞Í≥º ÏöîÏïΩ ÏÉùÏÑ±"""
        
        train_data = self.structure_info.get("train_data", {})
        
        summary = {
            "total_ts_single_dirs": len(train_data.get("single", {}).get("ts_directories", [])),
            "total_ts_combo_dirs": len(train_data.get("combination", {}).get("ts_directories", [])),
            "total_k_codes": len(train_data.get("single", {}).get("k_codes", [])),
            "total_combo_k_codes": len(train_data.get("combination", {}).get("combo_k_codes", [])),
            "estimated_total_images": train_data.get("single", {}).get("total_images", 0) + train_data.get("combination", {}).get("total_images", 0),
            "data_integrity_status": "OK" if not self.integrity_issues else "ISSUES_FOUND",
            "ready_for_processing": len(self.integrity_issues) == 0
        }
        
        return summary
    
    def save_analysis_report(self, output_path: str) -> None:
        """Î∂ÑÏÑù Í≤∞Í≥ºÎ•º JSON ÌååÏùºÎ°ú Ï†ÄÏû•"""
        
        output_file = Path(output_path)
        ensure_dir(output_file.parent)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.structure_info, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.success(f"Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏ Ï†ÄÏû• ÏôÑÎ£å: {output_file}")


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    
    # ÏÑ§Ï†ï Î°úÎî©
    config = load_config()
    data_root = config["data"]["root"]
    
    # Îç∞Ïù¥ÌÑ∞ Ïä§Ï∫êÎÑà ÏÉùÏÑ± Î∞è Ïã§Ìñâ
    scanner = PillSnapDataScanner(data_root)
    
    try:
        # Ï†ÑÏ≤¥ Íµ¨Ï°∞ Ïä§Ï∫î
        analysis_result = scanner.scan_full_structure()
        
        # Í≤∞Í≥º Ï∂úÎ†•
        summary = analysis_result["summary"]
        print("\n" + "="*60)
        print("üìä PillSnap Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Î∂ÑÏÑù Í≤∞Í≥º")
        print("="*60)
        print(f"üìÇ Single TS ÎîîÎ†âÌÜ†Î¶¨: {summary['total_ts_single_dirs']}Í∞ú")
        print(f"üîó Combination TS ÎîîÎ†âÌÜ†Î¶¨: {summary['total_ts_combo_dirs']}Í∞ú")
        print(f"üè∑Ô∏è Ï¥ù K-ÏΩîÎìú: {summary['total_k_codes']}Í∞ú")
        print(f"üîó Ï¥ù Ï°∞Ìï© K-ÏΩîÎìú: {summary['total_combo_k_codes']}Í∞ú")
        print(f"üì∑ ÏòàÏÉÅ Ï¥ù Ïù¥ÎØ∏ÏßÄ: {summary['estimated_total_images']:,}Í∞ú")
        print(f"üîí Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ±: {summary['data_integrity_status']}")
        print(f"‚úÖ Ï≤òÎ¶¨ Ï§ÄÎπÑ ÏÉÅÌÉú: {summary['ready_for_processing']}")
        
        # Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•
        report_path = "/mnt/data/exp/exp01/reports/data_structure_analysis.json"
        scanner.save_analysis_report(report_path)
        
        if summary["ready_for_processing"]:
            print("\nüéâ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Î∂ÑÏÑù ÏôÑÎ£å! Îç∞Ïù¥ÌÑ∞ ÌååÏù¥ÌîÑÎùºÏù∏ Íµ¨ÌòÑÏùÑ ÏßÑÌñâÌï† Ïàò ÏûàÏäµÎãàÎã§.")
        else:
            print("\n‚ö†Ô∏è Îç∞Ïù¥ÌÑ∞ Î¨¥Í≤∞ÏÑ± Ïù¥ÏäàÍ∞Ä Î∞úÍ≤¨ÎêòÏóàÏäµÎãàÎã§. ÌôïÏù∏Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.")
        
    except Exception as e:
        print(f"\n‚ùå Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ Î∂ÑÏÑù Ïã§Ìå®: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()