#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨

ì‹¤ì œ í„°ë¯¸ë„ ëª…ë ¹ì–´ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ
ì‹¤ì‹œê°„ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì‹œì—°í•©ë‹ˆë‹¤.
"""

import time
import random
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€  
sys.path.insert(0, str(Path(__file__).parent.parent))


def simulate_stage3_training():
    """Stage 3 í›ˆë ¨ ì‹œë®¬ë ˆì´ì…˜"""
    
    print("ğŸš€ Stage 3 í›ˆë ¨ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
    print("=" * 60)
    print("ë°ì´í„°ì…‹: 100K ìƒ˜í”Œ, 1000 í´ë˜ìŠ¤")
    print("GPU: RTX 5080 16GB")
    print("Progressive Resize: 224px â†’ 384px")
    print("=" * 60)
    print()
    
    # ì´ˆê¸°í™” ë‹¨ê³„
    print("ğŸ”§ ì´ˆê¸°í™” ì¤‘...")
    time.sleep(1)
    print("âœ… GPU ê°ì§€: NVIDIA GeForce RTX 5080")
    print("âœ… ë©”ëª¨ë¦¬ ì²´í¬: 15.5GB ì‚¬ìš© ê°€ëŠ¥")  
    print("âœ… ë°ì´í„° ë¡œë” ì¤€ë¹„ ì™„ë£Œ")
    print("âœ… Progressive Resize ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”")
    print()
    
    # í›ˆë ¨ ë£¨í”„
    total_epochs = 50
    
    for epoch in range(total_epochs):
        # Progressive Resize í•´ìƒë„ ê³„ì‚°
        if epoch < 10:
            resolution = 224
            phase = "Warmup"
            batch_size = 32
        elif epoch < 30:
            progress = (epoch - 10) / 20
            resolution = int(224 + (384 - 224) * (0.5 * (1 - math.cos(3.14159 * progress))))
            resolution = ((resolution + 7) // 8) * 8
            phase = "Transition"
            batch_size = max(16, int(32 * (224 / resolution) ** 1.5))
        else:
            resolution = 384
            phase = "Stable"
            batch_size = 18
        
        # ì—í¬í¬ ì‹œì‘
        print(f"ğŸ“ˆ Epoch {epoch:03d}/{total_epochs} [{phase}] - {resolution}px, Batch={batch_size}")
        
        # ë°°ì¹˜ë³„ ì§„í–‰
        num_batches = 100 + random.randint(-10, 10)
        
        for batch_idx in range(0, num_batches, 10):  # 10ë°°ì¹˜ë§ˆë‹¤ ì¶œë ¥
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œë®¬ë ˆì´ì…˜
            loss = max(0.1, 0.8 - epoch * 0.015 + random.uniform(-0.05, 0.05))
            acc = min(0.95, 0.6 + epoch * 0.007 + random.uniform(-0.02, 0.02))
            gpu_mem = 11.0 + (resolution / 224 - 1) * 3.0 + random.uniform(-0.5, 0.5)
            samples_per_sec = max(40, 100 - (resolution - 224) * 0.2 + random.uniform(-5, 5))
            
            print(f"  Batch {batch_idx:04d}: Loss={loss:.3f}, Acc={acc:.3f}, "
                  f"GPU={gpu_mem:.1f}GB, {samples_per_sec:.1f} sps")
            
            # ë©”ëª¨ë¦¬ ê²½ê³ 
            if gpu_mem > 14.0:
                print(f"  âš ï¸  GPU ë©”ëª¨ë¦¬ ë†’ìŒ: {gpu_mem:.1f}GB")
            
            # í•´ìƒë„ ë³€ê²½ ì•Œë¦¼
            if batch_idx == 0 and epoch in [10, 15, 20, 25, 30]:
                print(f"  ğŸ”„ í•´ìƒë„ ë³€ê²½: {resolution}px, ë°°ì¹˜ í¬ê¸°: {batch_size}")
            
            time.sleep(0.3)  # ì‹¤ì œ í›ˆë ¨ ì†ë„ ì‹œë®¬ë ˆì´ì…˜
        
        # ì—í¬í¬ ìš”ì•½
        val_acc = min(0.92, acc + random.uniform(0.01, 0.03))
        val_loss = max(0.08, loss - random.uniform(0.01, 0.03))
        
        print(f"  âœ… Validation: Loss={val_loss:.3f}, Acc={val_acc:.3f}")
        
        # Stage 4 ì¤€ë¹„ë„ (30 epoch ì´í›„ë¶€í„° í‘œì‹œ)
        if epoch >= 30:
            readiness = min(1.0, (val_acc / 0.85 + (resolution / 384) + (samples_per_sec / 80)) / 3)
            print(f"  ğŸ¯ Stage 4 ì¤€ë¹„ë„: {readiness*100:.1f}%")
            
            if readiness > 0.9:
                print(f"  ğŸš€ Stage 4 ì§„ì… ì¤€ë¹„ ì™„ë£Œ!")
        
        # ìµœì í™” ê¶Œê³  (ê°€ë”)
        if epoch % 10 == 0 and epoch > 0:
            if gpu_mem > 13.0:
                print(f"  ğŸ’¡ ê¶Œê³ : GPU ë©”ëª¨ë¦¬ ë†’ìŒ. ë°°ì¹˜ í¬ê¸° ê°ì†Œ ê¶Œì¥")
            elif samples_per_sec < 70:
                print(f"  ğŸ’¡ ê¶Œê³ : ì²˜ë¦¬ëŸ‰ ë‚®ìŒ. num_workers ì¦ê°€ ê³ ë ¤")
        
        print()
        
        # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if epoch % 10 == 9:
            print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: epoch_{epoch:03d}.pt")
            time.sleep(0.5)
            print()
    
    print("ğŸ‰ Stage 3 í›ˆë ¨ ì™„ë£Œ!")
    print(f"ìµœì¢… ì •í™•ë„: {val_acc:.3f}")
    print(f"ìµœì¢… í•´ìƒë„: {resolution}px")
    print(f"Stage 4 ì¤€ë¹„ë„: {readiness*100:.1f}%")
    
    if readiness > 0.85:
        print("âœ… Stage 4 ì§„ì… ê°€ëŠ¥!")
    else:
        print("â³ ì¶”ê°€ í›ˆë ¨ í•„ìš”")


def simulate_system_monitoring():
    """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜"""
    
    print("ğŸ’» ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 40)
    
    for i in range(20):
        gpu_util = 85 + random.uniform(-10, 10)
        gpu_mem = 12.5 + random.uniform(-1, 2)
        cpu_util = 45 + random.uniform(-15, 20)
        temp = 72 + random.uniform(-5, 8)
        
        print(f"[{time.strftime('%H:%M:%S')}] "
              f"GPU: {gpu_util:.1f}% ({gpu_mem:.1f}GB), "
              f"CPU: {cpu_util:.1f}%, Temp: {temp:.1f}Â°C")
        
        if gpu_util > 95:
            print("  âš ï¸  GPU ì‚¬ìš©ë¥  ë†’ìŒ")
        
        if temp > 80:
            print("  ğŸŒ¡ï¸  GPU ì˜¨ë„ ë†’ìŒ")
            
        time.sleep(2)


def simulate_log_tailing():
    """ì‹¤ì‹œê°„ ë¡œê·¸ tail ì‹œë®¬ë ˆì´ì…˜"""
    
    print("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜")
    print("tail -f /home/max16/pillsnap/logs/training.log")
    print("-" * 50)
    
    log_messages = [
        "INFO: Model loaded successfully",
        "INFO: DataLoader initialized with 8 workers",  
        "INFO: Progressive Resize scheduler ready",
        "INFO: Starting training loop...",
        "TRAIN: Epoch 001, Batch 0050: Loss=0.456, Acc=0.723",
        "TRAIN: GPU Memory: 13.2GB/16.0GB",
        "TRAIN: Samples/sec: 89.3",
        "INFO: Progressive Resize: 224px â†’ 240px",
        "TRAIN: Epoch 001, Batch 0100: Loss=0.445, Acc=0.731",
        "WARNING: GPU memory usage high: 14.1GB",
        "TRAIN: Validation accuracy: 0.756",
        "INFO: Checkpoint saved: model_epoch_001.pt",
        "TRAIN: Epoch 002, Batch 0050: Loss=0.421, Acc=0.748",
        "INFO: Stage 4 readiness: 67.3%",
        "TRAIN: Progressive Resize: 240px â†’ 264px",
        "ERROR: OOM avoided by batch size reduction",
        "INFO: Batch size adjusted: 32 â†’ 28",
        "TRAIN: Epoch 002 complete. Val Acc: 0.762",
    ]
    
    for i, message in enumerate(log_messages * 3):  # ë°˜ë³µ
        timestamp = time.strftime('%H:%M:%S')
        print(f"[{timestamp}] {message}")
        time.sleep(1 + random.uniform(-0.5, 0.5))
        
        # ê°€ë” ë¹ˆ ì¤„ ì¶œë ¥
        if i % 5 == 4:
            print()


if __name__ == "__main__":
    import math
    
    if len(sys.argv) > 1:
        mode = sys.argv[1]
        
        if mode == "training":
            simulate_stage3_training()
        elif mode == "system":
            simulate_system_monitoring()
        elif mode == "logs":
            simulate_log_tailing()
        else:
            print(f"ì‚¬ìš©ë²•: {sys.argv[0]} [training|system|logs]")
    else:
        print("ì‚¬ìš©í•  ì‹œë®¬ë ˆì´ì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. training - Stage 3 í›ˆë ¨ ì‹œë®¬ë ˆì´ì…˜")
        print("2. system - ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§")  
        print("3. logs - ì‹¤ì‹œê°„ ë¡œê·¸ tail")
        
        choice = input("ì„ íƒ (1-3): ").strip()
        
        if choice == "1":
            simulate_stage3_training()
        elif choice == "2":
            simulate_system_monitoring()
        elif choice == "3":
            simulate_log_tailing()
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")