#!/usr/bin/env python3
"""
Progressive Resize ì „ëµ ì‹¤ì œ ë™ì‘ ë°ëª¨

RTX 5080 16GB í™˜ê²½ì—ì„œ Stage 3-4 ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹
í›ˆë ¨ì„ ìœ„í•œ Progressive Resize ì „ëµ ì‹œì—°
"""

import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.data.progressive_resize_strategy import (
    create_progressive_scheduler,
    create_progressive_dataloader,
    ResizeSchedule
)
from src.utils.core import PillSnapLogger


def demo_progressive_resize():
    """Progressive Resize ì „ëµ ë°ëª¨"""
    logger = PillSnapLogger(__name__)
    
    print("=" * 70)
    print("ğŸš€ Progressive Resize ì „ëµ ì‹¤ì œ ë™ì‘ ë°ëª¨")
    print("=" * 70)
    print()
    
    # 1. ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
    print("1ï¸âƒ£ Progressive Resize ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±")
    scheduler = create_progressive_scheduler(
        initial_size=224,
        target_size=384,
        warmup_epochs=5,
        transition_epochs=15,
        schedule=ResizeSchedule.COSINE
    )
    
    # í›ˆë ¨ ìŠ¤ì¼€ì¤„ ìš”ì•½
    summary = scheduler.get_training_schedule_summary()
    print(f"   ì´ ì—í¬í¬: {summary['total_epochs']}")
    print(f"   ë©”ëª¨ë¦¬ í•œê³„: {summary['memory_optimization']['max_memory_gb']}GB (RTX 5080)")
    print()
    
    for phase_name, phase_info in summary['phases'].items():
        print(f"   ğŸ“‹ {phase_name.upper()} ë‹¨ê³„:")
        print(f"      ì—í¬í¬: {phase_info['epochs']}")
        print(f"      í•´ìƒë„: {phase_info['size']}")
        print(f"      ëª©ì : {phase_info['purpose']}")
        print()
    
    # 2. ì—í¬í¬ë³„ í•´ìƒë„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
    print("2ï¸âƒ£ ì—í¬í¬ë³„ í•´ìƒë„ ë° ë°°ì¹˜ í¬ê¸° ë³€í™”")
    print("-" * 60)
    print(f"{'Epoch':<6} {'Size(px)':<10} {'Batch Size':<12} {'Memory Est.':<12} {'Phase':<12}")
    print("-" * 60)
    
    test_epochs = [0, 2, 5, 8, 12, 15, 20, 25, 30, 40, 50]
    
    for epoch in test_epochs:
        # í˜„ì¬ í•´ìƒë„ ê³„ì‚°
        current_size = scheduler.get_current_size(epoch)
        
        # ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        optimal_batch = scheduler.get_optimal_batch_size(base_batch_size=32, current_size=current_size)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (MB)
        memory_est = optimal_batch * (current_size / 224) ** 2 * 2.0  # MB
        
        # ë‹¨ê³„ íŒì •
        if epoch < 5:
            phase = "Warmup"
        elif epoch < 20:
            phase = "Transition"
        else:
            phase = "Stable"
        
        print(f"{epoch:<6} {current_size:<10} {optimal_batch:<12} {memory_est:.1f}MB{'':<5} {phase:<12}")
    
    print("-" * 60)
    print()
    
    # 3. ì‹¤ì‹œê°„ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜
    print("3ï¸âƒ£ ì‹¤ì‹œê°„ í›ˆë ¨ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜")
    print("-" * 50)
    
    for epoch in [0, 5, 10, 15, 20]:
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        batch_size = scheduler.get_optimal_batch_size(32, scheduler.get_current_size(epoch))
        state = scheduler.update_state(epoch=epoch, batch_idx=100, batch_size=batch_size)
        
        print(f"Epoch {epoch:2d}: {state.current_size}px, ë°°ì¹˜={state.batch_size}, "
              f"ë©”ëª¨ë¦¬={state.memory_usage_gb:.1f}GB")
        
        time.sleep(0.1)  # ì‹œê°ì  íš¨ê³¼
    
    print()
    
    # 4. ë³€í™˜ íŒŒì´í”„ë¼ì¸ ìƒì„± ë°ëª¨
    print("4ï¸âƒ£ í•´ìƒë„ë³„ ë³€í™˜ íŒŒì´í”„ë¼ì¸")
    print("-" * 40)
    
    for epoch in [0, 10, 20]:
        current_size = scheduler.get_current_size(epoch)
        scheduler.update_state(epoch, 0, 16)  # ìƒíƒœ ì—…ë°ì´íŠ¸
        
        train_transform = scheduler.create_transform('train')
        val_transform = scheduler.create_transform('val')
        
        print(f"Epoch {epoch:2d} ({current_size}px):")
        print(f"   í›ˆë ¨ìš© ë³€í™˜: {len(train_transform.transforms)}ê°œ ë‹¨ê³„")
        print(f"   ê²€ì¦ìš© ë³€í™˜: {len(val_transform.transforms)}ê°œ ë‹¨ê³„")
        print()
    
    # 5. ì„±ëŠ¥ í†µê³„
    print("5ï¸âƒ£ Progressive Resize ì„±ëŠ¥ í†µê³„")
    print("-" * 40)
    
    stats = scheduler.get_current_stats()
    current_state = stats['current_state']
    perf_stats = stats['performance_stats']
    
    print(f"í˜„ì¬ ìƒíƒœ:")
    print(f"   í•´ìƒë„: {current_state['size']}")
    print(f"   ì—í¬í¬: {current_state['epoch']}")
    print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {current_state['memory_usage_gb']}GB")
    print(f"   ë°°ì¹˜ í¬ê¸°: {current_state['batch_size']}")
    print()
    
    print(f"ì„±ëŠ¥ í†µê³„:")
    print(f"   ì´ í•´ìƒë„ ë³€ê²½: {perf_stats['total_resizes']}íšŒ")
    print(f"   ë°°ì¹˜ í¬ê¸° ì¡°ì •: {perf_stats['batch_adjustments']}íšŒ")
    print(f"   ì´ë ¥ ê¸°ë¡ ìˆ˜: {stats['resize_history_count']}ê°œ")
    print()
    
    # 6. RTX 5080 ìµœì í™” í™•ì¸
    print("6ï¸âƒ£ RTX 5080 16GB í™˜ê²½ ìµœì í™” ê²€ì¦")
    print("-" * 45)
    
    # ë‹¤ì–‘í•œ í•´ìƒë„ì—ì„œ ë©”ëª¨ë¦¬ ì•ˆì „ì„± í™•ì¸
    test_sizes = [224, 288, 352, 384, 448, 512]
    
    print(f"{'Size(px)':<10} {'Max Batch':<12} {'Memory Est.':<15} {'Status':<10}")
    print("-" * 45)
    
    for size in test_sizes:
        max_batch = scheduler._calculate_max_batch_size(size)
        memory_est_gb = max_batch * (size / 224) ** 2 * 0.002  # GB ì¶”ì •
        
        if memory_est_gb <= 14.0:
            status = "âœ… ì•ˆì „"
        elif memory_est_gb <= 15.0:
            status = "âš ï¸  ì£¼ì˜"  
        else:
            status = "âŒ ìœ„í—˜"
        
        print(f"{size:<10} {max_batch:<12} {memory_est_gb:.2f}GB{'':<8} {status:<10}")
    
    print("-" * 45)
    print()
    
    # 7. ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ
    print("7ï¸âƒ£ ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ ì½”ë“œ")
    print("-" * 30)
    
    example_code = '''
# Progressive Resize í›ˆë ¨ ë£¨í”„ ì˜ˆì œ
scheduler = create_progressive_scheduler(
    initial_size=224,
    target_size=384,
    warmup_epochs=10,
    transition_epochs=20
)

for epoch in range(total_epochs):
    # ì—í¬í¬ë³„ í•´ìƒë„ ì—…ë°ì´íŠ¸
    current_size = scheduler.get_current_size(epoch)
    
    # ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
    optimal_batch = scheduler.get_optimal_batch_size(
        base_batch_size=32, 
        current_size=current_size
    )
    
    # ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)
    if scheduler.should_update_transform(epoch, 0):
        new_transform = scheduler.create_transform('train')
        # ë°ì´í„°ì…‹ì— ì ìš©...
    
    # í›ˆë ¨ ë£¨í”„...
    for batch_idx, batch in enumerate(dataloader):
        # ìƒíƒœ ëª¨ë‹ˆí„°ë§
        scheduler.update_state(epoch, batch_idx, optimal_batch)
        
        # ì‹¤ì œ í›ˆë ¨ ì½”ë“œ...
    '''
    
    print(example_code)
    print()
    
    print("=" * 70)
    print("âœ… Progressive Resize ì „ëµ ë°ëª¨ ì™„ë£Œ!")
    print()
    print("ì£¼ìš” ì¥ì :")
    print("  ğŸš€ í›ˆë ¨ ì´ˆê¸° ë¹ ë¥¸ ìˆ˜ë ´ (224px)")
    print("  ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™” (RTX 5080 16GB)")
    print("  ğŸ“ˆ ì ì§„ì  í’ˆì§ˆ í–¥ìƒ (224px â†’ 384px)")
    print("  ğŸ”§ ë°°ì¹˜ í¬ê¸° ìë™ ìµœì í™”")
    print("  ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
    print()
    print("Stage 3-4 ëŒ€ìš©ëŸ‰ í›ˆë ¨ ì¤€ë¹„ ì™„ë£Œ! ğŸ¯")
    print("=" * 70)


if __name__ == "__main__":
    demo_progressive_resize()