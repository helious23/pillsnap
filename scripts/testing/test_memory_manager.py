#!/usr/bin/env python3
"""
Memory State Manager ì‹¤ì œ ë™ì‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import time
import torch
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.utils.memory_state_manager import create_rtx5080_manager, MemoryState


def test_memory_manager():
    """Memory State Manager ì‹¤ì œ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("RTX 5080 Memory State Manager í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # RTX 5080 ìµœì í™” ë§¤ë‹ˆì € ìƒì„±
    manager = create_rtx5080_manager()
    
    # í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    stats = manager.get_current_memory_stats()
    print(f"GPU ì´ ë©”ëª¨ë¦¬: {stats.gpu_total:.1f}GB")
    print(f"í˜„ì¬ ì‚¬ìš©ëŸ‰: {stats.gpu_allocated:.1f}GB")
    print(f"í˜„ì¬ ìƒíƒœ: {stats.current_state.value}")
    print()
    
    # ìƒíƒœ ë³€ê²½ ì½œë°± ë“±ë¡
    def warning_callback(stats):
        print(f"âš ï¸  WARNING ìƒíƒœ ì§„ì…: {stats.gpu_allocated:.1f}GB")
    
    def critical_callback(stats):
        print(f"ğŸš¨ CRITICAL ìƒíƒœ ì§„ì…: {stats.gpu_allocated:.1f}GB")
    
    def emergency_callback(stats):
        print(f"ğŸ’¥ EMERGENCY ìƒíƒœ ì§„ì…: {stats.gpu_allocated:.1f}GB")
    
    manager.register_state_callback(MemoryState.WARNING, warning_callback)
    manager.register_state_callback(MemoryState.CRITICAL, critical_callback) 
    manager.register_state_callback(MemoryState.EMERGENCY, emergency_callback)
    
    # Context Managerë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    with manager:
        print("ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
        
        # ë°°ì¹˜ í¬ê¸° ì¡°ì • í…ŒìŠ¤íŠ¸
        base_batch_size = 32
        safe_batch_size = manager.get_safe_batch_size(base_batch_size)
        print(f"ê¶Œì¥ ë°°ì¹˜ í¬ê¸°: {base_batch_size} â†’ {safe_batch_size}")
        print()
        
        # ë©”ëª¨ë¦¬ ë³´ê³ ì„œ ì¶œë ¥
        report = manager.get_memory_report()
        print("ğŸ“Š ë©”ëª¨ë¦¬ ìƒíƒœ ë³´ê³ ì„œ:")
        print(f"  í˜„ì¬ ìƒíƒœ: {report['current_state']}")
        print(f"  GPU ì‚¬ìš©ë¥ : {report['gpu_memory']['utilization']}")
        print(f"  ì‹œìŠ¤í…œ ê°€ìš© ë©”ëª¨ë¦¬: {report['system_memory']['available']}")
        print()
        
        # ë©”ëª¨ë¦¬ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜ (ì•ˆì „í•œ ìˆ˜ì¤€)
        print("ë©”ëª¨ë¦¬ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì¤‘...")
        try:
            # ì‘ì€ í…ì„œë“¤ë¡œ ì ì§„ì  ë©”ëª¨ë¦¬ ì‚¬ìš©
            tensors = []
            for i in range(5):
                tensor = torch.randn(100, 100, 100, device='cuda' if torch.cuda.is_available() else 'cpu')
                tensors.append(tensor)
                
                current_stats = manager.get_current_memory_stats()
                print(f"  í…ì„œ {i+1}: {current_stats.gpu_allocated:.1f}GB / {current_stats.gpu_total:.1f}GB")
                
                time.sleep(0.5)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸
            print("\nê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬ í…ŒìŠ¤íŠ¸...")
            manager.force_cleanup()
            
            final_stats = manager.get_current_memory_stats()
            print(f"ì •ë¦¬ í›„: {final_stats.gpu_allocated:.1f}GB")
            
            # í…ì„œ í•´ì œ
            del tensors
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
        except Exception as e:
            print(f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print("\n3ì´ˆê°„ ëª¨ë‹ˆí„°ë§ ì§€ì†...")
        time.sleep(3)
    
    print("ëª¨ë‹ˆí„°ë§ ì¢…ë£Œë¨")
    print()
    
    # ìµœì¢… í†µê³„ ì¶œë ¥
    final_report = manager.get_memory_report()
    print("ğŸ“ˆ ìµœì¢… í†µê³„:")
    print(f"  ì´ ì •ë¦¬ íšŸìˆ˜: {final_report['statistics']['total_cleanups']}")
    print(f"  OOM ë°©ì§€ íšŸìˆ˜: {final_report['statistics']['oom_prevented']}")
    print(f"  ìƒíƒœ ì „í™˜ íšŸìˆ˜: {final_report['statistics']['state_transitions']}")
    print(f"  ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©: {final_report['statistics']['max_memory_seen']:.1f}GB")
    
    print("\nâœ… Memory State Manager í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    test_memory_manager()