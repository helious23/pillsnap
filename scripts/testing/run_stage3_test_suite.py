#!/usr/bin/env python3
"""
Stage 3 Classification í”„ë¡œë•ì…˜ê¸‰ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰ê¸°

í”„ë¡œë•ì…˜ ì§ì „ ì² ì €í•œ ê²€ì¦ì„ ìœ„í•œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ:
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: Manifest Creator í•µì‹¬ ê¸°ëŠ¥
- í†µí•© í…ŒìŠ¤íŠ¸: Classification Trainer ë° Training Script
- ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
- GPU í…ŒìŠ¤íŠ¸: ë©”ëª¨ë¦¬ ì•ˆì •ì„± ë° ëˆ„ìˆ˜ íƒì§€ (CUDA ì‚¬ìš© ê°€ëŠ¥ì‹œ)
- ì¢…í•© ë³´ê³ ì„œ: í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ í‰ê°€
"""

import os
import sys
import subprocess
import time
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.utils.core import PillSnapLogger


class Stage3TestSuiteRunner:
    """Stage 3 Classification í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.logger = PillSnapLogger(__name__)
        self.project_root = Path(__file__).parent.parent.parent
        self.test_results = {}
        self.cuda_available = self._check_cuda_availability()
        
        self.logger.info("Stage 3 Classification í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰ê¸° ì´ˆê¸°í™”")
        if self.cuda_available:
            self.logger.info("ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥ - GPU í…ŒìŠ¤íŠ¸ í¬í•¨")
        else:
            self.logger.warning("ğŸ’» CUDA ì—†ìŒ - CPU í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
    
    def _check_cuda_availability(self) -> bool:
        """CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def run_command(self, command: list, test_name: str, timeout: int = 600) -> dict:
        """ëª…ë ¹ì–´ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘"""
        self.logger.info(f"ğŸ”„ {test_name} ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        
        try:
            # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            env = os.environ.copy()
            env['PYTHONPATH'] = str(self.project_root)
            env['PILLSNAP_DATA_ROOT'] = '/home/max16/pillsnap_data'
            
            result = subprocess.run(
                command,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=timeout,
                env=env
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            test_result = {
                'name': test_name,
                'success': result.returncode == 0,
                'duration': duration,
                'returncode': result.returncode,
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            if test_result['success']:
                self.logger.info(f"  âœ… {test_name} ì„±ê³µ ({duration:.1f}ì´ˆ)")
            else:
                self.logger.error(f"  âŒ {test_name} ì‹¤íŒ¨ ({duration:.1f}ì´ˆ)")
                self.logger.error(f"  Error: {result.stderr[-300:]}")  # ë§ˆì§€ë§‰ 300ìë§Œ
            
            return test_result
            
        except subprocess.TimeoutExpired:
            self.logger.error(f"  â° {test_name} íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            return {
                'name': test_name,
                'success': False,
                'duration': timeout,
                'returncode': -1,
                'stdout': '',
                'stderr': f'Test timed out after {timeout} seconds'
            }
        except Exception as e:
            self.logger.error(f"  ğŸ’¥ {test_name} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {
                'name': test_name,
                'success': False,
                'duration': 0,
                'returncode': -1,
                'stdout': '',
                'stderr': str(e)
            }
    
    def run_unit_tests(self):
        """ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸ“‹ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        unit_tests = [
            {
                'name': 'Stage 3 Manifest Creator ë‹¨ìœ„ í…ŒìŠ¤íŠ¸',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/unit/test_stage3_manifest_creator.py',
                    '-v', '--tb=short'
                ],
                'timeout': 900
            }
        ]
        
        unit_results = []
        for test in unit_tests:
            result = self.run_command(test['command'], test['name'], test['timeout'])
            unit_results.append(result)
        
        self.test_results['unit_tests'] = unit_results
        
        success_count = sum(1 for r in unit_results if r['success'])
        self.logger.info(f"ğŸ“‹ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(unit_results)} ì„±ê³µ")
    
    def run_integration_tests(self):
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        integration_tests = [
            {
                'name': 'Classification Trainer í†µí•© í…ŒìŠ¤íŠ¸',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/integration/test_stage3_classification_training.py',
                    '-v', '--tb=short'
                ],
                'timeout': 1500
            },
            {
                'name': 'Training Script í†µí•© í…ŒìŠ¤íŠ¸',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/integration/test_stage3_training_script.py',
                    '-v', '--tb=short'
                ],
                'timeout': 1200
            }
        ]
        
        integration_results = []
        for test in integration_tests:
            result = self.run_command(test['command'], test['name'], test['timeout'])
            integration_results.append(result)
        
        self.test_results['integration_tests'] = integration_results
        
        success_count = sum(1 for r in integration_results if r['success'])
        self.logger.info(f"ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(integration_results)} ì„±ê³µ")
    
    def run_performance_tests(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        performance_tests = [
            {
                'name': 'í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/performance/test_stage3_production_simulation.py',
                    '-v', '--tb=short', '-m', 'not slow'
                ],
                'timeout': 2100
            }
        ]
        
        performance_results = []
        for test in performance_tests:
            result = self.run_command(test['command'], test['name'], test['timeout'])
            performance_results.append(result)
        
        self.test_results['performance_tests'] = performance_results
        
        success_count = sum(1 for r in performance_results if r['success'])
        self.logger.info(f"âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(performance_results)} ì„±ê³µ")
    
    def run_gpu_tests(self):
        """GPU í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (CUDA ì‚¬ìš© ê°€ëŠ¥ì‹œì—ë§Œ)"""
        if not self.cuda_available:
            self.logger.info("ğŸš« CUDA ì—†ìŒ - GPU í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
            self.test_results['gpu_tests'] = []
            return
        
        self.logger.info("ğŸ® GPU í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        gpu_tests = [
            {
                'name': 'GPU ë©”ëª¨ë¦¬ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/smoke/test_stage3_gpu_memory_stability.py',
                    '-v', '--tb=short', '-m', 'not slow'
                ],
                'timeout': 2700
            }
        ]
        
        gpu_results = []
        for test in gpu_tests:
            result = self.run_command(test['command'], test['name'], test['timeout'])
            gpu_results.append(result)
        
        self.test_results['gpu_tests'] = gpu_results
        
        success_count = sum(1 for r in gpu_results if r['success'])
        self.logger.info(f"ğŸ® GPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(gpu_results)} ì„±ê³µ")
    
    def run_long_stability_tests(self):
        """ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (ì„ íƒì )"""
        if os.getenv('RUN_LONG_TESTS', 'false').lower() != 'true':
            self.logger.info("â³ ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (RUN_LONG_TESTS=trueë¡œ ì„¤ì •ì‹œ ì‹¤í–‰)")
            self.test_results['long_stability_tests'] = []
            return
        
        self.logger.info("ğŸ• ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        long_tests = []
        
        # í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜ ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸
        long_tests.append({
            'name': 'ì¥ì‹œê°„ í”„ë¡œë•ì…˜ ì•ˆì •ì„±',
            'command': [
                'python', '-m', 'pytest',
                'tests/performance/test_stage3_production_simulation.py',
                '-v', '--tb=short', '-m', 'slow'
            ],
            'timeout': 3900
        })
        
        # GPU ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (CUDA ì‚¬ìš© ê°€ëŠ¥ì‹œ)
        if self.cuda_available:
            long_tests.append({
                'name': 'ì¥ì‹œê°„ GPU ë©”ëª¨ë¦¬ ì•ˆì •ì„±',
                'command': [
                    'python', '-m', 'pytest',
                    'tests/smoke/test_stage3_gpu_memory_stability.py',
                    '-v', '--tb=short', '-m', 'slow'
                ],
                'timeout': 3900
            })
        
        long_results = []
        for test in long_tests:
            result = self.run_command(test['command'], test['name'], test['timeout'])
            long_results.append(result)
        
        self.test_results['long_stability_tests'] = long_results
        
        success_count = sum(1 for r in long_results if r['success'])
        self.logger.info(f"ğŸ• ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_count}/{len(long_results)} ì„±ê³µ")
    
    def calculate_production_readiness_score(self) -> float:
        """í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì ìˆ˜ ê³„ì‚°"""
        category_weights = {
            'unit_tests': 0.25,        # 25% - ê¸°ë³¸ ê¸°ëŠ¥ ê²€ì¦
            'integration_tests': 0.35, # 35% - ì‹œìŠ¤í…œ í†µí•©
            'performance_tests': 0.25,  # 25% - ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
            'gpu_tests': 0.15          # 15% - GPU ìµœì í™” (CUDA ì—†ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¬ë°°ë¶„)
        }
        
        if not self.cuda_available:
            # GPU í…ŒìŠ¤íŠ¸ ì—†ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¬ë°°ë¶„
            category_weights['unit_tests'] = 0.30
            category_weights['integration_tests'] = 0.40
            category_weights['performance_tests'] = 0.30
            category_weights['gpu_tests'] = 0.0
        
        total_score = 0.0
        total_weight = 0.0
        
        for category, weight in category_weights.items():
            if category in self.test_results and self.test_results[category]:
                results = self.test_results[category]
                success_rate = sum(1 for r in results if r['success']) / len(results)
                total_score += success_rate * weight
                total_weight += weight
        
        return (total_score / total_weight) if total_weight > 0 else 0.0
    
    def generate_comprehensive_report(self):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        self.logger.info("ğŸ“Š ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±...")
        
        total_tests = 0
        total_success = 0
        total_duration = 0
        
        # ë³´ê³ ì„œ í—¤ë”
        report_lines = [
            "=" * 100,
            "ğŸ¯ Stage 3 Classification í”„ë¡œë•ì…˜ê¸‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ",
            f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"ğŸ’» í™˜ê²½: {'CUDA ì‚¬ìš© ê°€ëŠ¥' if self.cuda_available else 'CPU ì „ìš©'}",
            "=" * 100,
            ""
        ]
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼
        category_info = {
            'unit_tests': ('ğŸ“‹ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸', 'í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ê°œë³„ ê²€ì¦'),
            'integration_tests': ('ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸', 'ì‹œìŠ¤í…œ ê°„ ìƒí˜¸ì‘ìš© ê²€ì¦'),
            'performance_tests': ('âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸', 'í”„ë¡œë•ì…˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜'),
            'gpu_tests': ('ğŸ® GPU í…ŒìŠ¤íŠ¸', 'GPU ë©”ëª¨ë¦¬ ì•ˆì •ì„± ê²€ì¦'),
            'long_stability_tests': ('ğŸ• ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸', 'ì¥ê¸°ê°„ ì•ˆì •ì„± ê²€ì¦')
        }
        
        for category, results in self.test_results.items():
            if not results:
                continue
                
            category_name, description = category_info.get(category, (category, ''))
            category_success = sum(1 for r in results if r['success'])
            category_duration = sum(r['duration'] for r in results)
            
            total_tests += len(results)
            total_success += category_success
            total_duration += category_duration
            
            success_rate = (category_success / len(results)) * 100
            status_icon = "âœ…" if success_rate >= 80 else "âš ï¸" if success_rate >= 50 else "âŒ"
            
            report_lines.extend([
                f"{status_icon} {category_name}:",
                f"   ì„¤ëª…: {description}",
                f"   ì„±ê³µ: {category_success}/{len(results)} ({success_rate:.1f}%)",
                f"   ì†Œìš” ì‹œê°„: {category_duration:.1f}ì´ˆ",
                ""
            ])
            
            for result in results:
                test_status = "âœ…" if result['success'] else "âŒ"
                report_lines.append(f"     {test_status} {result['name']} ({result['duration']:.1f}ì´ˆ)")
            
            report_lines.append("")
        
        # í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì ìˆ˜
        production_score = self.calculate_production_readiness_score()
        success_rate = (total_success / total_tests * 100) if total_tests > 0 else 0
        
        # ì¤€ë¹„ë„ ë“±ê¸‰ ê²°ì •
        if production_score >= 0.95:
            readiness_grade = "ğŸ† ìš°ìˆ˜ (Excellent)"
        elif production_score >= 0.90:
            readiness_grade = "ğŸ¯ ì¤€ë¹„ì™„ë£Œ (Production Ready)"
        elif production_score >= 0.80:
            readiness_grade = "âš ï¸ ì£¼ì˜í•„ìš” (Needs Attention)"
        else:
            readiness_grade = "âŒ ë¯¸ì¤€ë¹„ (Not Ready)"
        
        # ì „ì²´ ìš”ì•½
        report_lines.extend([
            "=" * 100,
            "ğŸ“Š ì¢…í•© ê²°ê³¼ ìš”ì•½:",
            f"   ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ",
            f"   ì„±ê³µ: {total_success}ê°œ",
            f"   ì‹¤íŒ¨: {total_tests - total_success}ê°œ",
            f"   ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%",
            f"   ì´ ì†Œìš” ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)",
            "",
            f"ğŸ¯ í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ ì ìˆ˜: {production_score:.1%}",
            f"ğŸ… ì¤€ë¹„ë„ ë“±ê¸‰: {readiness_grade}",
            "=" * 100
        ])
        
        # ê¶Œì¥ì‚¬í•­
        report_lines.extend([
            "",
            "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­:",
            ""
        ])
        
        if production_score >= 0.90:
            report_lines.extend([
                "âœ… í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ!",
                "",
                "ğŸš€ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:",
                "   1. ./scripts/train_stage3.sh ì‹¤í–‰ìœ¼ë¡œ ì‹¤ì œ í•™ìŠµ ì‹œì‘",
                "   2. í•™ìŠµ ì§„í–‰ ëª¨ë‹ˆí„°ë§: ./scripts/monitoring/universal_training_monitor.sh --stage 3",
                "   3. í•™ìŠµ ì™„ë£Œ í›„ Stage 4 Two-Stage í†µí•© ì¤€ë¹„",
                ""
            ])
        else:
            report_lines.extend([
                "âš ï¸ í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì¶”ê°€ ì‘ì—… í•„ìš”",
                "",
                "ğŸ”§ ìš°ì„  í•´ê²° í•­ëª©:"
            ])
            
            for category, results in self.test_results.items():
                if results:
                    failed_tests = [r for r in results if not r['success']]
                    if failed_tests:
                        category_name = category_info.get(category, (category, ''))[0]
                        report_lines.append(f"   - {category_name}: {len(failed_tests)}ê°œ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ ìˆ˜ì •")
            
            report_lines.extend([
                "",
                "ğŸ”„ ìˆ˜ì • í›„ ì¬í…ŒìŠ¤íŠ¸:",
                "   python scripts/testing/run_stage3_test_suite.py",
                ""
            ])
        
        # ì½˜ì†” ì¶œë ¥
        for line in report_lines:
            print(line)
        
        # íŒŒì¼ ì €ì¥
        report_dir = Path("artifacts/stage3/test_reports")
        report_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # í…ìŠ¤íŠ¸ ë³´ê³ ì„œ
        report_file = report_dir / f"stage3_test_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        # JSON ìƒì„¸ ë³´ê³ ì„œ
        json_report = {
            'timestamp': datetime.now().isoformat(),
            'environment': {
                'cuda_available': self.cuda_available,
                'project_root': str(self.project_root)
            },
            'test_results': self.test_results,
            'summary': {
                'total_tests': total_tests,
                'total_success': total_success,
                'success_rate': success_rate,
                'total_duration': total_duration,
                'production_score': production_score,
                'production_ready': production_score >= 0.90
            }
        }
        
        json_file = report_dir / f"stage3_test_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“„ í…ìŠ¤íŠ¸ ë³´ê³ ì„œ: {report_file}")
        self.logger.info(f"ğŸ“„ JSON ë³´ê³ ì„œ: {json_file}")
        
        return production_score >= 0.90
    
    def run_full_test_suite(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Stage 3 Classification í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹œì‘")
        start_time = time.time()
        
        # 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
        self.run_unit_tests()
        
        # 2. í†µí•© í…ŒìŠ¤íŠ¸
        self.run_integration_tests()
        
        # 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        self.run_performance_tests()
        
        # 4. GPU í…ŒìŠ¤íŠ¸ (CUDA ì‚¬ìš© ê°€ëŠ¥ì‹œ)
        self.run_gpu_tests()
        
        # 5. ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (ì„ íƒì )
        self.run_long_stability_tests()
        
        # 6. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        success = self.generate_comprehensive_report()
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        if success:
            self.logger.info(f"ğŸ‰ Stage 3 í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì™„ë£Œ - í”„ë¡œë•ì…˜ ì¤€ë¹„ë¨! ({total_duration:.1f}ì´ˆ)")
            return 0
        else:
            self.logger.error(f"ğŸ’¥ Stage 3 í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ë¯¸ì™„ë£Œ - ì¶”ê°€ ì‘ì—… í•„ìš” ({total_duration:.1f}ì´ˆ)")
            return 1


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¯ Stage 3 Classification í”„ë¡œë•ì…˜ê¸‰ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸")
    print("=" * 80)
    print("ëª©ì : í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì² ì €í•œ ê²€ì¦")
    print("ë²”ìœ„: ë‹¨ìœ„/í†µí•©/ì„±ëŠ¥/GPU í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    runner = Stage3TestSuiteRunner()
    exit_code = runner.run_full_test_suite()
    
    sys.exit(exit_code)


if __name__ == "__main__":
    main()