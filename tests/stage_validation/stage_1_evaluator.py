"""
Stage 1 Evaluator: Progressive Validation + í˜„ì¬ GPU í…ŒìŠ¤íŠ¸ ë°©ë²•ë¡  í†µí•©
- PART_0 OptimizationAdvisor ë°˜ìë™ í‰ê°€ ì‹œìŠ¤í…œ
- í˜„ì¬ GPU ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ì ìš©
- ì‚¬ìš©ì ì„ íƒê¶Œ ì œê³µ (ì™„ì „ ìë™í™” ê¸ˆì§€)
"""

import json
import time
import subprocess
import sys
from pathlib import Path

def run_gpu_smoke_tests():
    """í˜„ì¬ GPU ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ íŒ¨í„´ ì‹¤í–‰"""
    print("ğŸš€ Running GPU Smoke Tests (Stage 1 Pattern)")
    
    results = {}
    
    # GPU-A: í•©ì„± ë°ì´í„° í…ŒìŠ¤íŠ¸ (í˜„ì¬ ë°©ë²•ë¡ )
    try:
        print("  ğŸ“‹ GPU-A: Synthetic Data Test")
        env = {"PYTHONPATH": "/home/max16/pillsnap"}
        result = subprocess.run([
            "/home/max16/pillsnap/.venv/bin/python", 
            "tests/gpu_smoke/gpu_smoke_A.py"
        ], cwd="/home/max16/pillsnap", capture_output=True, text=True, timeout=300, env=env)
        
        if result.returncode == 0:
            print("    âœ… GPU-A passed")
            results["gpu_a"] = {"success": True, "output": result.stdout}
        else:
            print("    âŒ GPU-A failed")
            results["gpu_a"] = {"success": False, "error": result.stderr}
            
    except Exception as e:
        print(f"    ğŸ’¥ GPU-A error: {e}")
        results["gpu_a"] = {"success": False, "error": str(e)}
    
    # GPU-B: ì‹¤ë°ì´í„° í…ŒìŠ¤íŠ¸ (í˜„ì¬ ë°©ë²•ë¡ )
    try:
        print("  ğŸ“‹ GPU-B: Real Data Test")
        env = {"PYTHONPATH": "/home/max16/pillsnap"}
        result = subprocess.run([
            "/home/max16/pillsnap/.venv/bin/python", 
            "tests/gpu_smoke/gpu_smoke_B.py"
        ], cwd="/home/max16/pillsnap", capture_output=True, text=True, timeout=300, env=env)
        
        if result.returncode == 0:
            print("    âœ… GPU-B passed")
            results["gpu_b"] = {"success": True, "output": result.stdout}
        else:
            print("    âŒ GPU-B failed")
            results["gpu_b"] = {"success": False, "error": result.stderr}
            
    except Exception as e:
        print(f"    ğŸ’¥ GPU-B error: {e}")
        results["gpu_b"] = {"success": False, "error": str(e)}
    
    return results

def analyze_stage1_performance(gpu_results):
    """Stage 1 ì„±ëŠ¥ ë¶„ì„ (PART_0 ëª©í‘œ ê¸°ì¤€)"""
    
    # PART_0 Stage 1 ëª©í‘œê°’
    target_metrics = {
        "classification_accuracy": 0.40,  # 50í´ë˜ìŠ¤ ê¸°ì¤€
        "detection_map_0_5": 0.30,       # ê¸°ë³¸ ê²€ì¶œ ê°€ëŠ¥ì„±
        "inference_time_ms": 50,          # RTX 5080 ì‹¤ì‹œê°„ ì²˜ë¦¬
        "memory_usage_gb": 14,            # VRAM ì•ˆì •ì„±
        "data_loading_s_per_batch": 2     # 128GB RAM í™œìš©ë„
    }
    
    # í˜„ì¬ GPU í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
    current_metrics = {}
    
    # GPU-B ì‹¤ë°ì´í„° ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ
    if gpu_results.get("gpu_b", {}).get("success"):
        try:
            # artifacts/gpu_runs ì—ì„œ ìµœì‹  ê²°ê³¼ ë¡œë“œ
            gpu_runs_path = Path("artifacts/gpu_runs")
            if gpu_runs_path.exists():
                latest_run = max(gpu_runs_path.glob("GPU_B_real_*"))
                metrics_file = latest_run / "metrics.json"
                if metrics_file.exists():
                    with open(metrics_file) as f:
                        gpu_metrics = json.load(f)
                    
                    current_metrics = {
                        "classification_accuracy": gpu_metrics.get("val_accuracy", 0.0),
                        "inference_time_ms": gpu_metrics.get("elapsed_seconds", 0) * 1000,
                        "memory_usage_gb": gpu_metrics.get("memory_peak_gb", 0),
                        "gpu_compatibility": True,
                        "pytorch_version": gpu_metrics.get("pytorch_version", "unknown")
                    }
        except Exception as e:
            print(f"  âš ï¸ Could not parse GPU-B metrics: {e}")
    
    return current_metrics, target_metrics

def generate_optimization_advisor_recommendations(current_metrics, target_metrics, gpu_results):
    """OptimizationAdvisor ê¶Œì¥ì‚¬í•­ ìƒì„± (PART_0 ë°˜ìë™í™” ì² í•™)"""
    
    # ê¸°ë³¸ ì²´í¬
    mandatory_checks = {
        "gpu_environment": gpu_results.get("gpu_a", {}).get("success", False),
        "real_data_processing": gpu_results.get("gpu_b", {}).get("success", False),
        "pytorch_compatibility": "2.7.0+cu128" in current_metrics.get("pytorch_version", ""),
        "rtx5080_support": current_metrics.get("gpu_compatibility", False)
    }
    
    # ì„±ëŠ¥ í‰ê°€
    performance_status = {}
    for metric, target in target_metrics.items():
        current = current_metrics.get(metric, 0)
        if metric in ["classification_accuracy", "detection_map_0_5"]:
            performance_status[metric] = current >= target
        elif metric in ["inference_time_ms", "memory_usage_gb", "data_loading_s_per_batch"]:
            performance_status[metric] = current <= target if current > 0 else True  # ì¸¡ì •ë˜ì§€ ì•Šìœ¼ë©´ í†µê³¼
        else:
            performance_status[metric] = True
    
    # ì „ì²´ í‰ê°€
    all_mandatory_passed = all(mandatory_checks.values())
    performance_acceptable = sum(performance_status.values()) >= len(performance_status) * 0.6  # 60% ì´ìƒ
    
    # OptimizationAdvisor ê¶Œì¥ì‚¬í•­ (PART_0 ì‚¬ìš©ì ì„ íƒê¶Œ ì¤‘ì‹¬)
    if all_mandatory_passed and performance_acceptable:
        status = "RECOMMEND_PROCEED"
        confidence = "high"
        reasons = [
            "âœ… GPU í™˜ê²½ ê²€ì¦ ì™„ë£Œ (RTX 5080 + PyTorch 2.7.0+cu128)",
            "âœ… ì‹¤ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸",
            "âœ… ê¸°ë³¸ ì„±ëŠ¥ ì„ê³„ê°’ ë‹¬ì„±",
            "âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •ì„± í™•ì¸"
        ]
        next_actions = [
            "Two-Stage Pipeline ì•„í‚¤í…ì²˜ êµ¬í˜„ (PART_C)",
            "YOLOv11m ê²€ì¶œ ëª¨ë¸ í†µí•©",
            "EfficientNetV2-S ë¶„ë¥˜ ëª¨ë¸ í†µí•©", 
            "Progressive Validation Stage 2 ì§„í–‰"
        ]
    elif all_mandatory_passed:
        status = "SUGGEST_OPTIMIZE"
        confidence = "medium"
        reasons = [
            "âœ… GPU í™˜ê²½ ê²€ì¦ ì™„ë£Œ",
            "âš ï¸ ì¼ë¶€ ì„±ëŠ¥ ì§€í‘œ ê°œì„  í•„ìš”",
            "âœ… ê¸°ë³¸ ê¸°ëŠ¥ ë™ì‘ í™•ì¸"
        ]
        next_actions = [
            "ì„±ëŠ¥ íŠœë‹ í›„ Stage 2 ì§„í–‰ ê¶Œì¥",
            "ë°°ì¹˜ í¬ê¸° ìµœì í™” ê³ ë ¤",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™”"
        ]
    else:
        status = "WARN_STOP"
        confidence = "low"
        reasons = [
            "âŒ í•„ìˆ˜ ì²´í¬ í•­ëª© ì‹¤íŒ¨",
            "âŒ GPU í™˜ê²½ ì„¤ì • ì¬ê²€í†  í•„ìš”"
        ]
        next_actions = [
            "GPU ë“œë¼ì´ë²„ ë° CUDA ì¬ì„¤ì¹˜",
            "PyTorch í˜¸í™˜ì„± ì¬í™•ì¸",
            "í™˜ê²½ ì„¤ì • ë””ë²„ê¹…"
        ]
    
    return {
        "stage": 1,
        "purpose": "pipeline_validation",
        "timestamp": time.time(),
        "status": status,
        "confidence": confidence,
        "mandatory_checks": mandatory_checks,
        "performance_metrics": {
            "current": current_metrics,
            "targets": target_metrics,
            "status": performance_status
        },
        "reasons": reasons,
        "next_actions": next_actions,
        # PART_0 ì‚¬ìš©ì ì„ íƒê¶Œ ì œê³µ
        "user_options": {
            "1": "RECOMMEND_PROCEED: ê¶Œì¥ì‚¬í•­ ì ìš© í›„ Stage 2 ì§„í–‰",
            "2": "SUGGEST_OPTIMIZE: í˜„ì¬ ì„±ëŠ¥ìœ¼ë¡œ Stage 2 ì§„í–‰", 
            "3": "WARN_STOP: ìˆ˜ë™ ë””ë²„ê¹… ëª¨ë“œ"
        }
    }

def display_terminal_dashboard(recommendations):
    """PART_B í„°ë¯¸ë„ ëŒ€ì‹œë³´ë“œ ì¶œë ¥"""
    
    status_colors = {
        "RECOMMEND_PROCEED": "ğŸŸ¢",
        "SUGGEST_OPTIMIZE": "ğŸŸ¡", 
        "WARN_STOP": "ğŸ”´"
    }
    
    print("\n" + "=" * 60)
    print(f"ğŸ¯ Stage 1 OptimizationAdvisor Report")
    print("=" * 60)
    
    print(f"\nğŸ“‹ Status: {status_colors.get(recommendations['status'], 'âšª')} {recommendations['status']}")
    print(f"ğŸ“Š Confidence: {recommendations['confidence'].upper()}")
    print(f"â±ï¸ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(recommendations['timestamp']))}")
    
    print(f"\nğŸ” Mandatory Checks:")
    for check, passed in recommendations['mandatory_checks'].items():
        symbol = "âœ…" if passed else "âŒ"
        print(f"  {symbol} {check}: {'PASS' if passed else 'FAIL'}")
    
    print(f"\nğŸ“ˆ Performance Metrics:")
    perf = recommendations['performance_metrics']
    for metric, target in perf['targets'].items():
        current = perf['current'].get(metric, 'N/A')
        status = perf['status'].get(metric, False)
        symbol = "âœ…" if status else "âš ï¸" 
        print(f"  {symbol} {metric}: {current} (target: {target})")
    
    print(f"\nğŸ’¡ Reasons:")
    for reason in recommendations['reasons']:
        print(f"  â€¢ {reason}")
        
    print(f"\nğŸ¯ Next Actions:")
    for action in recommendations['next_actions']:
        print(f"  â†’ {action}")
    
    print(f"\nğŸ‘¤ User Options:")
    for key, option in recommendations['user_options'].items():
        print(f"  [{key}] {option}")
    
    print("=" * 60)

def evaluate_stage1():
    """Stage 1 OptimizationAdvisor í‰ê°€ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ¯ Stage 1 Progressive Validation")
    print("   Purpose: Pipeline Validation (PART_0 Design)")
    print("   Test Pattern: Current GPU Smoke Tests")
    print("=" * 60)
    
    start_time = time.time()
    
    # 1. GPU ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (í˜„ì¬ ë°©ë²•ë¡ )
    gpu_results = run_gpu_smoke_tests()
    
    # 2. ì„±ëŠ¥ ë¶„ì„
    current_metrics, target_metrics = analyze_stage1_performance(gpu_results)
    
    # 3. OptimizationAdvisor ê¶Œì¥ì‚¬í•­ ìƒì„±
    recommendations = generate_optimization_advisor_recommendations(
        current_metrics, target_metrics, gpu_results
    )
    
    # 4. í„°ë¯¸ë„ ëŒ€ì‹œë³´ë“œ ì¶œë ¥
    display_terminal_dashboard(recommendations)
    
    # 5. ê²°ê³¼ ì €ì¥
    report_path = Path("/mnt/data/exp/exp01/reports/stage_1_evaluation.json")
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text(json.dumps(recommendations, indent=2))
    
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸ Evaluation completed in {elapsed:.1f}s")
    print(f"ğŸ“ Report saved: {report_path}")
    
    # ì„±ê³µ/ì‹¤íŒ¨ ë°˜í™˜
    return recommendations['status'] != "WARN_STOP"

if __name__ == "__main__":
    success = evaluate_stage1()
    sys.exit(0 if success else 1)