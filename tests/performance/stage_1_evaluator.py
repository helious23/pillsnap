#!/usr/bin/env python3
"""
Stage 1 Performance Evaluator
íŒŒì´í”„ë¼ì¸ ê²€ì¦ì„ ìœ„í•œ í‰ê°€ ì‹œìŠ¤í…œ

ëª©í‘œ:
- GPU í™˜ê²½ ê²€ì¦
- ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸
- Stage 2 ì§„í–‰ ê°€ëŠ¥ì„± í‰ê°€
"""

import json
import time
import torch
from pathlib import Path
from typing import Dict, Any

from src.utils.core import PillSnapLogger


class Stage1Evaluator:
    """Stage 1 íŒŒì´í”„ë¼ì¸ ê²€ì¦ í‰ê°€ê¸°"""
    
    def __init__(self):
        self.logger = PillSnapLogger(__name__)
        self.targets = {
            "classification_accuracy": 0.40,  # 50í´ë˜ìŠ¤ ê¸°ì¤€ (ë¬´ì‘ìœ„ 2% Ã— 20ë°°)
            "gpu_memory_limit": 14.0,         # RTX 5080 ì•ˆì •ì„± ê¸°ì¤€
            "pipeline_complete": True,        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
        }
    
    def evaluate_stage_1(self, exp_dir: str = "/home/max16/pillsnap_data/exp/exp01") -> Dict[str, Any]:
        """Stage 1 ì¢…í•© í‰ê°€"""
        
        self.logger.step("Stage 1 í‰ê°€ ì‹œì‘", "íŒŒì´í”„ë¼ì¸ ê²€ì¦")
        
        # 1. GPU í™˜ê²½ ê²€ì¦
        gpu_check = self._check_gpu_environment()
        
        # 2. í•™ìŠµ ê²°ê³¼ í™•ì¸
        training_results = self._check_training_results(exp_dir)
        
        # 3. ì‹œìŠ¤í…œ ì•ˆì •ì„± í™•ì¸
        system_check = self._check_system_stability(exp_dir)
        
        # 4. ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendation = self._generate_stage1_recommendation(
            gpu_check, training_results, system_check
        )
        
        # 5. í‰ê°€ ê²°ê³¼ ì €ì¥
        evaluation_report = {
            "stage": 1,
            "purpose": "pipeline_validation",
            "timestamp": time.time(),
            "gpu_environment": gpu_check,
            "training_results": training_results,
            "system_stability": system_check,
            "recommendation": recommendation,
            "targets": self.targets
        }
        
        self._save_evaluation_report(evaluation_report, exp_dir)
        
        # 6. ì‚¬ìš©ìì—ê²Œ ê²°ê³¼ í‘œì‹œ
        self._present_stage1_results(recommendation)
        
        return evaluation_report
    
    def _check_gpu_environment(self) -> Dict[str, Any]:
        """GPU í™˜ê²½ ê²€ì¦"""
        
        results = {}
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ì„±
        results["cuda_available"] = torch.cuda.is_available()
        
        if results["cuda_available"]:
            # GPU ì •ë³´
            results["gpu_name"] = torch.cuda.get_device_name(0)
            results["gpu_memory_total_gb"] = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            torch.cuda.empty_cache()
            results["gpu_memory_allocated_gb"] = torch.cuda.memory_allocated() / 1024**3
            results["gpu_memory_reserved_gb"] = torch.cuda.memory_reserved() / 1024**3
            
            # RTX 5080 í™•ì¸
            results["is_rtx5080"] = "RTX 5080" in results["gpu_name"]
            results["memory_adequate"] = results["gpu_memory_total_gb"] >= 15.0
        else:
            results["gpu_name"] = "CPU Only"
            results["gpu_memory_total_gb"] = 0.0
            results["is_rtx5080"] = False
            results["memory_adequate"] = False
        
        # PyTorch ë²„ì „
        results["pytorch_version"] = torch.__version__
        results["pytorch_cuda_version"] = torch.version.cuda if torch.cuda.is_available() else "N/A"
        
        return results
    
    def _check_training_results(self, exp_dir: str) -> Dict[str, Any]:
        """í•™ìŠµ ê²°ê³¼ í™•ì¸"""
        
        results = {
            "training_completed": False,
            "best_accuracy": 0.0,
            "model_saved": False,
            "logs_available": False
        }
        
        try:
            # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
            checkpoints_dir = Path(exp_dir) / "checkpoints"
            artifacts_dir = Path("artifacts/models/classification")
            
            # Stage 1 ëª¨ë¸ í™•ì¸ (50í´ë˜ìŠ¤)
            stage1_model = artifacts_dir / "best_classifier_50classes.pt"
            if stage1_model.exists():
                try:
                    checkpoint = torch.load(stage1_model, map_location='cpu')
                    results["best_accuracy"] = checkpoint.get("best_accuracy", 0.0)
                    results["model_saved"] = True
                    results["training_completed"] = True
                except Exception as e:
                    self.logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ë¡œê·¸ íŒŒì¼ í™•ì¸
            log_files = list(Path(exp_dir).glob("logs/*.out"))
            results["logs_available"] = len(log_files) > 0
            
        except Exception as e:
            self.logger.warning(f"í•™ìŠµ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return results
    
    def _check_system_stability(self, exp_dir: str) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± í™•ì¸"""
        
        results = {
            "no_oom_errors": True,
            "no_crashes": True,
            "data_loading_ok": True
        }
        
        try:
            # ì˜¤ë¥˜ ë¡œê·¸ í™•ì¸
            error_logs = list(Path(exp_dir).glob("logs/*.err"))
            for error_log in error_logs:
                if error_log.exists() and error_log.stat().st_size > 0:
                    with open(error_log) as f:
                        content = f.read()
                        
                        if "CUDA out of memory" in content or "OutOfMemoryError" in content:
                            results["no_oom_errors"] = False
                        
                        if "Traceback" in content or "Exception" in content:
                            results["no_crashes"] = False
        except Exception as e:
            self.logger.warning(f"ë¡œê·¸ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return results
    
    def _generate_stage1_recommendation(
        self, 
        gpu_check: Dict, 
        training_results: Dict, 
        system_check: Dict
    ) -> Dict[str, Any]:
        """Stage 1 ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        # í•„ìˆ˜ ì²´í¬
        mandatory_passed = (
            gpu_check.get("cuda_available", False) and
            training_results.get("training_completed", False) and
            system_check.get("no_crashes", True)
        )
        
        # ì„±ëŠ¥ ì²´í¬
        accuracy_ok = training_results.get("best_accuracy", 0) >= self.targets["classification_accuracy"]
        memory_ok = gpu_check.get("memory_adequate", False)
        
        # ì¢…í•© íŒì •
        if mandatory_passed and accuracy_ok and memory_ok:
            decision = "RECOMMEND_PROCEED"
            color = "ğŸŸ¢"
            message = "Stage 1 íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ!"
        elif mandatory_passed and (accuracy_ok or memory_ok):
            decision = "RECOMMEND_PROCEED"
            color = "ğŸŸ¢"
            message = "Stage 1 ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±"
        elif mandatory_passed:
            decision = "SUGGEST_OPTIMIZE"
            color = "ğŸŸ¡"
            message = "Stage 1 ì™„ë£Œ, ì¼ë¶€ ìµœì í™” ê¶Œì¥"
        else:
            decision = "WARN_STOP"
            color = "ğŸ”´"
            message = "Stage 1 í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±"
        
        # êµ¬ì²´ì  ì œì•ˆì‚¬í•­
        suggestions = []
        
        if not gpu_check.get("cuda_available"):
            suggestions.append("CUDA í™˜ê²½ ì„¤ì • í™•ì¸")
        
        if not training_results.get("training_completed"):
            suggestions.append("í•™ìŠµ ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê±°ë‚˜ ì¬ì‹¤í–‰")
        
        if training_results.get("best_accuracy", 0) < self.targets["classification_accuracy"]:
            suggestions.append(f"ì •í™•ë„ ê°œì„  í•„ìš” (í˜„ì¬: {training_results.get('best_accuracy', 0):.1%}, ëª©í‘œ: {self.targets['classification_accuracy']:.1%})")
        
        if not gpu_check.get("memory_adequate"):
            suggestions.append("GPU ë©”ëª¨ë¦¬ í™•ì¸ (RTX 5080 ê¶Œì¥)")
        
        # ì‚¬ìš©ì ì„ íƒ ì˜µì…˜
        if decision == "RECOMMEND_PROCEED":
            user_options = [
                "[1] Stage 2ë¡œ ì§„í–‰",
                "[2] Stage 1 ì¶”ê°€ ìµœì í™”",
                "[3] ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"
            ]
        elif decision == "SUGGEST_OPTIMIZE":
            user_options = [
                "[1] ê¶Œì¥ì‚¬í•­ ì ìš© í›„ ì¬ì‹œë„",
                "[2] í˜„ì¬ ìƒíƒœë¡œ Stage 2 ì§„í–‰",
                "[3] ìƒì„¸ ë””ë²„ê¹… ëª¨ë“œ"
            ]
        else:
            user_options = [
                "[1] í™˜ê²½ ì„¤ì • ì¬ê²€í† ",
                "[2] í•™ìŠµ ì¬ì‹¤í–‰",
                "[3] ê¸°ìˆ  ì§€ì› ìš”ì²­"
            ]
        
        return {
            "decision": decision,
            "color": color,
            "message": message,
            "suggestions": suggestions,
            "user_options": user_options,
            "performance_score": self._calculate_stage1_score(gpu_check, training_results, system_check)
        }
    
    def _calculate_stage1_score(
        self, 
        gpu_check: Dict, 
        training_results: Dict, 
        system_check: Dict
    ) -> float:
        """Stage 1 ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        
        scores = []
        
        # GPU í™˜ê²½ ì ìˆ˜
        if gpu_check.get("cuda_available"):
            scores.append(1.0)
        else:
            scores.append(0.0)
        
        # í•™ìŠµ ì™„ë£Œ ì ìˆ˜
        if training_results.get("training_completed"):
            accuracy = training_results.get("best_accuracy", 0)
            accuracy_score = min(1.0, accuracy / self.targets["classification_accuracy"])
            scores.append(accuracy_score)
        else:
            scores.append(0.0)
        
        # ì•ˆì •ì„± ì ìˆ˜
        stability_score = sum([
            system_check.get("no_oom_errors", True),
            system_check.get("no_crashes", True),
            system_check.get("data_loading_ok", True)
        ]) / 3
        scores.append(stability_score)
        
        return sum(scores) / len(scores) if scores else 0.0
    
    def _save_evaluation_report(self, report: Dict, exp_dir: str) -> None:
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        
        try:
            reports_dir = Path(exp_dir) / "reports"
            reports_dir.mkdir(parents=True, exist_ok=True)
            
            report_path = reports_dir / "stage_1_evaluation.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"Stage 1 í‰ê°€ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
            
        except Exception as e:
            self.logger.error(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _present_stage1_results(self, recommendation: Dict) -> None:
        """Stage 1 í‰ê°€ ê²°ê³¼ í‘œì‹œ"""
        
        print("\n")
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘                    ğŸ¯ Stage 1 í‰ê°€ ì™„ë£Œ                          â•‘")
        print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"â•‘ {recommendation['color']} {recommendation['message']}")
        print("â•‘")
        print(f"â•‘ ğŸ“Š ì„±ëŠ¥ ì ìˆ˜: {recommendation['performance_score']:.3f}")
        print("â•‘")
        
        if recommendation.get('suggestions'):
            print("â•‘ ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, suggestion in enumerate(recommendation['suggestions'], 1):
                print(f"â•‘   {i}. {suggestion}")
            print("â•‘")
        
        print("â•‘ ğŸ­ ì„ íƒ ì˜µì…˜:")
        for option in recommendation['user_options']:
            print(f"â•‘   {option}")
        
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
        try:
            user_choice = input("\nì„ íƒí•˜ì„¸ìš” [1-3]: ")
            print(f"ì„ íƒë¨: {user_choice}")
            
            if user_choice == "1":
                if recommendation["decision"] == "RECOMMEND_PROCEED":
                    print("âœ… Stage 2 ì§„í–‰ì„ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
                    print("python -m src.training.train_classification_stage --stage 2 --epochs 30")
                else:
                    print("ğŸ”§ í™˜ê²½ ì„¤ì •ì„ ì¬ê²€í† í•©ë‹ˆë‹¤...")
            elif user_choice == "2":
                print("ğŸ“Š ì¶”ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
            elif user_choice == "3":
                print("ğŸ” ìƒì„¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸  í‰ê°€ ì¢…ë£Œ")
        except Exception as e:
            print(f"\nâš ï¸  ì…ë ¥ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


def main():
    """CLI ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Stage 1 Performance Evaluator")
    parser.add_argument("--exp-dir", type=str, 
                       default="/home/max16/pillsnap_data/exp/exp01",
                       help="Experiment directory path")
    parser.add_argument("--save-report", action="store_true",
                       help="Save detailed evaluation report")
    
    args = parser.parse_args()
    
    print("ğŸ¯ Stage 1 íŒŒì´í”„ë¼ì¸ ê²€ì¦ í‰ê°€ ì‹œì‘")
    print("=" * 60)
    
    evaluator = Stage1Evaluator()
    evaluation_result = evaluator.evaluate_stage_1(args.exp_dir)
    
    print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: {args.exp_dir}/reports/stage_1_evaluation.json")


if __name__ == "__main__":
    main()