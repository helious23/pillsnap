"""
Combination Pill Training DataLoader
ì¡°í•© ì•½í’ˆ í•™ìŠµìš© ë°ì´í„°ë¡œë”

YOLOv11m ê²€ì¶œìš©:
- 640x640 ì´ë¯¸ì§€ ì „ì²˜ë¦¬
- YOLO ì–´ë…¸í…Œì´ì…˜ í¬ë§· ì§€ì›
- ê²€ì¶œ + ë¶„ë¥˜ Two-Stage íŒŒì´í”„ë¼ì¸ ì§€ì›
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union, Any
import json

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
from PIL import Image

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.data.progressive_validation_sampler import ProgressiveValidationSampler, Stage1SamplingStrategy
from src.data.image_preprocessing_factory import TwoStageImagePreprocessor, PipelineStage
from src.utils.core import PillSnapLogger


class CombinationPillDataset(Dataset):
    """ì¡°í•© ì•½í’ˆ ë°ì´í„°ì…‹ (YOLO ê²€ì¶œìš©)"""
    
    def __init__(
        self,
        image_paths: List[Path],
        annotation_paths: List[Path],
        preprocessor: TwoStageImagePreprocessor,
        is_training: bool = True
    ):
        self.image_paths = image_paths
        self.annotation_paths = annotation_paths
        self.preprocessor = preprocessor
        self.is_training = is_training
        self.logger = PillSnapLogger(__name__)
        
        assert len(image_paths) == len(annotation_paths), "ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ"
        
        self.logger.info(f"CombinationPillDataset ì´ˆê¸°í™”: {len(image_paths)}ê°œ ì´ë¯¸ì§€")
    
    def __len__(self) -> int:
        return len(self.image_paths)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        image_path = self.image_paths[idx]
        annotation_path = self.annotation_paths[idx]
        
        try:
            # ê²€ì¶œìš© ì „ì²˜ë¦¬ (640x640)
            success, processed_tensor, info = self.preprocessor.preprocess_for_detection(
                image_path,
                is_training=self.is_training
            )
            
            if not success:
                self.logger.warning(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {image_path}")
                processed_tensor = torch.zeros(3, 640, 640)
            
            # YOLO ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
            targets = self._load_yolo_annotation(annotation_path)
            
            return processed_tensor, targets
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ {image_path}: {e}")
            return torch.zeros(3, 640, 640), torch.zeros(0, 5)  # ë¹ˆ íƒ€ê²Ÿ
    
    def _load_yolo_annotation(self, annotation_path: Path) -> torch.Tensor:
        """YOLO í˜•ì‹ ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ"""
        try:
            if annotation_path.exists():
                with open(annotation_path, 'r') as f:
                    lines = f.readlines()
                
                targets = []
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        # YOLO í˜•ì‹: class_id, center_x, center_y, width, height
                        class_id = int(parts[0])
                        center_x = float(parts[1])
                        center_y = float(parts[2])
                        width = float(parts[3])
                        height = float(parts[4])
                        
                        targets.append([class_id, center_x, center_y, width, height])
                
                if targets:
                    return torch.tensor(targets, dtype=torch.float32)
            
            # ì–´ë…¸í…Œì´ì…˜ì´ ì—†ê±°ë‚˜ ë¹ˆ ê²½ìš°
            return torch.zeros(0, 5)
            
        except Exception as e:
            self.logger.warning(f"ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ì‹¤íŒ¨ {annotation_path}: {e}")
            return torch.zeros(0, 5)


class CombinationPillTrainingDataLoader:
    """ì¡°í•© ì•½í’ˆ í•™ìŠµìš© ë°ì´í„°ë¡œë” ë§¤ë‹ˆì €"""
    
    def __init__(
        self,
        data_root: str = "/mnt/data/pillsnap_dataset",
        stage: int = 1,
        batch_size: int = 16,  # YOLOëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë” ì‘ì€ ë°°ì¹˜
        num_workers: int = 8,
        pin_memory: bool = True
    ):
        self.data_root = Path(data_root)
        self.stage = stage
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.logger = PillSnapLogger(__name__)
        
        # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        self.preprocessor = TwoStageImagePreprocessor()
        
        # ìƒ˜í”Œë§ ì „ëµ
        if stage == 1:
            self.strategy = Stage1SamplingStrategy(target_images=5000, target_classes=50)
        else:
            raise NotImplementedError(f"Stage {stage} ì•„ì§ êµ¬í˜„ë˜ì§€ ì•ŠìŒ")
        
        self.logger.info(f"CombinationPillTrainingDataLoader ì´ˆê¸°í™” (Stage {stage})")
    
    def prepare_datasets(
        self,
        validation_split: float = 0.2
    ) -> Tuple[CombinationPillDataset, CombinationPillDataset]:
        """í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ì¤€ë¹„"""
        
        self.logger.step("ì¡°í•© ì•½í’ˆ ë°ì´í„°ì…‹ ì¤€ë¹„", f"Stage {self.stage} ê²€ì¶œìš© ìƒ˜í”Œë§")
        
        try:
            # Progressive Validation ìƒ˜í”ŒëŸ¬ë¡œ ë°ì´í„° ìƒì„±
            sampler = ProgressiveValidationSampler(str(self.data_root), self.strategy)
            stage_sample = sampler.generate_stage1_sample()
            
            # ì¡°í•© ì•½í’ˆë§Œ í•„í„°ë§
            combo_samples = []
            for k_code, sample_data in stage_sample['samples'].items():
                combo_images = sample_data.get('combo_images', [])
                combo_samples.extend([(Path(img_path), k_code) for img_path in combo_images])
            
            if not combo_samples:
                self.logger.warning("ì¡°í•© ì•½í’ˆ ì´ë¯¸ì§€ê°€ ì—†ìŒ - ë‹¨ì¼ ì•½í’ˆìœ¼ë¡œ ëŒ€ì²´")
                # ë‹¨ì¼ ì•½í’ˆìœ¼ë¡œ ëŒ€ì²´ (ê²€ì¶œ í•™ìŠµìš©)
                for k_code, sample_data in stage_sample['samples'].items():
                    single_images = sample_data.get('single_images', [])[:10]  # ì œí•œì ìœ¼ë¡œ ì‚¬ìš©
                    combo_samples.extend([(Path(img_path), k_code) for img_path in single_images])
            
            # ì´ë¯¸ì§€ ê²½ë¡œ ë¶„ë¦¬
            image_paths = [img_path for img_path, _ in combo_samples]
            
            # ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ ìƒì„± (ì‹¤ì œë¡œëŠ” YOLO ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì´ ìˆì–´ì•¼ í•¨)
            annotation_paths = []
            for img_path in image_paths:
                # ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ ì¶”ì •
                ann_path = img_path.parent / f"{img_path.stem}.txt"
                if not ann_path.exists():
                    # ë”ë¯¸ ì–´ë…¸í…Œì´ì…˜ ìƒì„±
                    ann_path = self._create_dummy_annotation(img_path)
                annotation_paths.append(ann_path)
            
            self.logger.info(f"ì¡°í•© ì•½í’ˆ ì´ë¯¸ì§€: {len(image_paths)}ê°œ")
            
            # í•™ìŠµ/ê²€ì¦ ë¶„í• 
            import random
            random.seed(42)
            indices = list(range(len(image_paths)))
            random.shuffle(indices)
            
            split_idx = int(len(indices) * (1 - validation_split))
            train_indices = indices[:split_idx]
            val_indices = indices[split_idx:]
            
            # í•™ìŠµ ë°ì´í„°ì…‹
            train_image_paths = [image_paths[i] for i in train_indices]
            train_annotation_paths = [annotation_paths[i] for i in train_indices]
            
            train_dataset = CombinationPillDataset(
                image_paths=train_image_paths,
                annotation_paths=train_annotation_paths,
                preprocessor=self.preprocessor,
                is_training=True
            )
            
            # ê²€ì¦ ë°ì´í„°ì…‹
            val_image_paths = [image_paths[i] for i in val_indices]
            val_annotation_paths = [annotation_paths[i] for i in val_indices]
            
            val_dataset = CombinationPillDataset(
                image_paths=val_image_paths,
                annotation_paths=val_annotation_paths,
                preprocessor=self.preprocessor,
                is_training=False
            )
            
            self.logger.info(f"í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ")
            self.logger.info(f"ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
            self.logger.success("ì¡°í•© ì•½í’ˆ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")
            
            return train_dataset, val_dataset
            
        except Exception as e:
            self.logger.error(f"ì¡°í•© ì•½í’ˆ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_dummy_annotation(self, image_path: Path) -> Path:
        """ë”ë¯¸ YOLO ì–´ë…¸í…Œì´ì…˜ ìƒì„±"""
        try:
            ann_path = image_path.parent / f"{image_path.stem}.txt"
            
            # ë”ë¯¸ ë°”ìš´ë”© ë°•ìŠ¤ (ì´ë¯¸ì§€ ì¤‘ì•™ì— ì•½í’ˆ í•˜ë‚˜)
            dummy_annotation = "0 0.5 0.5 0.3 0.3\n"  # class_id=0, ì¤‘ì•™ ìœ„ì¹˜, 30% í¬ê¸°
            
            with open(ann_path, 'w') as f:
                f.write(dummy_annotation)
            
            return ann_path
            
        except Exception as e:
            self.logger.warning(f"ë”ë¯¸ ì–´ë…¸í…Œì´ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return image_path.parent / "dummy.txt"
    
    def create_dataloaders(
        self,
        train_dataset: CombinationPillDataset,
        val_dataset: CombinationPillDataset
    ) -> Tuple[DataLoader, DataLoader]:
        """YOLOìš© ë°ì´í„°ë¡œë” ìƒì„±"""
        
        try:
            # ì»¤ìŠ¤í…€ collate function (YOLOëŠ” ê°€ë³€ ê¸¸ì´ íƒ€ê²Ÿ)
            def yolo_collate_fn(batch):
                images, targets = zip(*batch)
                images = torch.stack(images, 0)
                
                # íƒ€ê²Ÿì„ ë°°ì¹˜ ì¸ë±ìŠ¤ì™€ í•¨ê»˜ íŒ¨í‚¹
                batch_targets = []
                for i, target in enumerate(targets):
                    if target.size(0) > 0:
                        # ë°°ì¹˜ ì¸ë±ìŠ¤ ì¶”ê°€
                        batch_idx = torch.full((target.size(0), 1), i)
                        target_with_batch = torch.cat([batch_idx, target], dim=1)
                        batch_targets.append(target_with_batch)
                
                if batch_targets:
                    targets = torch.cat(batch_targets, 0)
                else:
                    targets = torch.zeros(0, 6)  # batch_idx + 5 YOLO params
                
                return images, targets
            
            # í•™ìŠµ ë°ì´í„°ë¡œë”
            train_loader = DataLoader(
                train_dataset,
                batch_size=self.batch_size,
                shuffle=True,
                num_workers=self.num_workers,
                pin_memory=self.pin_memory,
                collate_fn=yolo_collate_fn,
                drop_last=True
            )
            
            # ê²€ì¦ ë°ì´í„°ë¡œë”
            val_loader = DataLoader(
                val_dataset,
                batch_size=self.batch_size,
                shuffle=False,
                num_workers=self.num_workers,
                pin_memory=self.pin_memory,
                collate_fn=yolo_collate_fn,
                drop_last=False
            )
            
            self.logger.info(f"YOLO ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ")
            self.logger.info(f"  í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
            self.logger.info(f"  ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
            
            return train_loader, val_loader
            
        except Exception as e:
            self.logger.error(f"YOLO ë°ì´í„°ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def get_stage_dataloaders(
        self,
        validation_split: float = 0.2
    ) -> Tuple[DataLoader, DataLoader, Dict[str, Any]]:
        """Stageë³„ ì¡°í•© ì•½í’ˆ ë°ì´í„°ë¡œë” ìƒì„±"""
        
        # ë°ì´í„°ì…‹ ì¤€ë¹„
        train_dataset, val_dataset = self.prepare_datasets(validation_split)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader, val_loader = self.create_dataloaders(train_dataset, val_dataset)
        
        # ë©”íƒ€ì •ë³´
        metadata = {
            'num_classes': 1,  # ë‹¨ì¼ í´ë˜ìŠ¤ (pill)
            'train_size': len(train_dataset),
            'val_size': len(val_dataset),
            'batch_size': self.batch_size,
            'stage': self.stage,
            'annotation_format': 'YOLO'
        }
        
        return train_loader, val_loader, metadata


def main():
    """ì¡°í•© ì•½í’ˆ ë°ì´í„°ë¡œë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ“Š Combination Pill Training DataLoader Test")
    print("=" * 60)
    
    try:
        # ë°ì´í„°ë¡œë” ë§¤ë‹ˆì € ìƒì„±
        dataloader_manager = CombinationPillTrainingDataLoader(
            stage=1,
            batch_size=8,  # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë°°ì¹˜
            num_workers=2
        )
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader, val_loader, metadata = dataloader_manager.get_stage_dataloaders()
        
        print(f"âœ… ì¡°í•© ì•½í’ˆ ë°ì´í„°ë¡œë” ìƒì„± ì„±ê³µ")
        print(f"   í•™ìŠµ ë°ì´í„°: {metadata['train_size']}ê°œ")
        print(f"   ê²€ì¦ ë°ì´í„°: {metadata['val_size']}ê°œ")
        print(f"   ë°°ì¹˜ ìˆ˜: í•™ìŠµ {len(train_loader)}, ê²€ì¦ {len(val_loader)}")
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
        if len(train_loader) > 0:
            train_batch = next(iter(train_loader))
            images, targets = train_batch
            
            print(f"   ë°°ì¹˜ ëª¨ì–‘: ì´ë¯¸ì§€ {images.shape}, íƒ€ê²Ÿ {targets.shape}")
            print(f"   ì´ë¯¸ì§€ ë²”ìœ„: [{images.min():.3f}, {images.max():.3f}]")
            print(f"   íƒ€ê²Ÿ ìˆ˜: {targets.size(0)}ê°œ ë°”ìš´ë”© ë°•ìŠ¤")
        
        print("\nâœ… ì¡°í•© ì•½í’ˆ ë°ì´í„°ë¡œë” í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()