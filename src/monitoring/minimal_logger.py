"""
PillSnap ML ìµœì†Œì…‹ ë¡œê¹… ì‹œìŠ¤í…œ (1ë‹¨ê³„ í•„ìˆ˜)

í•µì‹¬ ë©”íŠ¸ë¦­ë§Œ ê¸°ë¡í•˜ì—¬ ìš©ëŸ‰/ì‹œê°„ ì ˆê°:
- ë¶„ë¥˜: top-1/top-5/macro-F1(ì „ì²´+ë„ë©”ì¸)
- ê²€ì¶œ: mAP@0.5/Recall/Precision(ë„ë©”ì¸) + selected_confidence
- íŒŒì´í”„ë¼ì¸: det/crop/cls/total(ms) (+ p50/p95/p99)
- ì‹œìŠ¤í…œ: VRAM current/peak, grad-norm(after_clipping), 3epochë§ˆë‹¤ before_clipping ìŠ¤ëƒ…ìƒ·

RTX 5080 ìµœì í™”
"""

import time
import json
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, asdict
from pathlib import Path
from collections import defaultdict, deque
import statistics

import torch
import numpy as np

from src.utils.core import PillSnapLogger


@dataclass
class MinimalLoggingConfig:
    """ìµœì†Œì…‹ ë¡œê¹… ì„¤ì • (1ë‹¨ê³„ í•„ìˆ˜)"""
    
    # ë¡œê¹… ì£¼ê¸°
    log_every_n_steps: int = 10           # N stepë§ˆë‹¤ ë¡œê¹…
    log_validation_always: bool = True     # ê²€ì¦ì‹œ í•­ìƒ ë¡œê¹…
    
    # ë©”íŠ¸ë¦­ ì„ íƒ
    classification_metrics: List[str] = None  # ["top1", "top5", "macro_f1", "domain_f1"]
    detection_metrics: List[str] = None       # ["map_0_5", "recall", "precision", "confidence"]
    pipeline_metrics: List[str] = None        # ["det_ms", "crop_ms", "cls_ms", "total_ms"]
    system_metrics: List[str] = None          # ["vram_current", "vram_peak", "grad_norm"]
    
    # ì‹œìŠ¤í…œ ë¡œê¹…
    log_grad_norm_before_clipping_every: int = 3  # 3 epochë§ˆë‹¤ clipping ì „ grad norm
    track_percentiles: bool = True                 # p50/p95/p99 ì¶”ì 
    
    # ì €ì¥ ì˜µì…˜
    save_to_json: bool = True
    save_to_tensorboard: bool = False  # ìµœì†Œì…‹ì´ë¯€ë¡œ ê¸°ë³¸ ë¹„í™œì„±í™”
    
    def __post_init__(self):
        if self.classification_metrics is None:
            self.classification_metrics = ["top1", "top5", "macro_f1", "domain_f1"]
        if self.detection_metrics is None:
            self.detection_metrics = ["map_0_5", "recall", "precision", "confidence"]
        if self.pipeline_metrics is None:
            self.pipeline_metrics = ["det_ms", "crop_ms", "cls_ms", "total_ms"]
        if self.system_metrics is None:
            self.system_metrics = ["vram_current", "vram_peak", "grad_norm"]


class PipelineTotalTimer:
    """íŒŒì´í”„ë¼ì¸ total(ms) ë³´ì¥ Context Manager"""
    
    def __init__(self, logger_instance, operation: str = "total"):
        self.logger = logger_instance
        self.operation = operation
        self.start_time = None
        
    def __enter__(self):
        self.start_time = time.perf_counter()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.start_time is not None:
            total_ms = (time.perf_counter() - self.start_time) * 1000
            self.logger.record_pipeline_timing(self.operation, total_ms)
        return False


class PerformanceTracker:
    """ì„±ëŠ¥ ì¶”ì ê¸° (íŒŒì´í”„ë¼ì¸ ë ˆì´í„´ì‹œìš©)"""
    
    def __init__(self, track_percentiles: bool = True, window_size: int = 100):
        self.track_percentiles = track_percentiles
        self.window_size = window_size
        
        # ì‹œê°„ ì¸¡ì • ì €ì¥ì†Œ
        self.timings = defaultdict(lambda: deque(maxlen=window_size))
        self.current_timings = {}
        
    def start_timer(self, operation: str) -> None:
        """íƒ€ì´ë¨¸ ì‹œì‘"""
        self.current_timings[operation] = time.perf_counter()
    
    def end_timer(self, operation: str) -> float:
        """íƒ€ì´ë¨¸ ì¢…ë£Œ ë° ì‹œê°„ ê¸°ë¡"""
        if operation not in self.current_timings:
            return 0.0
        
        elapsed_ms = (time.perf_counter() - self.current_timings[operation]) * 1000
        self.timings[operation].append(elapsed_ms)
        
        return elapsed_ms
    
    def get_timing_stats(self, operation: str) -> Dict[str, float]:
        """íŠ¹ì • ì‘ì—…ì˜ íƒ€ì´ë° í†µê³„ ë°˜í™˜"""
        if operation not in self.timings or len(self.timings[operation]) == 0:
            return {"mean": 0.0, "p50": 0.0, "p95": 0.0, "p99": 0.0}
        
        values = list(self.timings[operation])
        
        stats = {
            "mean": statistics.mean(values)
        }
        
        if self.track_percentiles and len(values) >= 3:
            sorted_values = sorted(values)
            n = len(sorted_values)
            
            stats.update({
                "p50": sorted_values[int(n * 0.50)],
                "p95": sorted_values[int(n * 0.95)],
                "p99": sorted_values[int(n * 0.99)]
            })
        else:
            stats.update({"p50": stats["mean"], "p95": stats["mean"], "p99": stats["mean"]})
        
        return stats
    
    def get_all_timing_stats(self) -> Dict[str, Dict[str, float]]:
        """ëª¨ë“  ì‘ì—…ì˜ íƒ€ì´ë° í†µê³„ ë°˜í™˜"""
        return {
            operation: self.get_timing_stats(operation)
            for operation in self.timings.keys()
        }


class MinimalLogger:
    """ìµœì†Œì…‹ ë¡œê¹… ì‹œìŠ¤í…œ (1ë‹¨ê³„ í•„ìˆ˜)"""
    
    def __init__(self, config: MinimalLoggingConfig, save_dir: Optional[str] = None):
        """
        Args:
            config: ìµœì†Œì…‹ ë¡œê¹… ì„¤ì •
            save_dir: ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.config = config
        self.logger = PillSnapLogger(__name__)
        
        # ì €ì¥ ê²½ë¡œ ì„¤ì •
        if save_dir is None:
            save_dir = Path("artifacts/logs/minimal")
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„±ëŠ¥ ì¶”ì ê¸°
        self.performance_tracker = PerformanceTracker(
            track_percentiles=config.track_percentiles
        )
        
        # ë¡œê·¸ ì €ì¥ì†Œ
        self.log_history = []
        self.step_count = 0
        self.epoch_count = 0
        
        # VRAM í”¼í¬ ì¶”ì 
        self.vram_peak = 0.0
        
        # Gradient norm íˆìŠ¤í† ë¦¬
        self.grad_norm_history = deque(maxlen=1000)
        
        self.logger.info(f"ğŸ“ ìµœì†Œì…‹ ë¡œê±° ì´ˆê¸°í™” - ì €ì¥ ìœ„ì¹˜: {self.save_dir}")
    
    def log_step(
        self,
        step: int,
        epoch: int,
        metrics: Dict[str, Any],
        force_log: bool = False
    ) -> None:
        """ìŠ¤í…ë³„ ë¡œê¹…"""
        self.step_count = step
        self.epoch_count = epoch
        
        # ë¡œê¹… ì£¼ê¸° í™•ì¸
        should_log = (
            force_log or
            step % self.config.log_every_n_steps == 0 or
            step == 0
        )
        
        if not should_log:
            return
        
        # ë¡œê·¸ ì—”íŠ¸ë¦¬ ìƒì„±
        log_entry = {
            "timestamp": time.time(),
            "step": step,
            "epoch": epoch,
            "metrics": self._filter_metrics(metrics)
        }
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¶”ê°€
        system_metrics = self._collect_system_metrics()
        log_entry["metrics"]["system"] = system_metrics
        
        # íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ ì¶”ê°€
        pipeline_metrics = self._collect_pipeline_metrics()
        if pipeline_metrics:
            log_entry["metrics"]["pipeline"] = pipeline_metrics
        
        # ì €ì¥ ë° ì¶œë ¥
        self.log_history.append(log_entry)
        self._log_to_console(log_entry)
        
        if self.config.save_to_json:
            self._save_to_json()
    
    def log_validation(
        self,
        epoch: int,
        metrics: Dict[str, Any],
        selected_confidences: Optional[Dict[str, float]] = None
    ) -> None:
        """ê²€ì¦ ë¡œê¹… (í•­ìƒ ê¸°ë¡)"""
        log_entry = {
            "timestamp": time.time(),
            "type": "validation",
            "epoch": epoch,
            "metrics": self._filter_metrics(metrics)
        }
        
        # Selected confidence ì¶”ê°€
        if selected_confidences:
            log_entry["selected_confidences"] = selected_confidences
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¶”ê°€
        system_metrics = self._collect_system_metrics()
        log_entry["metrics"]["system"] = system_metrics
        
        # íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ ì¶”ê°€
        pipeline_metrics = self._collect_pipeline_metrics()
        if pipeline_metrics:
            log_entry["metrics"]["pipeline"] = pipeline_metrics
        
        # ì €ì¥ ë° ì¶œë ¥
        self.log_history.append(log_entry)
        self._log_to_console(log_entry, is_validation=True)
        
        if self.config.save_to_json:
            self._save_to_json()
    
    def _filter_metrics(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """í•µì‹¬ ë©”íŠ¸ë¦­ë§Œ í•„í„°ë§ (ë„ë©”ì¸ë³„ Top-1/Top-5 ì§€ì›)"""
        filtered = {}
        
        # ë¶„ë¥˜ ë©”íŠ¸ë¦­ í•„í„°ë§ (ë„ë©”ì¸ë³„ ì§€ì›)
        if "classification" in metrics:
            cls_metrics = {}
            for metric in self.config.classification_metrics:
                if metric in metrics["classification"]:
                    cls_metrics[metric] = metrics["classification"][metric]
                    
                # ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ì¶”ê°€ ê²€ì‚¬ (flat keys)
                elif metric in ["top1", "top5", "macro_f1", "f1"] and f"{metric}_single" in metrics["classification"]:
                    # Flat format: top1_single, top5_single, macro_f1_single, f1_single, etc.
                    for domain in ["single", "combination"]:
                        domain_key = f"{metric}_{domain}"
                        if domain_key in metrics["classification"]:
                            cls_metrics[domain_key] = metrics["classification"][domain_key]
                            
                # ì¤‘ì²© í˜•ì‹ë„ ì§€ì› (nested format)
                elif metric in ["top1", "top5", "macro_f1", "f1"] and "domain_metrics" in metrics["classification"]:
                    domain_metrics = metrics["classification"]["domain_metrics"]
                    if isinstance(domain_metrics, dict):
                        for domain in ["single", "combination"]:
                            if domain in domain_metrics and metric in domain_metrics[domain]:
                                cls_metrics[f"{metric}_{domain}"] = domain_metrics[domain][metric]
                                
            if cls_metrics:
                filtered["classification"] = cls_metrics
        
        # ê²€ì¶œ ë©”íŠ¸ë¦­ í•„í„°ë§
        if "detection" in metrics:
            det_metrics = {}
            for metric in self.config.detection_metrics:
                if metric in metrics["detection"]:
                    det_metrics[metric] = metrics["detection"][metric]
            if det_metrics:
                filtered["detection"] = det_metrics
        
        # ê¸°íƒ€ ë©”íŠ¸ë¦­ (loss ë“±)
        for key, value in metrics.items():
            if key not in ["classification", "detection", "pipeline", "system"]:
                if isinstance(value, (int, float, str)):
                    filtered[key] = value
        
        return filtered
    
    def _collect_system_metrics(self) -> Dict[str, float]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        system_metrics = {}
        
        # VRAM ë©”íŠ¸ë¦­
        if torch.cuda.is_available() and "vram_current" in self.config.system_metrics:
            current_vram = torch.cuda.memory_allocated() / 1024**3  # GB
            reserved_vram = torch.cuda.memory_reserved() / 1024**3  # GB
            
            # í”¼í¬ ì¶”ì 
            self.vram_peak = max(self.vram_peak, reserved_vram)
            
            system_metrics.update({
                "vram_current": round(current_vram, 2),
                "vram_reserved": round(reserved_vram, 2),
                "vram_peak": round(self.vram_peak, 2)
            })
        
        # Gradient norm (after clipping)
        if hasattr(self, '_last_grad_norm') and "grad_norm" in self.config.system_metrics:
            system_metrics["grad_norm_after_clipping"] = self._last_grad_norm
        
        return system_metrics
    
    def _collect_pipeline_metrics(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        pipeline_stats = self.performance_tracker.get_all_timing_stats()
        
        if not pipeline_stats:
            return {}
        
        # í•„í„°ë§ëœ íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­
        filtered_pipeline = {}
        for operation in self.config.pipeline_metrics:
            if operation.replace("_ms", "") in pipeline_stats:
                op_key = operation.replace("_ms", "")
                stats = pipeline_stats[op_key]
                
                filtered_pipeline[operation] = round(stats["mean"], 2)
                
                if self.config.track_percentiles:
                    filtered_pipeline[f"{operation}_p50"] = round(stats["p50"], 2)
                    filtered_pipeline[f"{operation}_p95"] = round(stats["p95"], 2)
                    filtered_pipeline[f"{operation}_p99"] = round(stats["p99"], 2)
        
        return filtered_pipeline
    
    def record_pipeline_timing(self, operation: str, elapsed_ms: float) -> None:
        """íŒŒì´í”„ë¼ì¸ íƒ€ì´ë° ê¸°ë¡"""
        # ì„±ëŠ¥ ì¶”ì ê¸°ì— ì§ì ‘ ê¸°ë¡
        self.performance_tracker.timings[operation].append(elapsed_ms)
    
    def start_pipeline_timer(self, operation: str) -> None:
        """íŒŒì´í”„ë¼ì¸ íƒ€ì´ë¨¸ ì‹œì‘"""
        self.performance_tracker.start_timer(operation)
    
    def end_pipeline_timer(self, operation: str) -> float:
        """íŒŒì´í”„ë¼ì¸ íƒ€ì´ë¨¸ ì¢…ë£Œ"""
        return self.performance_tracker.end_timer(operation)
    
    def record_grad_norm(self, grad_norm: float, before_clipping: bool = False) -> None:
        """Gradient norm ê¸°ë¡"""
        if before_clipping:
            # 3 epochë§ˆë‹¤ before_clipping ê¸°ë¡
            if self.epoch_count % self.config.log_grad_norm_before_clipping_every == 0:
                self.grad_norm_history.append({
                    "epoch": self.epoch_count,
                    "step": self.step_count,
                    "grad_norm_before_clipping": grad_norm,
                    "timestamp": time.time()
                })
        else:
            # After clippingì€ í•­ìƒ ê¸°ë¡
            self._last_grad_norm = grad_norm
    
    def pipeline_timer(self, operation: str = "total") -> PipelineTotalTimer:
        """íŒŒì´í”„ë¼ì¸ total(ms) ë³´ì¥ Context Manager ìƒì„±
        
        Usage:
            with logger.pipeline_timer("total") as timer:
                # íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰
                detection_result = detect(image)
                crop_result = crop(detection_result) 
                classification_result = classify(crop_result)
        """
        return PipelineTotalTimer(self, operation)
    
    def _log_to_console(self, log_entry: Dict[str, Any], is_validation: bool = False) -> None:
        """ì½˜ì†” ì¶œë ¥"""
        entry_type = "VAL" if is_validation else "TRAIN"
        step = log_entry.get("step", "")
        epoch = log_entry.get("epoch", "")
        
        # í•µì‹¬ ë©”íŠ¸ë¦­ë§Œ ê°„ë‹¨íˆ ì¶œë ¥
        metrics = log_entry.get("metrics", {})
        
        output_parts = [f"[{entry_type}] E{epoch}"]
        if step:
            output_parts.append(f"S{step}")
        
        # ë¶„ë¥˜ ë©”íŠ¸ë¦­ (ë„ë©”ì¸ë³„ í‘œì‹œ ì§€ì›)
        if "classification" in metrics:
            cls_metrics = metrics["classification"]
            
            # ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ì´ ìˆëŠ”ì§€ í™•ì¸
            has_domain_metrics = any(key.endswith('_single') or key.endswith('_combination') for key in cls_metrics.keys())
            
            if has_domain_metrics:
                # ë„ë©”ì¸ë³„ ë¶„ë¦¬ ì¶œë ¥: CLS[S: t1=0.43/t5=0.75/F1=0.39 | C: t1=0.31/t5=0.62/F1=0.28]
                single_parts = []
                combo_parts = []
                
                # Single domain metrics
                if "top1_single" in cls_metrics:
                    single_parts.append(f"t1={cls_metrics['top1_single']:.2f}")
                if "top5_single" in cls_metrics:
                    single_parts.append(f"t5={cls_metrics['top5_single']:.2f}")
                if "macro_f1_single" in cls_metrics:
                    single_parts.append(f"F1={cls_metrics['macro_f1_single']:.2f}")
                elif "f1_single" in cls_metrics:
                    single_parts.append(f"F1={cls_metrics['f1_single']:.2f}")
                    
                # Combination domain metrics
                if "top1_combination" in cls_metrics:
                    combo_parts.append(f"t1={cls_metrics['top1_combination']:.2f}")
                if "top5_combination" in cls_metrics:
                    combo_parts.append(f"t5={cls_metrics['top5_combination']:.2f}")
                if "macro_f1_combination" in cls_metrics:
                    combo_parts.append(f"F1={cls_metrics['macro_f1_combination']:.2f}")
                elif "f1_combination" in cls_metrics:
                    combo_parts.append(f"F1={cls_metrics['f1_combination']:.2f}")
                    
                # ë„ë©”ì¸ë³„ ì¶œë ¥ ì¡°í•©
                domain_output = "CLS["
                if single_parts:
                    domain_output += f"S: {'/'.join(single_parts)}"
                if combo_parts:
                    if single_parts:
                        domain_output += " | "
                    domain_output += f"C: {'/'.join(combo_parts)}"
                domain_output += "]"
                
                if single_parts or combo_parts:
                    output_parts.append(domain_output)
            else:
                # ê¸°ì¡´ ì „ì²´ ë©”íŠ¸ë¦­ ì¶œë ¥
                if "top1" in cls_metrics:
                    output_parts.append(f"Top1:{cls_metrics['top1']:.3f}")
                if "macro_f1" in cls_metrics:
                    output_parts.append(f"F1:{cls_metrics['macro_f1']:.3f}")
        
        # ê²€ì¶œ ë©”íŠ¸ë¦­
        if "detection" in metrics:
            det_metrics = metrics["detection"]
            if "map_0_5" in det_metrics:
                output_parts.append(f"mAP:{det_metrics['map_0_5']:.3f}")
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        if "system" in metrics:
            sys_metrics = metrics["system"]
            if "vram_current" in sys_metrics:
                output_parts.append(f"VRAM:{sys_metrics['vram_current']:.1f}GB")
        
        # Selected confidence (ê²€ì¦ì‹œ)
        if "selected_confidences" in log_entry:
            confs = log_entry["selected_confidences"]
            conf_strs = [f"{k}:{v:.2f}" for k, v in confs.items()]
            output_parts.append(f"Conf:[{','.join(conf_strs)}]")
        
        output = " | ".join(output_parts)
        self.logger.info(output)
    
    def _save_to_json(self) -> None:
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = time.strftime("%Y%m%d")
        json_file = self.save_dir / f"minimal_log_{timestamp}.json"
        
        # ìµœì‹  100ê°œë§Œ ìœ ì§€í•˜ì—¬ íŒŒì¼ í¬ê¸° ì œí•œ
        recent_logs = self.log_history[-100:] if len(self.log_history) > 100 else self.log_history
        
        log_data = {
            "config": asdict(self.config),
            "logs": recent_logs,
            "grad_norm_history": list(self.grad_norm_history)
        }
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False, default=str)
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """ìš”ì•½ í†µê³„ ë°˜í™˜"""
        if not self.log_history:
            return {}
        
        return {
            "total_steps": self.step_count,
            "total_epochs": self.epoch_count,
            "log_entries": len(self.log_history),
            "vram_peak_gb": self.vram_peak,
            "pipeline_stats": self.performance_tracker.get_all_timing_stats(),
            "recent_grad_norms": list(self.grad_norm_history)[-10:]  # ìµœê·¼ 10ê°œ
        }


if __name__ == "__main__":
    print("ğŸ§ª ìµœì†Œì…‹ ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ í•„ìˆ˜ + ë„ë©”ì¸ë³„ + total(ms) ë³´ì¥)")
    print("=" * 80)
    
    # ì„¤ì • í…ŒìŠ¤íŠ¸
    config = MinimalLoggingConfig(
        log_every_n_steps=5,
        track_percentiles=True
    )
    
    logger = MinimalLogger(config, save_dir="/tmp/test_minimal_logs")
    print(f"âœ… ë¡œê±° ì´ˆê¸°í™”: {len(config.classification_metrics)}ê°œ ë¶„ë¥˜ ë©”íŠ¸ë¦­")
    
    # íŒŒì´í”„ë¼ì¸ íƒ€ì´ë° í…ŒìŠ¤íŠ¸
    logger.start_pipeline_timer("detection")
    time.sleep(0.01)  # 10ms ì‹œë®¬ë ˆì´ì…˜
    det_time = logger.end_pipeline_timer("detection")
    
    logger.start_pipeline_timer("classification")
    time.sleep(0.005)  # 5ms ì‹œë®¬ë ˆì´ì…˜
    cls_time = logger.end_pipeline_timer("classification")
    
    print(f"âœ… íŒŒì´í”„ë¼ì¸ íƒ€ì´ë°: det={det_time:.1f}ms, cls={cls_time:.1f}ms")
    
    # ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ë¡œê¹… í…ŒìŠ¤íŠ¸
    mock_metrics = {
        "classification": {
            "top1": 0.752,
            "top5": 0.934,
            "macro_f1": 0.681,
            # ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ì¶”ê°€
            "top1_single": 0.823,
            "top5_single": 0.956,
            "f1_single": 0.734,
            "top1_combination": 0.645,
            "top5_combination": 0.812,
            "f1_combination": 0.598
        },
        "detection": {
            "map_0_5": 0.456,
            "recall": 0.623,
            "precision": 0.578
        },
        "loss": 2.34
    }
    
    # íŒŒì´í”„ë¼ì¸ total(ms) Context Manager í…ŒìŠ¤íŠ¸
    with logger.pipeline_timer("total"):
        time.sleep(0.02)  # 20ms ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
    print("âœ… íŒŒì´í”„ë¼ì¸ total(ms) Context Manager í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # ìŠ¤í… ë¡œê¹… (ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ í¬í•¨)
    logger.log_step(step=10, epoch=1, metrics=mock_metrics)
    print("âœ… ë„ë©”ì¸ë³„ ìŠ¤í… ë¡œê¹… ì™„ë£Œ")
    
    # ê²€ì¦ ë¡œê¹… (ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ í¬í•¨)
    logger.log_validation(
        epoch=1,
        metrics=mock_metrics,
        selected_confidences={"single": 0.24, "combination": 0.26}
    )
    print("âœ… ë„ë©”ì¸ë³„ ê²€ì¦ ë¡œê¹… ì™„ë£Œ")
    
    # Gradient norm ê¸°ë¡
    logger.record_grad_norm(1.23, before_clipping=False)
    logger.record_grad_norm(2.45, before_clipping=True)  # 3 epochë§ˆë‹¤ë§Œ ê¸°ë¡
    print("âœ… Gradient norm ê¸°ë¡ ì™„ë£Œ")
    
    # ìš”ì•½ í†µê³„
    summary = logger.get_summary_stats()
    print(f"âœ… ìš”ì•½ í†µê³„: {summary['log_entries']}ê°œ ë¡œê·¸ ì—”íŠ¸ë¦¬")
    
    # íŒŒì´í”„ë¼ì¸ í†µê³„ í™•ì¸
    pipeline_stats = summary.get('pipeline_stats', {})
    if 'total' in pipeline_stats:
        total_stats = pipeline_stats['total']
        print(f"âœ… Total íŒŒì´í”„ë¼ì¸ í†µê³„: mean={total_stats['mean']:.1f}ms, p95={total_stats['p95']:.1f}ms")
    
    print("ğŸ‰ ìµœì†Œì…‹ ë¡œê¹… ì‹œìŠ¤í…œ (ë„ë©”ì¸ë³„ + total(ms) ë³´ì¥) í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ“Š ë„ë©”ì¸ë³„ ì¶œë ¥ ì˜ˆì‹œ: CLS[S: t1=0.82/t5=0.96/F1=0.73 | C: t1=0.65/t5=0.81/F1=0.60]")