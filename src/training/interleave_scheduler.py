"""
PillSnap ML ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ (1ë‹¨ê³„ í•„ìˆ˜)

det:cls=1:2 í™•ë¥  ìŠ¤ì¼€ì¤„ë§:
- ì—„ê²©í•œ êµì°¨ ëŒ€ì‹  í™•ë¥  ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
- Detection:Classification = 1:2 ë¹„ìœ¨ ìœ ì§€
- ê°œë°œ ë¹„ìš© ìµœì†Œí™”, ê¸°ëŒ€ê°’ ë™ì¼í•œ íš¨ê³¼
- ì˜µí‹°ë§ˆì´ì € step í˜¸ì¶œ ì¼ê´€ì„± ë³´ì¥

RTX 5080 ìµœì í™”
"""

import random
import time
from typing import Dict, Any, Optional, Callable, List, Tuple
from dataclasses import dataclass
from enum import Enum

from src.utils.core import PillSnapLogger


class TaskType(Enum):
    """í•™ìŠµ íƒœìŠ¤í¬ íƒ€ì…"""
    DETECTION = "detection"
    CLASSIFICATION = "classification"


@dataclass
class InterleaveConfig:
    """ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ì„¤ì • (1ë‹¨ê³„ í•„ìˆ˜)"""
    
    # ë¹„ìœ¨ ì„¤ì •
    detection_probability: float = 1/3    # det:cls = 1:2
    classification_probability: float = 2/3
    
    # í™•ë¥  ì¡°ì • ì„¤ì •
    rebalance_every_n_steps: int = 10    # 10 stepë§ˆë‹¤ ë¹„ìœ¨ ì¬ì¡°ì •
    target_tolerance: float = 0.1        # 10% í—ˆìš© ì˜¤ì°¨
    
    # ì˜µí‹°ë§ˆì´ì € ìŠ¤ì¼€ì¤„ë§
    sync_optimizer_steps: bool = True    # ì˜µí‹°ë§ˆì´ì € step ë™ê¸°í™”
    min_steps_before_sync: int = 5       # ìµœì†Œ 5 step í›„ ë™ê¸°í™”
    sync_grace_steps: int = 20           # ë™ê¸°í™” ë³´ì • ì£¼ê¸° (ë“œë¦¬í”„íŠ¸ ë°©ì§€)
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì„¤ì •
    grad_accum_det: int = 2              # Detection ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í…
    grad_accum_cls: int = 2              # Classification ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í…
    
    # ë¡œê¹…
    log_scheduling_stats: bool = True


class InterleaveScheduler:
    """ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ (1ë‹¨ê³„ í•„ìˆ˜)"""
    
    def __init__(self, config: InterleaveConfig):
        self.config = config
        self.logger = PillSnapLogger(__name__)
        
        # ìƒíƒœ ì¶”ì 
        self.total_steps = 0
        self.detection_steps = 0
        self.classification_steps = 0
        self.last_rebalance_step = 0
        
        # í™•ë¥  ì¡°ì •
        self.current_det_prob = config.detection_probability
        self.current_cls_prob = config.classification_probability
        
        # ì˜µí‹°ë§ˆì´ì € ë™ê¸°í™”
        self.pending_det_steps = 0
        self.pending_cls_steps = 0
        self.last_sync_step = 0
        self.force_sync_next = False  # ë¦¬ë°¸ëŸ°ìŠ¤ í›„ ê°•ì œ ë™ê¸°í™”
        
        # í†µê³„
        self.scheduling_history = []
        
        self.logger.info(
            f"ğŸ“‹ ì¸í„°ë¦¬ë¸Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” - det:cls = {config.detection_probability:.2f}:{config.classification_probability:.2f}"
        )
    
    def should_train_detection(self) -> bool:
        """
        Detection í•™ìŠµ ì—¬ë¶€ ê²°ì • (í™•ë¥  ê¸°ë°˜)
        
        Returns:
            bool: Detection í•™ìŠµí•´ì•¼ í•˜ëŠ”ì§€ ì—¬ë¶€
        """
        # í™•ë¥  ê¸°ë°˜ ì„ íƒ
        choice = random.random()
        should_det = choice < self.current_det_prob
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.total_steps += 1
        
        if should_det:
            self.detection_steps += 1
            self.pending_det_steps += 1
            task_type = TaskType.DETECTION
        else:
            self.classification_steps += 1
            self.pending_cls_steps += 1
            task_type = TaskType.CLASSIFICATION
        
        # íˆìŠ¤í† ë¦¬ ê¸°ë¡
        self.scheduling_history.append({
            "step": self.total_steps,
            "task": task_type.value,
            "det_prob": self.current_det_prob,
            "cls_prob": self.current_cls_prob
        })
        
        # ì£¼ê¸°ì  ì¬ì¡°ì •
        if (self.total_steps - self.last_rebalance_step) >= self.config.rebalance_every_n_steps:
            self._rebalance_probabilities()
        
        # ë¡œê¹…
        if self.config.log_scheduling_stats and self.total_steps % 50 == 0:
            self._log_scheduling_stats()
        
        return should_det
    
    def get_next_task(self) -> TaskType:
        """
        ë‹¤ìŒ íƒœìŠ¤í¬ íƒ€ì… ë°˜í™˜
        
        Returns:
            TaskType: ë‹¤ìŒì— í•™ìŠµí•  íƒœìŠ¤í¬
        """
        if self.should_train_detection():
            return TaskType.DETECTION
        else:
            return TaskType.CLASSIFICATION
    
    def should_sync_optimizers(self, pending_det_steps: int = None, pending_cls_steps: int = None, 
                              grad_accum_det: int = None, grad_accum_cls: int = None) -> bool:
        """
        íƒœìŠ¤í¬ ë¬´ê´€ ê¸€ë¡œë²Œ ë™ê¸°í™” íŒë‹¨
        
        Args:
            pending_det_steps: ëŒ€ê¸° ì¤‘ì¸ Detection ìŠ¤í… ìˆ˜ (ê¸°ë³¸ê°’: self.pending_det_steps)
            pending_cls_steps: ëŒ€ê¸° ì¤‘ì¸ Classification ìŠ¤í… ìˆ˜ (ê¸°ë³¸ê°’: self.pending_cls_steps)
            grad_accum_det: Detection ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í… (ê¸°ë³¸ê°’: config.grad_accum_det)
            grad_accum_cls: Classification ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í… (ê¸°ë³¸ê°’: config.grad_accum_cls)
            
        Returns:
            bool: ì–‘ìª½ ì˜µí‹°ë§ˆì´ì €ë¥¼ ë™ê¸°í™”í•´ì•¼ í•˜ëŠ”ì§€ ì—¬ë¶€
        """
        if not self.config.sync_optimizer_steps:
            return True  # ë™ê¸°í™” ë¹„í™œì„±í™”ì‹œ í•­ìƒ step
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if pending_det_steps is None:
            pending_det_steps = self.pending_det_steps
        if pending_cls_steps is None:
            pending_cls_steps = self.pending_cls_steps
        if grad_accum_det is None:
            grad_accum_det = self.config.grad_accum_det
        if grad_accum_cls is None:
            grad_accum_cls = self.config.grad_accum_cls
        
        # ê°•ì œ ë™ê¸°í™” í”Œë˜ê·¸ ì²´í¬
        if self.force_sync_next:
            self.force_sync_next = False
            return True
        
        # ì¡°ê±´ a: ì–‘ìª½ ëª¨ë‘ grad_accum ì¡°ê±´ ë§Œì¡±
        both_ready = (pending_det_steps >= grad_accum_det and 
                     pending_cls_steps >= grad_accum_cls)
        
        if both_ready:
            return True
        
        # ì¡°ê±´ b: ë™ê¸°í™” ë³´ì • ì£¼ê¸° ê²½ê³¼ ì‹œ ë“œë¦¬í”„íŠ¸ ë°©ì§€
        steps_since_sync = self.total_steps - self.last_sync_step
        grace_period_exceeded = steps_since_sync >= self.config.sync_grace_steps
        
        if grace_period_exceeded:
            # í•œìª½ë§Œ ê³„ì† ë¯¸ë‹¬ì¼ ë•Œë„ ë™ê¸°í™” ê°•ì œ
            either_ready = (pending_det_steps >= grad_accum_det or 
                           pending_cls_steps >= grad_accum_cls)
            if either_ready:
                self.logger.warning(
                    f"âš ï¸ ë™ê¸°í™” ë³´ì • ì£¼ê¸° ê²½ê³¼ - ê°•ì œ ë™ê¸°í™” ì‹¤í–‰ "
                    f"(det: {pending_det_steps}/{grad_accum_det}, cls: {pending_cls_steps}/{grad_accum_cls})"
                )
                return True
        
        return False
    
    def sync_and_step_optimizers(self, det_opt: Any, cls_opt: Any) -> None:
        """
        ë™ê¸°í™” ì‹œì ì—ì„œ ì–‘ìª½ ì˜µí‹°ë§ˆì´ì € ëª¨ë‘ step ë° ë¦¬ì…‹
        
        Args:
            det_opt: Detection ì˜µí‹°ë§ˆì´ì €
            cls_opt: Classification ì˜µí‹°ë§ˆì´ì €
        """
        # ì–‘ìª½ ì˜µí‹°ë§ˆì´ì € ëª¨ë‘ step
        if det_opt:
            det_opt.step()
            det_opt.zero_grad()
        
        if cls_opt:
            cls_opt.step()
            cls_opt.zero_grad()
        
        # ì¹´ìš´í„° ë¦¬ì…‹
        det_steps = self.pending_det_steps
        cls_steps = self.pending_cls_steps
        
        self.pending_det_steps = 0
        self.pending_cls_steps = 0
        self.last_sync_step = self.total_steps
        
        # ë™ê¸°í™” ë¡œê·¸
        det_cls_ratio = f"1:{cls_steps/max(1, det_steps):.2f}" if det_steps > 0 else f"0:{cls_steps}"
        self.logger.info(
            f"ğŸ”„ SYNC(det:cls={det_cls_ratio}, det_steps={det_steps}, cls_steps={cls_steps})"
        )
    
    def _rebalance_probabilities(self) -> None:
        """í™•ë¥  ì¬ì¡°ì • (ë¹„ìœ¨ ìœ ì§€)"""
        if self.total_steps <= 1:
            return
        
        # í˜„ì¬ ì‹¤ì œ ë¹„ìœ¨ ê³„ì‚°
        actual_det_ratio = self.detection_steps / self.total_steps
        actual_cls_ratio = self.classification_steps / self.total_steps
        
        # ëª©í‘œ ë¹„ìœ¨ê³¼ ë¹„êµ
        target_det_ratio = self.config.detection_probability
        target_cls_ratio = self.config.classification_probability
        
        det_diff = actual_det_ratio - target_det_ratio
        cls_diff = actual_cls_ratio - target_cls_ratio
        
        # í—ˆìš© ì˜¤ì°¨ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        if abs(det_diff) <= self.config.target_tolerance:
            self.last_rebalance_step = self.total_steps
            return  # ì¬ì¡°ì • ë¶ˆí•„ìš”
        
        # í™•ë¥  ì¡°ì • (ë¶€ì¡±í•œ ìª½ì˜ í™•ë¥  ì¦ê°€)
        adjustment_factor = 0.1  # 10% ì¡°ì •
        
        if det_diff < 0:  # Detectionì´ ë¶€ì¡±
            self.current_det_prob = min(0.9, self.current_det_prob + adjustment_factor)
            self.current_cls_prob = 1.0 - self.current_det_prob
        elif cls_diff < 0:  # Classificationì´ ë¶€ì¡±
            self.current_cls_prob = min(0.9, self.current_cls_prob + adjustment_factor)
            self.current_det_prob = 1.0 - self.current_cls_prob
        
        self.last_rebalance_step = self.total_steps
        
        # ë³´ì • ì§í›„ ì²« ë™ê¸°í™”ì—ì„œ ì–‘ìª½ ë™ì‹œ step ìœ ë„
        self.force_sync_next = True
        
        self.logger.info(
            f"ğŸ“Š í™•ë¥  ì¬ì¡°ì • - det: {target_det_ratio:.2f}â†’{self.current_det_prob:.2f}, "
            f"cls: {target_cls_ratio:.2f}â†’{self.current_cls_prob:.2f} "
            f"(ì‹¤ì œ ë¹„ìœ¨: det {actual_det_ratio:.3f}, cls {actual_cls_ratio:.3f}) - ë‹¤ìŒ ë™ê¸°í™” ê°•ì œ"
        )
    
    def _log_scheduling_stats(self) -> None:
        """ìŠ¤ì¼€ì¤„ë§ í†µê³„ ë¡œê¹…"""
        if self.total_steps == 0:
            return
        
        actual_det_ratio = self.detection_steps / self.total_steps
        actual_cls_ratio = self.classification_steps / self.total_steps
        
        target_det_ratio = self.config.detection_probability
        target_cls_ratio = self.config.classification_probability
        
        det_deviation = abs(actual_det_ratio - target_det_ratio)
        cls_deviation = abs(actual_cls_ratio - target_cls_ratio)
        
        self.logger.info(
            f"ğŸ“ˆ ìŠ¤ì¼€ì¤„ë§ í†µê³„ (step {self.total_steps}) - "
            f"det: {actual_det_ratio:.3f} (ëª©í‘œ {target_det_ratio:.3f}, í¸ì°¨ {det_deviation:.3f}), "
            f"cls: {actual_cls_ratio:.3f} (ëª©í‘œ {target_cls_ratio:.3f}, í¸ì°¨ {cls_deviation:.3f}), "
            f"ëŒ€ê¸°: det {self.pending_det_steps}, cls {self.pending_cls_steps}"
        )
    
    def get_statistics(self) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¤„ë§ í†µê³„ ë°˜í™˜"""
        if self.total_steps == 0:
            return {
                "total_steps": 0,
                "detection_steps": 0,
                "classification_steps": 0,
                "actual_ratios": {"detection": 0.0, "classification": 0.0},
                "target_ratios": {"detection": self.config.detection_probability, "classification": self.config.classification_probability},
                "deviations": {"detection": 0.0, "classification": 0.0},
                "current_probabilities": {"detection": self.current_det_prob, "classification": self.current_cls_prob}
            }
        
        actual_det_ratio = self.detection_steps / self.total_steps
        actual_cls_ratio = self.classification_steps / self.total_steps
        
        return {
            "total_steps": self.total_steps,
            "detection_steps": self.detection_steps,
            "classification_steps": self.classification_steps,
            "actual_ratios": {
                "detection": actual_det_ratio,
                "classification": actual_cls_ratio
            },
            "target_ratios": {
                "detection": self.config.detection_probability,
                "classification": self.config.classification_probability
            },
            "deviations": {
                "detection": abs(actual_det_ratio - self.config.detection_probability),
                "classification": abs(actual_cls_ratio - self.config.classification_probability)
            },
            "current_probabilities": {
                "detection": self.current_det_prob,
                "classification": self.current_cls_prob
            },
            "pending_steps": {
                "detection": self.pending_det_steps,
                "classification": self.pending_cls_steps
            }
        }
    
    def reset_statistics(self) -> None:
        """í†µê³„ ë¦¬ì…‹ (ì—í¬í¬ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
        self.total_steps = 0
        self.detection_steps = 0
        self.classification_steps = 0
        self.last_rebalance_step = 0
        self.pending_det_steps = 0
        self.pending_cls_steps = 0
        self.last_sync_step = 0
        self.force_sync_next = False
        self.scheduling_history.clear()
        
        # í™•ë¥  ì´ˆê¸°í™”
        self.current_det_prob = self.config.detection_probability
        self.current_cls_prob = self.config.classification_probability
        
        self.logger.info("ğŸ”„ ì¸í„°ë¦¬ë¸Œ ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„ ë¦¬ì…‹")


class InterleaveTrainingWrapper:
    """ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ë˜í¼ (í¸ì˜ í´ë˜ìŠ¤)"""
    
    def __init__(
        self,
        detection_train_fn: Callable,
        classification_train_fn: Callable,
        scheduler: InterleaveScheduler,
        detection_optimizer: Optional[Any] = None,
        classification_optimizer: Optional[Any] = None
    ):
        """
        Args:
            detection_train_fn: Detection í•™ìŠµ í•¨ìˆ˜
            classification_train_fn: Classification í•™ìŠµ í•¨ìˆ˜
            scheduler: ì¸í„°ë¦¬ë¸Œ ìŠ¤ì¼€ì¤„ëŸ¬
            detection_optimizer: Detection ì˜µí‹°ë§ˆì´ì € (ì„ íƒì )
            classification_optimizer: Classification ì˜µí‹°ë§ˆì´ì € (ì„ íƒì )
        """
        self.detection_train_fn = detection_train_fn
        self.classification_train_fn = classification_train_fn
        self.scheduler = scheduler
        self.detection_optimizer = detection_optimizer
        self.classification_optimizer = classification_optimizer
        
        self.logger = PillSnapLogger(__name__)
    
    def training_step(self, **kwargs) -> Tuple[TaskType, Any]:
        """
        ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ìŠ¤í… ì‹¤í–‰
        
        Returns:
            Tuple[TaskType, Any]: (ì‹¤í–‰ëœ íƒœìŠ¤í¬ íƒ€ì…, í•™ìŠµ ê²°ê³¼)
        """
        # ë‹¤ìŒ íƒœìŠ¤í¬ ê²°ì •
        task_type = self.scheduler.get_next_task()
        
        # í•´ë‹¹ íƒœìŠ¤í¬ í•™ìŠµ ì‹¤í–‰
        if task_type == TaskType.DETECTION:
            result = self.detection_train_fn(**kwargs)
            optimizer = self.detection_optimizer
        else:
            result = self.classification_train_fn(**kwargs)
            optimizer = self.classification_optimizer
        
        # ì˜µí‹°ë§ˆì´ì € ë™ê¸°í™” ì²˜ë¦¬ (ìƒˆë¡œìš´ ë°©ì‹)
        if self.scheduler.should_sync_optimizers():
            self.scheduler.sync_and_step_optimizers(
                self.detection_optimizer, 
                self.classification_optimizer
            )
        
        return task_type, result
    
    def get_scheduler_stats(self) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„ ë°˜í™˜"""
        return self.scheduler.get_statistics()


if __name__ == "__main__":
    print("ğŸ§ª ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ í•„ìˆ˜)")
    print("=" * 60)
    
    # ì„¤ì • í…ŒìŠ¤íŠ¸
    config = InterleaveConfig(
        detection_probability=1/3,
        classification_probability=2/3,
        rebalance_every_n_steps=10
    )
    scheduler = InterleaveScheduler(config)
    
    print(f"âœ… ì´ˆê¸° ì„¤ì •: det={config.detection_probability:.2f}, cls={config.classification_probability:.2f}")
    
    # 100 step ì‹œë®¬ë ˆì´ì…˜
    for step in range(100):
        task = scheduler.get_next_task()
        should_step = scheduler.should_step_optimizer(task)
        
        if step % 25 == 24:  # 25 stepë§ˆë‹¤ í†µê³„ ì¶œë ¥
            stats = scheduler.get_statistics()
            print(f"Step {step+1}: det={stats['actual_ratios']['detection']:.3f}, cls={stats['actual_ratios']['classification']:.3f}")
    
    # ìµœì¢… í†µê³„
    final_stats = scheduler.get_statistics()
    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    print(f"  Detection: {final_stats['actual_ratios']['detection']:.3f} (ëª©í‘œ: {final_stats['target_ratios']['detection']:.3f})")
    print(f"  Classification: {final_stats['actual_ratios']['classification']:.3f} (ëª©í‘œ: {final_stats['target_ratios']['classification']:.3f})")
    print(f"  í¸ì°¨: det={final_stats['deviations']['detection']:.3f}, cls={final_stats['deviations']['classification']:.3f}")
    
    print("ğŸ‰ ì¸í„°ë¦¬ë¸Œ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")