# Part C â€” ì¡°ê±´ë¶€ Two-Stage ë°ì´í„° íŒŒì´í”„ë¼ì¸ + 128GB RAM ìµœì í™”

[ì ˆëŒ€ ê²½ë¡œ/ì „ì œ + ë””ìŠ¤í¬ I/O ë³‘ëª© í•´ê²° ìƒí™©]

- **ì›ë³¸ ë°ì´í„°**: /mnt/data/pillsnap_dataset (ì›ë³¸ ë³´ê´€)
- **ë°ì´í„° êµ¬ì¡°**: 
  - **Native Linux**: /home/max16/pillsnap_data (Linux SSD, ì£¼ìš” ë°ì´í„°)
  - **Windows SSD**: ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ì—°ê²° (í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€)
  - **ë°±ì—…**: /mnt/data/pillsnap_dataset (ì›ë³¸ ë³´ê´€ìš©)
- **Native Linux ì´ì „ ì™„ë£Œ**: WSL ì œì•½ í•´ê²°, CPU ë©€í‹°í”„ë¡œì„¸ì‹± í™œì„±í™” (num_workers=8)
  - **âœ… Stage 1**: 74.9% ì •í™•ë„ ë‹¬ì„± (Native Linux, 1ë¶„ ì™„ë£Œ)
  - **âœ… Stage 2**: 83.1% ì •í™•ë„ ë‹¬ì„± (25K ìƒ˜í”Œ, 250í´ë˜ìŠ¤)
  - **âœ… Stage 3**: 85.01% ì •í™•ë„ ë‹¬ì„± (100K ìƒ˜í”Œ, 1,000í´ë˜ìŠ¤)
  - **ğŸ¯ Stage 4**: ì¤€ë¹„ ì™„ë£Œ (500K ìƒ˜í”Œ, 4,523í´ë˜ìŠ¤)
- ê¸°ë³¸ ì‘ì—…: ì•½í’ˆ ê²€ì¶œ+ë¶„ë¥˜(Detection â†’ Classification, Two-Stage). ìˆœìˆ˜ ë¶„ë¥˜ ëª¨ë“œë„ ì§€ì›.
- ëª¨ë“  ë°ì´í„° ê²½ë¡œëŠ” **/home/max16/pillsnap_data** ì‚¬ìš© (í”„ë¡œì íŠ¸ì™€ ë¶„ë¦¬).
- ì½”ë“œëŠ” /home/max16/pillsnap, **í•™ìŠµ ì‚°ì¶œë¬¼/ì²´í¬í¬ì¸íŠ¸**ëŠ” /home/max16/pillsnap_data/exp/ë¡œ ê³ ì • (ë°ì´í„° ë¶„ë¦¬).

C-0) ëª©í‘œ & ì‚°ì¶œë¬¼

- ëª©í‘œ:
  1. COCO í¬ë§· ì•½í’ˆ ê²€ì¶œ ë°ì´í„°ë¥¼ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì•ˆì „í•˜ê²Œ ë¡œë”©í•œë‹¤.
  2. ì‚¬ìš©ì ì„ íƒ ê¸°ë°˜ Two-Mode: ë‹¨ì¼ ë¶„ë¥˜ìš© + ì¡°í•© ê²€ì¶œìš© ë°ì´í„°ë¡œë”ë¥¼ êµ¬ì„±í•œë‹¤.
  3. DataLoader ë³‘ëª©ì„ ì¤„ì—¬ GPUë¡œì˜ H2D ì „ì†¡ì„ ìµœëŒ€í•œ ê²¹ì¹œë‹¤(non_blocking).
  4. ê¹¨ì§„ ìƒ˜í”Œ/ì˜ˆì™¸ëŠ” "ìŠ¤í‚µ + ë¡œê·¸"ë¡œ ì²˜ë¦¬(í•™ìŠµ ì¤‘ë‹¨ ê¸ˆì§€).
  5. ì•½í’ˆ ë©”íƒ€ë°ì´í„° ë§¤í•‘ í…Œì´ë¸”ì„ êµ¬ì¶•í•˜ê³  ì•½í’ˆ IDì™€ ì—°ê²°í•œë‹¤.
  6. ìë™ íŒë‹¨ ë¡œì§ ì™„ì „ ì œê±° - ì‚¬ìš©ì ì„ íƒë§Œ ì§€ì›
- ì´ íŒŒíŠ¸ì—ì„œ êµ¬í˜„(íŒŒì¼: src/data.py):
  â€¢ PillsnapDetDataset(torch.utils.data.Dataset) # YOLO ê²€ì¶œìš©
  â€¢ PillsnapClsDataset(torch.utils.data.Dataset) # cropëœ ì•½í’ˆ ë¶„ë¥˜ìš©  
  â€¢ convert_coco_to_yolo(coco_json_path, output_dir) -> yolo_format_files
  â€¢ build_drug_metadata_mapping(root_path) -> dict[drug_id, complete_metadata]
  â€¢ build_transforms_detection(train: bool, img_size: int, augment_cfg: dict) -> callable
  â€¢ build_transforms_classification(train: bool, img_size: int, augment_cfg: dict) -> callable
  â€¢ discover_detection_data(root, coco_annotations) -> (images, annotations, classes)
  â€¢ make_splits(records, annotations, split_ratio, seed, stratified: bool, persist_path: str, max_samples: int|None) -> dict{train,val,test}
  â€¢ build_dataloaders_by_mode(cfg, mode="single"|"combo", logger, seed) -> (train_loader, val_loader, test_loader|None, meta)
  â€¢ safe_collate_detection(batch) # bbox ê²€ì¦ í¬í•¨
  â€¢ safe_collate_classification(batch) # SkipSample-safe
  â€¢ validate_bbox(bbox, img_w, img_h) -> bool
  â€¢ worker_init_fn(worker_id) # ì‹œë“œ ê³ ì •
  â€¢ open_image_safely(path) -> PIL.Image | dict(\_skip=True, error=...)
  â€¢ summarize_dataset(...) -> dict # ì•½í’ˆ ë¶„í¬/ë°”ìš´ë”©ë°•ìŠ¤ í†µê³„/ë©”íƒ€ë°ì´í„° ë§¤í•‘ í˜„í™©
  â€¢ build_drug_metadata_mapping(coco_annotations_dir: str, output_path: str) -> dict # edi_code â†’ drug_metadata ë§¤í•‘
  â€¢ get_class_id_from_edi_code(edi_code: str, mapping_data: dict) -> int # edi_code â†’ class_id ë³€í™˜
  â€¢ get_drug_metadata_from_class_id(class_id: int, mapping_data: dict) -> dict # class_id â†’ drug_metadata ë³€í™˜

C-1) config.yaml í™•ì¥(í‚¤ ì¶”ê°€/ì„¤ëª…)

```
data:
  task: "two_stage"              # "two_stage" (detection + classification)
  pipeline_strategy: "user_controlled"  # single ìš°ì„ , combo ëª…ì‹œì  ì„ íƒ
  default_mode: "single"         # 90% ì¼€ì´ìŠ¤ ê¸°ë³¸ê°’
  auto_fallback: false           # ìë™ íŒë‹¨ ì™„ì „ ì œê±°
  root: "/home/max16/pillsnap_data"  # Native Linux SSD ë°ì´í„° ê²½ë¡œ (Stage 1-2 ì™„ë£Œ)
  detection:
    img_size: 640
    coco_json_path: "data/train/labels"  # COCO annotation ê²½ë¡œ
    yolo_output_dir: "/home/max16/pillsnap_data/exp/exp01/yolo_data"      # Native Linux SSDì— ë³€í™˜ëœ YOLO í¬ë§· ì €ì¥
    conf_threshold: 0.3
    iou_threshold: 0.5
    max_detections: 100
  classification:
    img_size: 384                # EfficientNetV2-S ê³ í•´ìƒë„ í¬ê¸°
    crop_padding: 0.1            # ê²€ì¶œëœ bbox í™•ì¥ ë¹„ìœ¨
  # ë°ì´í„° ë¶„í•  ì „ëµ: AI Hub Training(159ê°œ)ë¥¼ train/valë¡œ, AI Hub Validation(22ê°œ)ë¥¼ testë¡œ
  split_ratio: [0.85, 0.15]      # AI Hub Training ë°ì´í„°ë§Œ train:valë¡œ ë¶„í• 
  test_data_source: "aihub_validation"  # AI Hub Validation ì „ì²´ë¥¼ testë¡œ ì‚¬ìš© (Stage í•™ìŠµ ì¤‘ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)
  test_usage_policy: "final_evaluation_only"  # testëŠ” ëª¨ë“  Stage ì™„ë£Œ í›„ ìµœì¢… í‰ê°€ì‹œ 1íšŒë§Œ ì‚¬ìš©
  max_samples: null              # ë””ë²„ê·¸ ì‹œ 1000 ê°™ì€ ì œí•œ ì§€ì›(nullì´ë©´ ì „ì²´)
  drug_metadata_file: "/home/max16/pillsnap_data/exp/exp01/drug_metadata.json"  # Native Linux SSDì— drug_id â†’ complete_metadata ë§¤í•‘
  # ë‹¨ìˆœí™”ëœ Stage í‰ê°€ ì‹œìŠ¤í…œ (Native Linux ì—…ë°ì´íŠ¸)
  progressive_validation:
    current_stage: 2  # Stage 2 ì¤€ë¹„ ì™„ë£Œ
    stage_1: {max_samples: 5000, max_classes: 50, target_accuracy: 0.78, achieved_accuracy: 0.749, status: "completed"}
    stage_2: {max_samples: 25000, max_classes: 250, target_accuracy: 0.82, status: "ready"}
    stage_3: {max_samples: 100000, max_classes: 1000, target_accuracy: 0.85, max_latency_ms: 200}
    stage_4: {max_samples: 500000, max_classes: 4523, target_accuracy: 0.85, max_latency_ms: 200}
  extensions: [".jpg",".jpeg",".png",".bmp",".webp"]
  ignore_hidden: true            # ._* ìˆ¨ê¹€ íŒŒì¼ ë¬´ì‹œ
  verify_on_build: true          # ìŠ¤ìº” ì‹œ ì´ë¯¸ì§€ ì˜¤í”ˆ ê²€ì¦(ê¶Œì¥)
  cache_meta_path: "/home/max16/pillsnap_data/exp/exp01/splits.json"  # Native Linux SSDì— ë¶„í• /ë©”íƒ€ ìºì‹œ
  broken_policy: "skip"          # "skip"|"fail" â€” ë°˜ë“œì‹œ "skip"
  grayscale_policy: "rgb"        # "rgb"(3ì±„ë„ ë³€í™˜) | "skip"
  rgba_policy: "drop_alpha"      # "drop_alpha"(RGB ë³€í™˜) | "skip"
  augment:
    detection:
      randaugment: false         # YOLO ìì²´ ì¦ê°• ì‚¬ìš©
      mosaic: 0.5
      mixup: 0.1
      hflip: true
      scale: [0.5, 1.5]          # ìŠ¤ì¼€ì¼ ì¦ê°• ë²”ìœ„
    classification:
      randaugment: true
      color_jitter: [0.2,0.2,0.2,0.05]   # brightness, contrast, saturation, hue
      hflip: true
      auto_augment: null         # "imagenet" | null
  imbalance:
    use_class_weights: true      # ë¶„ë¥˜ ë‹¨ê³„ì—ì„œë§Œ ì ìš©
    method: "inv_freq"           # "inv_freq" | "effective_num"
    beta: 0.9999                 # effective_numì¼ ë•Œë§Œ
    use_weighted_sampler: false  # trueë©´ DataLoader samplerë¡œ ëŒ€ì²´(ì¶©ëŒ ì£¼ì˜)

dataloader:
  num_workers: 8  # Native Linux ìµœì í™” ê°’
  autotune_workers: true
  pin_memory: true
  pin_memory_device: "cuda"
  prefetch_factor: 6          # ê¸°ë³¸ê°’ ìƒí–¥ (4â†’6)
  prefetch_per_stage:         # Stageë³„ ì°¨ë³„í™”
    1: 4
    2: 6
    3: 8
    4: 8
  persistent_workers: true
  drop_last: true
  multiprocessing_context: "spawn"
  
  # ë‹¨ê³„ì  ë©”ëª¨ë¦¬ ìµœì í™” (ê¸°ë³¸ off, ë‹¨ê³„ì  On)
  ram_optimization:
    # Phase 1: ê¸°ë³¸ ìºì‹œë§Œ (ë³´ìˆ˜ì  ì‹œì‘ì )
    cache_policy: "labels_only"    # ì´ˆê¸°ì—ëŠ” ë ˆì´ë¸”ë§Œ ìºì‹œ
    cache_labels: true
    preload_samples: 0             # í”„ë¦¬ë¡œë“œ ë¹„í™œì„±í™”
    hotset_size_images: 0          # í•«ì…‹ ë¹„í™œì„±í™”
    use_lmdb: false                # LMDB ë¹„í™œì„±í™”
    
    # Phase 2: ë³‘ëª© í™•ì¸ í›„ ê°€ë²¼ìš´ í™•ì¥
    # cache_policy: "hotset"
    # hotset_size_images: 40000    # 40K ì´ë¯¸ì§€ ìºì‹œ (~16GB)
    
    # Phase 3: ì§„ì§œ I/O ë³‘ëª©ì¼ ë•Œë§Œ
    # use_lmdb: true ë˜ëŠ” WebDataset ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ
```

> ì°¸ê³ : Native Linuxì—ì„œ num_workers=8ë¡œ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
> autotune_workersê°€ trueì´ë©´ Part Dì˜ ì˜¤í† íŠœë„ˆê°€ [4,8,12,16] í›„ë³´ë¡œ ë²¤ì¹˜ í›„ ìµœì ì„ ë°˜ì˜í•©ë‹ˆë‹¤.

```

C-2) ë””ë ‰í† ë¦¬/íŒŒì¼ êµ¬ì¡°(COCO â†’ YOLO ë³€í™˜)

- í†µì¼ëœ ì…ë ¥ êµ¬ì¡° (Native Linux SSD ì´ì „ ì™„ë£Œ, ì‹¤ì œ ZIP ì¶”ì¶œ êµ¬ì¡°):
```
/home/max16/pillsnap_data/  # Stage 1-2 ì™„ë£Œ, Stage 3-4 ì¤€ë¹„
â”œâ”€ data/train/
â”‚  â”œâ”€ labels/
â”‚  â”‚  â”œâ”€ combination/
â”‚  â”‚  â”‚  â”œâ”€ TL_1_combo/
â”‚  â”‚  â”‚  â”‚  â”œâ”€ K-000250-000573-002483-006192_json/   # K-ì½”ë“œ_json í´ë”
â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ K-000250-000573-002483-006192_*.json  # JSON ë¼ë²¨ íŒŒì¼ë“¤
â”‚  â”‚  â”‚  â”‚  â”œâ”€ K-000250-000573-002483-012778_json/
â”‚  â”‚  â”‚  â”‚  â””â”€ ... (547ê°œ ì¡°í•© K-ì½”ë“œ_json í´ë”)
â”‚  â”‚  â”‚  â”œâ”€ TL_2_combo/
â”‚  â”‚  â”‚  â””â”€ ... (TL_1_combo~TL_8_combo)
â”‚  â”‚  â””â”€ single/
â”‚  â”‚     â”œâ”€ TL_1_single/
â”‚  â”‚     â”‚  â”œâ”€ K-000001_json/                    # K-ì½”ë“œ_json í´ë”
â”‚  â”‚     â”‚  â”‚  â””â”€ K-000001_*.json                 # JSON ë¼ë²¨ íŒŒì¼ë“¤
â”‚  â”‚     â”‚  â”œâ”€ K-000002_json/
â”‚  â”‚     â”‚  â””â”€ ... (50ê°œ ë‹¨ì¼ K-ì½”ë“œ_json í´ë”)
â”‚  â”‚     â”œâ”€ TL_2_single/
â”‚  â”‚     â””â”€ ... (TL_1_single~TL_81_single)
â”‚  â””â”€ images/
â”‚     â”œâ”€ combination/
â”‚     â”‚  â”œâ”€ TS_1_combo/
â”‚     â”‚  â”‚  â”œâ”€ K-000250-000573-002483-006192/   # K-ì½”ë“œ í´ë”
â”‚     â”‚  â”‚  â”‚  â”œâ”€ K-000250-000573-002483-006192_0_0_0_0_60_000_200.png
â”‚     â”‚  â”‚  â”‚  â””â”€ ...
â”‚     â”‚  â”‚  â”œâ”€ K-000250-000573-002483-012778/
â”‚     â”‚  â”‚  â””â”€ ... (547ê°œ ì¡°í•© K-ì½”ë“œ í´ë”)
â”‚     â”‚  â”œâ”€ TS_2_combo/
â”‚     â”‚  â””â”€ ... (TS_1_combo~TS_8_combo)
â”‚     â””â”€ single/
â”‚        â”œâ”€ TS_1_single/
â”‚        â”‚  â”œâ”€ K-000001/                         # K-ì½”ë“œ í´ë”
â”‚        â”‚  â”‚  â”œâ”€ K-000001_0_0_0_0_60_000_200.png
â”‚        â”‚  â”‚  â””â”€ ...
â”‚        â”‚  â”œâ”€ K-000002/
â”‚        â”‚  â””â”€ ... (50ê°œ ë‹¨ì¼ K-ì½”ë“œ í´ë”)
â”‚        â”œâ”€ TS_2_single/
â”‚        â””â”€ ... (TS_1_single~TS_81_single)
â”œâ”€ data/val/
â”‚  â”œâ”€ labels/
â”‚  â”‚  â”œâ”€ combination/
â”‚  â”‚  â”‚  â””â”€ VL_1_combo/
â”‚  â”‚  â”‚     â”œâ”€ K-016235-027733-029667-031885_json/   # K-ì½”ë“œ_json í´ë”
â”‚  â”‚  â”‚     â”‚  â””â”€ K-016235-027733-029667-031885_*.json  # JSON ë¼ë²¨ íŒŒì¼ë“¤
â”‚  â”‚  â”‚     â””â”€ ... (500ê°œ ì¡°í•© K-ì½”ë“œ_json í´ë”)
â”‚  â”‚  â””â”€ single/
â”‚  â”‚     â”œâ”€ VL_1_single/
â”‚  â”‚     â”‚  â”œâ”€ K-039148_json/                    # K-ì½”ë“œ_json í´ë”
â”‚  â”‚     â”‚  â”‚  â””â”€ K-039148_*.json                 # JSON ë¼ë²¨ íŒŒì¼ë“¤
â”‚  â”‚     â”‚  â””â”€ ... (50ê°œ ë‹¨ì¼ K-ì½”ë“œ_json í´ë”)
â”‚  â”‚     â””â”€ ... (VL_1_single~VL_10_single)
â”‚  â””â”€ images/
â”‚     â”œâ”€ combination/
â”‚     â”‚  â””â”€ VS_1_combo/
â”‚     â”‚     â”œâ”€ K-016235-027733-029667-031885/   # K-ì½”ë“œ í´ë”
â”‚     â”‚     â”‚  â”œâ”€ K-016235-027733-029667-031885_0_0_0_0_60_000_200.png
â”‚     â”‚     â”‚  â””â”€ ...
â”‚     â”‚     â””â”€ ... (500ê°œ ì¡°í•© K-ì½”ë“œ í´ë”)
â”‚     â””â”€ single/
â”‚        â”œâ”€ VS_1_single/
â”‚        â”‚  â”œâ”€ K-039148/                         # K-ì½”ë“œ í´ë”
â”‚        â”‚  â”‚  â”œâ”€ K-039148_0_0_0_0_60_000_200.png
â”‚        â”‚  â”‚  â””â”€ ...
â”‚        â”‚  â””â”€ ... (50ê°œ ë‹¨ì¼ K-ì½”ë“œ í´ë”)
â”‚        â””â”€ ... (VS_1_single~VS_10_single)
â””â”€ data/test/ (Stage 4 ì™„ë£Œ í›„ë§Œ ì‚¬ìš©, ë™ì¼í•œ K-ì½”ë“œ í´ë” êµ¬ì¡°)
```

- ì¶œë ¥ êµ¬ì¡° (Native Linux SSD ìµœì í™”, YOLO í¬ë§·):
```
/home/max16/pillsnap_data/exp/exp01/yolo_data/  # Native Linux SSDì— YOLO í¬ë§· ì €ì¥
â”œâ”€ images/
â”‚  â”œâ”€ train/
â”‚  â””â”€ val/
â”œâ”€ labels/  
â”‚  â”œâ”€ train/
â”‚  â””â”€ val/
â”œâ”€ data.yaml        # YOLO ì„¤ì • íŒŒì¼
â””â”€ drug_metadata.json # drug_id â†’ complete_metadata ë§¤í•‘
```

- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ: JSON annotationsì—ì„œ ì „ì²´ 47ê°œ í•„ë“œë¥¼ í™œìš©í•˜ì—¬ ì™„ì „í•œ ì•½í’ˆ ì •ë³´ ë§¤í•‘ í…Œì´ë¸” ìƒì„±.

C-3) COCO â†’ YOLO ë³€í™˜ ë° ê²€ì¦ ê·œì¹™(ê°•ì œ)

- convert_coco_to_yolo():
1. COCO JSON íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ì—¬ ì´ë¯¸ì§€ ê²½ë¡œì™€ annotations ì¶”ì¶œ.
2. bbox ì¢Œí‘œë¥¼ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜: [x_center, y_center, width, height] (0~1 ì •ê·œí™”).
3. ê° ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” .txt íŒŒì¼ ìƒì„± (YOLO ë¼ë²¨ í¬ë§·).
4. data.yaml íŒŒì¼ ìƒì„±: train/val ê²½ë¡œ, í´ë˜ìŠ¤ ìˆ˜, í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜.
5. drug_metadata.json ìƒì„±: drug_id â†’ complete_metadata ë§¤í•‘ í…Œì´ë¸”.
- validate_bbox(): ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê²€ì¦ (0â‰¤x,y,w,hâ‰¤1, w>0, h>0).
- summarize_dataset():
â€¢ ìƒ˜í”Œ(ìµœëŒ€ 2~3ì²œì¥)ë¡œ í•´ìƒë„/ì¢…íš¡ë¹„ íˆìŠ¤í† , í´ë˜ìŠ¤ ë¶„í¬ ìƒìœ„ 10, ì†ìƒ/ìŠ¤í‚µ ë¹„ìœ¨ ë¡œê·¸.
- make_splits(records, labels, split_ratio, seed, stratified=True, persist_path, max_samples):
â€¢ AI Hub Training ë°ì´í„°(159ê°œ)ë§Œ train/valë¡œ ë¶„í•  (85:15 ë¹„ìœ¨)
â€¢ AI Hub Validation ë°ì´í„°(22ê°œ)ëŠ” testë¡œ ì™„ì „ ë¶„ë¦¬, í•™ìŠµ ê³¼ì •ì—ì„œ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
â€¢ Stratified ë¶„í• (ë¹„ìœ¨ ë³´ì¡´). í´ë˜ìŠ¤ ìˆ˜ê°€ 1ê°œë©´ ëœë¤ ë¶„í• ë¡œ í´ë°±(ê²½ê³ ).
â€¢ ê° í´ë˜ìŠ¤ ìµœì†Œ 1ê°œ val ë³´ì¥(ë¶€ì¡± ì‹œ ê²½ê³ ).
â€¢ persist_pathê°€ ì¡´ì¬í•˜ë©´ ìºì‹œ ì¬ì‚¬ìš©(ë¬´ê²°ì„±: íŒŒì¼ ì¡´ì¬/ê°œìˆ˜/ë¼ë²¨ í•©ì¹˜). ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” persist_path=cfg.data.cache_meta_path ë¥¼ ì‚¬ìš©í•œë‹¤.
â€¢ max_samples ì„¤ì • ì‹œ ê· ì¼ ì„œë¸Œìƒ˜í”Œ(ì „ì²´ì—ì„œ ë¬´ì‘ìœ„ ê· ì¼; í´ë˜ìŠ¤ë³„ ë‹¤ìš´ìƒ˜í”Œì€ TODO ì£¼ì„).
â€¢ ë°˜í™˜: {'train': train_records, 'val': val_records, 'test': test_records} # testëŠ” ìµœì¢… í‰ê°€ìš©
- ì—ì§€ ì¼€ì´ìŠ¤:
â€¢ ë¼ë²¨ ëˆ„ë½/êµ¬ì¡° ì˜¤ë¥˜ íŒŒì¼: ì¦‰ì‹œ ê²½ê³  í›„ skip(broken_policy ê³ ì •).
â€¢ ì¤‘ë³µ ê²½ë¡œ/ê¹¨ì§„ ì‹¬ë³¼ë¦­ë§í¬ë„ skip.

C-4) ì „ì²˜ë¦¬/ì¦ê°•(vision v2, í…ì„œ ê²½ë¡œ)

- build_transforms(train, img_size, augment_cfg):
ê³µí†µ: ì…ë ¥ì„ RGB 3ì±„ë„ë¡œ í†µì¼(ê·¸ë ˆì´ìŠ¤ì¼€ì¼/ì•ŒíŒŒ ì •ì±… ì ìš©).
train:
â€¢ RandomResizedCrop(img_size, antialias=True)
â€¢ RandomHorizontalFlip(p=0.5) (cfg.augment.hflip)
â€¢ (ì˜µì…˜) RandAugment(num_ops=2~3, magnitude=7~9) (cfg.augment.randaugment)
â€¢ (ì˜µì…˜) ColorJitter(\*cfg.augment.color_jitter)
â€¢ ToTensor() â†’ Normalize(IMAGENET mean/std)
val/test:
â€¢ Resize(shorter=img_size) + CenterCrop(img_size) ë˜ëŠ” Resize(img_size)
â€¢ ToTensor() â†’ Normalize(...)
- í…ì„œëŠ” float32, AMPëŠ” ëª¨ë¸ì¸¡ì—ì„œ ì²˜ë¦¬. ëª¨ë¸ì€ channels_last ë©”ëª¨ë¦¬ í¬ë§·(Part Dì—ì„œ ì „ì†¡ ì‹œ ì„¤ì •).

C-5) Dataset/Collate/DataLoader ì„¤ê³„(ì„±ëŠ¥ í•µì‹¬)

- PillsnapClsDataset:
**getitem**(i):
1. img = open_image_safely(path) # ì‹¤íŒ¨ ì‹œ dict(\_skip=True, error=...)
2. transforms ì ìš© â†’ Tensor
3. ì„±ê³µ: {"image": Tensor, "label": int, "path": str} ë°˜í™˜
   **len**(): ìƒ˜í”Œ ìˆ˜
- safe_collate(batch):
â€¢ \_skip=True í•­ëª© í•„í„°. ë‚¨ì€ ìƒ˜í”Œ < 1ì´ë©´ ê²½ê³  í›„ ë¹ˆ ë°°ì¹˜ ì˜ˆì™¸ íšŒí”¼(ìƒìœ„ ë£¨í”„ê°€ ë‹¤ìŒ ìŠ¤í… ì§„í–‰).
â€¢ (images[N,C,H,W], labels[N], meta{paths}) ë°˜í™˜.
- DataLoader:
train_loader = DataLoader(
dataset=train_ds,
batch_size=cfg.train.batch_size,
shuffle=not cfg.data.imbalance.use_weighted_sampler,
sampler=WeightedRandomSampler(...) if cfg.data.imbalance.use_weighted_sampler else None,
num_workers=cfg.dataloader.num_workers,
pin_memory=cfg.dataloader.pin_memory,
prefetch_factor=cfg.dataloader.prefetch_factor,
persistent_workers=cfg.dataloader.persistent_workers,
drop_last=cfg.dataloader.drop_last,
collate_fn=safe_collate,
worker_init_fn=worker_init_fn
)
val_loader: shuffle=False, sampler=None, ë‚˜ë¨¸ì§€ ë™ì¼.
- ì›Œì»¤ ì˜¤í† íŠœë‹: Part Dì˜ autotune_num_workers()ë¡œ í›„ë³´ [4,8,12,16]ì— ëŒ€í•´ 50~100 step ë¯¸ë‹ˆë²¤ì¹˜ â†’ data_time ìµœì†Œê°’ ì„ íƒ â†’ ìµœì¢… ë¡œë” ì¬ìƒì„±.

C-6) í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬(ê°€ì¤‘ì¹˜ vs ìƒ˜í”ŒëŸ¬)

- compute_class_weights(labels, num_classes, method, smooth, beta):
â€¢ inv_freq: w_c = total/(count_c + smooth); í‰ê·  1.0ë¡œ ìŠ¤ì¼€ì¼.
â€¢ effective_num: w_c = (1 - Î²)/(1 - Î²^{count_c}); í‰ê·  1.0ë¡œ ìŠ¤ì¼€ì¼.
â†’ torch.Tensor[num_classes]ì„ ë°˜í™˜í•˜ì—¬ CrossEntropy(weight=...)ì— ì‚¬ìš©.
- WeightedRandomSampler:
â€¢ ê·¹ë‹¨ì  ë¶ˆê· í˜•ì—ì„œë§Œ ì‚¬ìš©(ê³¼ë³´ì • ì£¼ì˜). ì‚¬ìš© ì‹œ train_loader.shuffle=Falseë¡œ ì „í™˜.
â€¢ loss ê°€ì¤‘ì¹˜ì™€ ë™ì‹œ ì‚¬ìš© ë¹„ê¶Œì¥(ë‘˜ ì¤‘ í•˜ë‚˜ ìš°ì„ ).

C-7) ì•ˆì „ ë¡œë”©(open_image_safely) ì •ì±…

- EXIF Orientation êµì •(transpose) ì‹œë„.
- ì»¬ëŸ¬ ì •ì±…:
â€¢ grayscale_policy="rgb": convert("RGB")ë¡œ 3ì±„ë„í™”. "skip"ì´ë©´ ìŠ¤í‚µ.
â€¢ rgba_policy="drop_alpha": convert("RGB")ë¡œ ì•ŒíŒŒ ë“œë¡­. "skip"ì´ë©´ ìŠ¤í‚µ.
- í¬ë§·: WebP/PNG/BMP/JPEG ì§€ì›. Pillow ì˜¤ë¥˜ ì‹œ 1íšŒ OpenCV(cv2.imdecode) í´ë°±.
- ìµœì¢… ì‹¤íŒ¨ëŠ” ì˜ˆì™¸ë¥¼ ë˜ì§€ì§€ ë§ê³  {"\_skip": True, "error": "..."} ë°˜í™˜ â†’ collateì—ì„œ í•„í„°.
- ë¡œê¹… ê°•í™”: ê° ì‹¤íŒ¨ ë‹¨ê³„ë³„ êµ¬ì²´ì  ì—ëŸ¬ ë©”ì‹œì§€ ê¸°ë¡ (PILì‹¤íŒ¨/OpenCVí´ë°±/ìµœì¢…ì‹¤íŒ¨)

C-8) ë©”íƒ€/ë¡œê·¸ ê°€ì‹œì„±

- summarize_dataset() ë¡œê·¸ í•­ëª©:
â€¢ ì´ íŒŒì¼/ìœ íš¨ íŒŒì¼ ìˆ˜, í´ë˜ìŠ¤ ìˆ˜/ìƒìœ„ 10 í´ë˜ìŠ¤ ë¶„í¬
â€¢ í•´ìƒë„ í†µê³„(í‰ê· /ì¤‘ì•™/ë¶„ì‚°, ìƒ˜í”Œë§), ì¢…íš¡ë¹„ íˆìŠ¤í†  ë²”ë¡€
â€¢ broken/skip ì¹´ìš´íŠ¸(ë¹„ìœ¨)
- build_dataloaders() ë¡œê·¸:
â€¢ ë¶„í•  ë¹„ìœ¨/ìƒ˜í”Œ ìˆ˜(train/val/test), num_workers/pin_memory/prefetch/persistent/drop_last
â€¢ test ë°ì´í„°ëŠ” ë¡œë” ìƒì„±í•˜ë˜ Stage í•™ìŠµ ì¤‘ ì‚¬ìš© ê¸ˆì§€ ëª…ì‹œ
â€¢ sampler/ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€, max_samples ì ìš© ì—¬ë¶€
â€¢ ì˜¤í† íŠœë‹ì„ ëŒë ¸ë‹¤ë©´ í›„ë³´ë³„ data_time ë° ìµœì¢… ì„ íƒê°’

C-9) ë°˜í™˜ ë©”íƒ€(meta ë”•ì…”ë„ˆë¦¬) ìŠ¤í™
meta = {
"class_names": list[str],
"class_to_idx": dict[str,int],
"train_count": int, "val_count": int, "test_count": int,
"img_size": int,
"splits_json": "/home/max16/pillsnap_data/exp/exp01/splits.json",
"test_usage_policy": "final_evaluation_only",
"weights_used": "inv_freq|effective_num|none",
"sampler_used": "weighted|none",
"skipped_files": int
}

C-10) í…ŒìŠ¤íŠ¸(ê¶Œì¥)

- tests/test_data_min.py ì‘ì„±:
â€¢ discover_dataset(): íŒŒì¼/í´ë˜ìŠ¤ ìˆ˜ ì¼ì¹˜, ìˆ¨ê¹€/í™•ì¥ì í•„í„° ë™ì‘
â€¢ make_splits(): ìºì‹œ ì €ì¥/ì¬ì‚¬ìš©/ë¬´ê²°ì„± ì²´í¬
â€¢ open_image_safely(): grayscale/RGBA/EXIF ì²˜ë¦¬ ê²€ì¦
â€¢ build_dataloaders(): safe_collateë¡œ ë¹ˆ ë°°ì¹˜ ì˜ˆì™¸ ì—†ì´ ë°°ì¹˜ ìƒì„±
â€¢ compute_class_weights(): ê°’ ë²”ìœ„/í‰ê· =1 ìŠ¤ì¼€ì¼ ê²€ì¦
- ì„±ëŠ¥ ìŠ¤ëª¨í¬: num_workers í›„ë³´ [4,8]ë¡œ 200 step ë¯¸ë‹ˆë²¤ì¹˜ â†’ data_time ê°œì„  ë¡œê·¸ í™•ì¸.

C-11) ì‹¤í–‰Â·ê²€ì¦ ì ˆì°¨

1. config.yamlì˜ data.root/img_size/augment í™•ì¸.
2. (ì„ íƒ) classes.json ì‘ì„±í•´ data.class_namesì— ì§€ì •, ì—†ìœ¼ë©´ í´ë”ëª… ìë™.
3. src/data.pyë¥¼ ë³¸ ëª…ì„¸ëŒ€ë¡œ êµ¬í˜„(ì£¼ì„ì— ì„¤ê³„ ì´ìœ Â·ì˜ˆì™¸ ì²˜ë¦¬ ê·¼ê±° í¬í•¨).
4. $ bash scripts/core/setup_venv.sh
5. (ê°„ì´ ì ê²€) Python REPL:
 > > > from src import data as D, utils as U
 > > >
 > > > # cfg ë¡œë“œ í›„:
 > > >
 > > > # train_loader, val_loader, meta = D.build_dataloaders(cfg, logger, seed=42)
6. Part Dë¡œ ë„˜ì–´ê°€ $ bash scripts/train.sh ì‹¤í–‰. ë¡œê·¸ì— ë°ì´í„° ìš”ì•½/ë¶„í• /ì˜¤í† íŠœë‹ ê²°ê³¼ê°€ ì°íˆëŠ”ì§€ í™•ì¸.

C-12) ì„±ëŠ¥ íŠœë‹ íŒ

- Pillow-SIMD: ì„¤ì¹˜ ì‹œ ë””ì½”ë”©â†‘ (í™˜ê²½ ì¶©ëŒ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ íŒ¨ìŠ¤, READMEì— ì£¼ì„ ë§í¬).
- ulimit -n ìƒí–¥: ì›Œì»¤ íŒŒì¼í•¸ë“¤ ë¶€ì¡± ì˜¤ë¥˜ ì˜ˆë°©.
- prefetch_factor: 2â†’4â†’8ë¡œ ëŠ˜ë¦¬ë©° data_time ì¶”ì (ë©”ëª¨ë¦¬ ì—¬ìœ  í•„ìš”).
- persistent_workers=True: ì—í­ ì‚¬ì´ ì¬í¬í¬ ë¹„ìš©â†“.
- ì…ë ¥ í¬ê¸° ë‹¤ì–‘ ì‹œ RandomResizedCropì´ resize+augmentationì„ í†µí•©í•´ ìºì‹œ íš¨ìœ¨â†‘.

C-13) Drug Metadata ë§¤í•‘ ë¡œì§ êµ¬í˜„

**build_drug_metadata_mapping í•¨ìˆ˜**:
```python
def build_drug_metadata_mapping(coco_annotations_dir: str, output_path: str) -> dict:
    """
    COCO annotationsì—ì„œ edi_code â†’ drug_metadata ë§¤í•‘ í…Œì´ë¸” êµ¬ì¶•
    
    Args:
        coco_annotations_dir: COCO JSON íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_path: ë§¤í•‘ í…Œì´ë¸” ì €ì¥ ê²½ë¡œ
    
    Returns:
        ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ {edi_code: {metadata}}
    """
    drug_metadata = {}
    edi_to_class_id = {}
    class_id_counter = 0
    
    # ëª¨ë“  COCO JSON íŒŒì¼ ìˆœíšŒ
    for json_file in glob.glob(f"{coco_annotations_dir}/**/*.json", recursive=True):
        with open(json_file, 'r', encoding='utf-8') as f:
            coco_data = json.load(f)
        
        # images ì„¹ì…˜ì—ì„œ ì•½í’ˆ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        for image_info in coco_data.get('images', []):
            edi_code = image_info.get('di_edi_code')
            if not edi_code:
                continue
                
            # edi_code â†’ class_id ë§¤í•‘ (ì²« ë“±ì¥ì‹œ ìƒˆ ID í• ë‹¹)
            if edi_code not in edi_to_class_id:
                edi_to_class_id[edi_code] = class_id_counter
                class_id_counter += 1
            
            # ì™„ì „í•œ ì•½í’ˆ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
            metadata = {
                'edi_code': edi_code,
                'class_id': edi_to_class_id[edi_code],
                'dl_name': image_info.get('dl_name', ''),
                'drug_shape': image_info.get('drug_shape', ''),
                'color_class1': image_info.get('color_class1', ''),
                'color_class2': image_info.get('color_class2', ''),
                'print_front': image_info.get('print_front', ''),
                'print_back': image_info.get('print_back', ''),
                'drug_type': image_info.get('drug_type', ''),
                'mark_code_front': image_info.get('mark_code_front', ''),
                'mark_code_back': image_info.get('mark_code_back', ''),
                # ì¶”ê°€ í•„ë“œë“¤...
            }
            
            drug_metadata[edi_code] = metadata
    
    # ë§¤í•‘ í…Œì´ë¸” ì €ì¥
    mapping_data = {
        'edi_to_class_id': edi_to_class_id,
        'drug_metadata': drug_metadata,
        'num_classes': len(edi_to_class_id),
        'created_at': datetime.utcnow().isoformat()
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(mapping_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"Drug metadata mapping saved: {len(drug_metadata)} drugs, {len(edi_to_class_id)} classes")
    return mapping_data

def get_class_id_from_edi_code(edi_code: str, mapping_data: dict) -> int:
    """edi_code â†’ class_id ë³€í™˜"""
    return mapping_data['edi_to_class_id'].get(edi_code, -1)

def get_drug_metadata_from_class_id(class_id: int, mapping_data: dict) -> dict:
    """class_id â†’ drug_metadata ë³€í™˜"""
    for edi_code, metadata in mapping_data['drug_metadata'].items():
        if metadata['class_id'] == class_id:
            return metadata
    return {'error': 'metadata_not_found', 'class_id': class_id}
```

C-14) êµ¬ì²´ì  ë©”ëª¨ë¦¬ ê´€ë¦¬ êµ¬í˜„

**LMDB ìºì‹œ ì‹œìŠ¤í…œ**:
```python
# src/data/lmdb_cache.py
import lmdb
import pickle
from cachetools import LRUCache

class LMDBImageCache:
    def __init__(self, lmdb_path: str, readonly: bool = True, map_size: str = "500GB"):
        self.env = lmdb.open(lmdb_path, readonly=readonly, 
                            lock=False, readahead=True, 
                            max_readers=512, map_size=self._parse_size(map_size))
        
    def get(self, key: str) -> Optional[np.ndarray]:
        with self.env.begin() as txn:
            data = txn.get(key.encode())
            if data:
                return pickle.loads(data)
        return None
```

**LRU ìºì‹œ ë˜í¼**:
```python
# 32GB LRU ìºì‹œ with size tracking
class SizedLRUCache:
    def __init__(self, max_bytes: int = 34359738368):  # 32GB
        self.max_bytes = max_bytes
        self.current_bytes = 0
        self.cache = {}
        self.access_order = []
    
    def get(self, key: str) -> Optional[np.ndarray]:
        if key in self.cache:
            self.access_order.remove(key)
            self.access_order.append(key)
            return self.cache[key]
        return None
```

**í”„ë¡œì„¸ìŠ¤ê°„ ê³µìœ  ë©”ëª¨ë¦¬**:
```python
# Dataset.__getitem__ ìµœì í™”
def __getitem__(self, idx: int):
    # 1. LMDB ì¡°íšŒ
    if self.use_lmdb:
        image = self.lmdb_cache.get(f"image_{idx}")
        if image is not None:
            return self._process_cached(image, idx)
    
    # 2. LRU ìºì‹œ ì¡°íšŒ  
    cache_key = f"{self.split}_{idx}"
    if cache_key in self.lru_cache:
        image = self.lru_cache[cache_key]
        return self._process_cached(image, idx)
    
    # 3. ë””ìŠ¤í¬ ë¡œë“œ
    image = self._load_from_disk(idx)
    
    # 4. ìºì‹œ ì €ì¥ (í¬ê¸° ì œí•œ)
    if self._should_cache(image):
        self.lru_cache[cache_key] = image
    
    return self._process_image(image, idx)

def _process_cached(self, image: np.ndarray, idx: int):
    # torch.from_numpy with share_memory_() for multiprocessing
    tensor = torch.from_numpy(image).share_memory_()
    if self.channels_last:
        tensor = tensor.to(memory_format=torch.channels_last)
    return {"image": tensor, "label": self.labels[idx]}
```

**Stageë³„ í”„ë¦¬ë¡œë“œ ì „ëµ**:
```python
# Stageë³„ ë°ì´í„° ì‚¬ì „ ë¡œë“œ
def preload_stage_data(cfg, stage: int):
    preload_count = cfg.dataloader.ram_optimization.preload_samples.get(f"stage_{stage}", 0)
    
    if preload_count > 0:
        logger.info(f"Stage {stage}: Preloading {preload_count} samples to memory")
        # hotsetì— ìì£¼ ì‚¬ìš©ë˜ëŠ” ìƒ˜í”Œë“¤ ìš°ì„  ë¡œë“œ
        for idx in range(min(preload_count, len(dataset))):
            _ = dataset[idx]  # ìºì‹œì— ì €ì¥ë¨
```

C-Seg) ì„¸ê·¸ë©˜í…Œì´ì…˜ íŒŒì´í”„ë¼ì¸(ì˜µì…˜)

- data.task="segmentation"ì¼ ë•Œë§Œ.
- êµ¬ì¡°: images/_.jpg|png, masks/_.png(ì •ìˆ˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤, íŒŒì¼ëª… ë§¤ì¹­)
- ë³€í™˜: albumentationsë¡œ ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ ë™ê¸°(rotate/flip/scale/crop/colorjitter)
- ë³´ê°„: ì´ë¯¸ì§€=bilinear, ë§ˆìŠ¤í¬=nearest
- Dataset.**getitem** â†’ {"image": Tensor, "mask": LongTensor, "path": str}
- ì†ì‹¤/ì§€í‘œ: CE+Dice, mIoU/Dice/PixelAcc
- DataLoader/ì˜¤í† íŠœë‹/ë¡œê¹… ê·œì¹™ì€ ë¶„ë¥˜ì™€ ë™ì¼

C-Det) YOLOv11 ë°ì´í„°(ì˜µì…˜, Ultralytics)

- í¬ë§·:
root/images/train|val|test/_.jpg|png
root/labels/train|val|test/_.txt # <cls> <cx> <cy> <w> <h> (0~1)
- data.yaml ì˜ˆ:
path: /mnt/data/AIHub_576
train: images/train
val: images/val
test: images/test
nc: 3
names: ["pill","capsule","tablet"]
- ìœ íš¨ì„± ìœ í‹¸(src/det/utils_det.py): ë¼ë²¨ ë²”ìœ„/í´ë˜ìŠ¤ ì¸ë±ìŠ¤/ê³ ì•„ íŒŒì¼ ê²€ì‚¬.
- ë³€í™˜ ë³´ì¡° ìŠ¤í¬ë¦½íŠ¸(scripts/prepare_yolo.sh): ë¶„ë¥˜â†’ê²€ì¶œ ë³€í™˜(ì„ íƒ).

Annex) ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½
A1. discover_dataset(): verify_on_build=Trueë©´ PIL.verify()+EXIF transpose, ì‹¤íŒ¨=skip
A2. open_image_safely(): grayscale/rgba ì •ì±…, OpenCV í´ë°± 1íšŒ, ì‹¤íŒ¨ëŠ” {"\_skip":True}
A3. make_splits(): stratified+persist JSON, ë¬´ê²°ì„±=ê²½ë¡œ/ê°œìˆ˜/ë¼ë²¨
A4. build_transforms(): vision v2 ê¸°ë°˜, Normalize(IMAGENET), train/val êµ¬ë¶„
A5. Dataset: **getitem** ì˜ˆì™¸ë¥¼ ë˜ì§€ì§€ ì•Šê³  "\_skip" í”Œë˜ê·¸ë¡œ ìƒìœ„ì— í†µì§€
A6. safe_collate(): \_skip í•„í„°, ë¹ˆ ë°°ì¹˜ ë°©ì§€, meta(paths) ë°˜í™˜
A7. build_dataloaders(): sampler/ê°€ì¤‘ì¹˜/ì˜¤í† íŠœë‹/ë¡œê¹… ë°˜ì˜
A8. compute_class_weights(): inv_freq/effective_num, í‰ê· =1 ìŠ¤ì¼€ì¼
A9. worker_init_fn(): numpy/torch/random ì‹œë“œ ê³ ì •
A10. summarize_dataset(): ë¶„í¬/í•´ìƒë„/ì¢…íš¡ë¹„/ì†ìƒ ë¡œê·¸

## ğŸ¯ **PART_C í•µì‹¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ**

### âœ… **ì¡°ê±´ë¶€ Two-Stage ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„**
- **ë‹¨ì¼ ì•½í’ˆ**: ì§ì ‘ ë¶„ë¥˜ (384px, EfficientNetV2-S ìµœì í™”)
- **ì¡°í•© ì•½í’ˆ**: YOLO ê²€ì¶œ â†’ ë¶„ë¥˜ (640px, YOLOv11m)  
- **ì‚¬ìš©ì ì œì–´**: mode="single"|"combo" íŒŒë¼ë¯¸í„° ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì„ íƒ

### âœ… **128GB RAM + RTX 5080 16GB ìµœì í™” (ë³´ìˆ˜ì  ê¸°ë³¸ê°’)**
- **ë©”ëª¨ë¦¬ ìºì‹œ**: í•«ì…‹ 6ë§Œì¥ë§Œ ìºì‹œ (â‰ˆ25GB, ê¸°ë³¸ off)
- **LMDB ë³€í™˜**: ê¸°ë³¸ ë¹„í™œì„±, data_time ë³‘ëª© ì‹œì—ë§Œ í™œì„±í™” (Opt-in)
- **ë°ì´í„°ë¡œë”**: num_workers=8, prefetch_factor=4, pin_memory_device="cuda"

### âœ… **ì˜ë¬¸ ë°ì´í„° ê²½ë¡œ êµ¬ì¡°**
- **ì…ë ¥**: /mnt/data/pillsnap_dataset (í•œê¸€â†’ì˜ë¬¸ ë³€í™˜)
- **ì²˜ë¦¬**: single/combination ë¶„ë¦¬ êµ¬ì¡°
- **ì¶œë ¥**: LMDB + YOLO í˜•ì‹ ìµœì í™”

### ğŸ“‹ **ë‹¤ìŒ íŒŒíŠ¸ì—ì„œ êµ¬í˜„í•  í•µì‹¬ í´ë˜ìŠ¤**
- `UserControlledTwoStageDataset`: ì‚¬ìš©ì ì œì–´ íŒŒì´í”„ë¼ì¸ ì„ íƒ
- `SinglePillDataset`: ì§ì ‘ ë¶„ë¥˜ìš© (384px)  
- `CombinationPillDataset`: YOLO ê²€ì¶œìš© (640px)
- `memory_efficient_loader`: 128GB RAM ìµœì í™”
- `lmdb_converter`: ëŒ€ìš©ëŸ‰ ë°ì´í„° I/O ìµœì í™”

**âœ… PART_C ì™„ë£Œ: í•˜ë“œì›¨ì–´ ìµœì í™”ëœ ì¡°ê±´ë¶€ Two-Stage ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„**

---

## ğŸ¯ **Stage 3-4 Manifest ê¸°ë°˜ ì ‘ê·¼ë²• (2025-08-22 ì—…ë°ì´íŠ¸)**

### **â­ ì¤‘ìš”í•œ ì •ì±… ë³€ê²½**
**Stage 3-4ëŠ” ë°˜ë“œì‹œ manifest ê¸°ë°˜ìœ¼ë¡œë§Œ ì§„í–‰í•©ë‹ˆë‹¤.**

- **ë¬¼ë¦¬ì  ë°ì´í„° ë³µì‚¬**: âŒ ê¸ˆì§€ (SSD ìš©ëŸ‰ ë¶€ì¡±)
- **Manifest CSV íŒŒì¼**: âœ… ê¶Œì¥ (ìš©ëŸ‰ ì ˆì•½)
- **ì›ë³¸ ì§ì ‘ ë¡œë”©**: âœ… í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€ í™œìš©

### **ìš©ëŸ‰ ì ˆì•½ íš¨ê³¼**
```
Stage 3 (100K ìƒ˜í”Œ): 14.6GB â†’ 50MB (99.7% ì ˆì•½)
Stage 4 (500K ìƒ˜í”Œ): 73.0GB â†’ 200MB (99.7% ì ˆì•½)
ì´ ì ˆì•½ëŸ‰: 87.6GB â†’ 250MB (99.7% ì ˆì•½)
```

### **ê¸°ìˆ ì  ê·¼ê±°**
1. **Native Linux + 128GB RAM**: ì‹¤ì‹œê°„ ê³ ì† ë¡œë”© ê°€ëŠ¥
2. **í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€**: Linux SSD (3.5GB/s) + Windows SSD (1GB/s)
3. **ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±**: `src/data.py` ë°ì´í„°ë¡œë” ê·¸ëŒ€ë¡œ ì‚¬ìš©
4. **ì„±ëŠ¥ ì†ì‹¤ ì—†ìŒ**: ë©”ëª¨ë¦¬ ìºì‹œ + ë¹ ë¥¸ SSD I/O

### **êµ¬í˜„ ë°©í–¥**
- **Stage 1-2**: ê¸°ì¡´ config ê¸°ë°˜ ë°©ì‹ ìœ ì§€
- **Stage 3-4**: manifest ìƒì„± ìŠ¤í¬ë¦½íŠ¸ + ê¸°ì¡´ `src/data.py` Dataset í™œìš©
- **ì½”ë“œ ë³€ê²½ ìµœì†Œí™”**: ìƒˆë¡œìš´ ë°ì´í„°ë¡œë” êµ¬í˜„ ë¶ˆí•„ìš”
- **ê¸°ì¡´ ì»¨ë²¤ì…˜ ì¤€ìˆ˜**: `src/training/train_classification_stage.py` í™œìš©

### **Stage 3-4 í•™ìŠµ ëª…ë ¹ì–´ (ê¸°ì¡´ ì»¨ë²¤ì…˜)**
```bash
# Stage 3 manifest ê¸°ë°˜ í•™ìŠµ (ê¸°ì¡´ trainer í™œìš©)
python -m src.training.train_classification_stage \
    --manifest artifacts/stage3/manifest_train.csv \
    --num-classes 1000 \
    --target-accuracy 0.85 \
    --epochs 50 \
    --batch-size 16

# Stage 4 manifest ê¸°ë°˜ í•™ìŠµ (ê¸°ì¡´ trainer í™œìš©)  
python -m src.training.train_classification_stage \
    --manifest artifacts/stage4/manifest_train.csv \
    --num-classes 4523 \
    --target-accuracy 0.92 \
    --epochs 100 \
    --batch-size 8
```
